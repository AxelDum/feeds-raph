diff --git a/.gitignore b/.gitignore
deleted file mode 100644
index ad4a208..0000000
--- a/.gitignore
+++ /dev/null
@@ -1 +0,0 @@
-cmd/bosun/dev.conf
diff --git a/build/build.go b/build/build.go
index 2486634..29b687b 100644
--- a/build/build.go
+++ b/build/build.go
@@ -8,12 +8,21 @@ import (
 	"log"
 	"os"
 	"os/exec"
+	"path/filepath"
 	"strings"
 	"time"
 )
 
+var (
+	shaFlag         = flag.String("sha", "", "SHA to embed.")
+	buildBosun      = flag.Bool("bosun", false, "Only build Bosun.")
+	buildScollector = flag.Bool("scollector", false, "Only build scollector.")
+	output          = flag.String("output", "", "Output directory; defaults to $GOPATH/bin.")
+
+	allProgs = []string{"bosun", "scollector"}
+)
+
 func main() {
-	shaFlag := flag.String("sha", "", "Sha to embed")
 	flag.Parse()
 	// Get current commit SHA
 	sha := *shaFlag
@@ -28,11 +37,25 @@ func main() {
 	}
 
 	timeStr := time.Now().UTC().Format("20060102150405")
-
 	ldFlags := fmt.Sprintf("-X bosun.org/version.VersionSHA %s -X bosun.org/version.VersionDate %s", sha, timeStr)
 
-	for _, app := range []string{"bosun", "scollector"} {
-		cmd := exec.Command("go", "install", "-v", "-ldflags", ldFlags, fmt.Sprintf("bosun.org/cmd/%s", app))
+	progs := allProgs
+	if *buildBosun {
+		progs = []string{"bosun"}
+	}
+	if *buildScollector {
+		progs = []string{"scollector"}
+	}
+	for _, app := range progs {
+		fmt.Println("building", app)
+		var args []string
+		if *output != "" {
+			args = append(args, "build", "-o", filepath.Join(*output, app))
+		} else {
+			args = append(args, "install")
+		}
+		args = append(args, "-ldflags", ldFlags, fmt.Sprintf("bosun.org/cmd/%s", app))
+		cmd := exec.Command("go", args...)
 		cmd.Stdout = os.Stdout
 		cmd.Stderr = os.Stderr
 		err := cmd.Run()
diff --git a/cmd/bosun/conf/conf.go b/cmd/bosun/conf/conf.go
index 04ddf30..85acb5f 100644
--- a/cmd/bosun/conf/conf.go
+++ b/cmd/bosun/conf/conf.go
@@ -55,8 +55,6 @@ type Conf struct {
 	Squelch          Squelches `json:"-"`
 	Quiet            bool
 	NoSleep          bool
-	AllowedPutIPs    []*net.IPNet
-	BlockedPutIPs    []*net.IPNet
 	ShortURLKey      string
 
 	TSDBHost             string                    // OpenTSDB relay and query destination: ny-devtsdb04:4242
@@ -71,29 +69,6 @@ type Conf struct {
 	squelch         []string
 }
 
-func (c *Conf) PutAuthorized(ip net.IP) bool {
-	// First process all blocked put ip ranges.
-	for _, ipnet := range c.BlockedPutIPs {
-		if ipnet.Contains(ip) {
-			return false
-		}
-	}
-	// If no allowed put IPs are specified, then allow all IPs.
-	if len(c.AllowedPutIPs) == 0 {
-		return true
-	}
-	if ip.IsLoopback() {
-		return true
-	}
-	// Finally process allowed IPs.
-	for _, ipnet := range c.AllowedPutIPs {
-		if ipnet.Contains(ip) {
-			return true
-		}
-	}
-	return false
-}
-
 // TSDBContext returns an OpenTSDB context limited to
 // c.ResponseLimit. A nil context is returned if TSDBHost is not set.
 func (c *Conf) TSDBContext() opentsdb.Context {
@@ -444,10 +419,6 @@ func (c *Conf) loadGlobal(p *parse.PairNode) {
 		c.PingDuration = d
 	case "noSleep":
 		c.NoSleep = true
-	case "blockedPutIPs":
-		c.BlockedPutIPs = c.parseIPs(v)
-	case "allowedPutIPs":
-		c.AllowedPutIPs = c.parseIPs(v)
 	case "unknownThreshold":
 		i, err := strconv.Atoi(v)
 		if err != nil {
@@ -697,10 +668,13 @@ var defaultFuncs = ttemplate.FuncMap{
 		}
 		return ByteSize(0), fmt.Errorf("unexpected type: %T (%v)", v, v)
 	},
+	"pct": func(i interface{}) string {
+		return fmt.Sprintf("%.2f%%", i)
+	},
+	"replace": strings.Replace,
 	"short": func(v string) string {
 		return strings.SplitN(v, ".", 2)[0]
 	},
-	"replace": strings.Replace,
 }
 
 func (c *Conf) loadTemplate(s *parse.SectionNode) {
@@ -1131,7 +1105,7 @@ func (c *Conf) NewExpr(s string) *expr.Expr {
 		c.error(err)
 	}
 	switch exp.Root.Return() {
-	case eparse.TypeNumber, eparse.TypeScalar:
+	case eparse.TypeNumberSet, eparse.TypeScalar:
 		break
 	default:
 		c.errorf("expression must return a number")
@@ -1245,7 +1219,7 @@ func (c *Conf) Funcs() map[string]eparse.Func {
 		if err != nil {
 			return nil, err
 		}
-		if a.returnType != eparse.TypeNumber {
+		if a.returnType != eparse.TypeNumberSet {
 			return nil, fmt.Errorf("alert requires a number-returning expression (got %v)", a.returnType)
 		}
 		return e.Root.Tags()
@@ -1254,19 +1228,19 @@ func (c *Conf) Funcs() map[string]eparse.Func {
 	funcs := map[string]eparse.Func{
 		"alert": {
 			Args:   []eparse.FuncType{eparse.TypeString, eparse.TypeString},
-			Return: eparse.TypeNumber,
+			Return: eparse.TypeNumberSet,
 			Tags:   tagAlert,
 			F:      c.alert,
 		},
 		"lookup": {
 			Args:   []eparse.FuncType{eparse.TypeString, eparse.TypeString},
-			Return: eparse.TypeNumber,
+			Return: eparse.TypeNumberSet,
 			Tags:   lookupTags,
 			F:      lookup,
 		},
 		"lookupSeries": {
-			Args:   []eparse.FuncType{eparse.TypeSeries, eparse.TypeString, eparse.TypeString},
-			Return: eparse.TypeNumber,
+			Args:   []eparse.FuncType{eparse.TypeSeriesSet, eparse.TypeString, eparse.TypeString},
+			Return: eparse.TypeNumberSet,
 			Tags:   lookupSeriesTags,
 			F:      lookupSeries,
 		},
diff --git a/cmd/bosun/expr/expr.go b/cmd/bosun/expr/expr.go
index f442c64..e2c7fc8 100644
--- a/cmd/bosun/expr/expr.go
+++ b/cmd/bosun/expr/expr.go
@@ -143,7 +143,7 @@ func marshalFloat(n float64) ([]byte, error) {
 
 type Number float64
 
-func (n Number) Type() parse.FuncType         { return parse.TypeNumber }
+func (n Number) Type() parse.FuncType         { return parse.TypeNumberSet }
 func (n Number) Value() interface{}           { return n }
 func (n Number) MarshalJSON() ([]byte, error) { return marshalFloat(float64(n)) }
 
@@ -156,7 +156,7 @@ func (s Scalar) MarshalJSON() ([]byte, error) { return marshalFloat(float64(s))
 // Series is the standard form within bosun to represent timeseries data.
 type Series map[time.Time]float64
 
-func (s Series) Type() parse.FuncType { return parse.TypeSeries }
+func (s Series) Type() parse.FuncType { return parse.TypeSeriesSet }
 func (s Series) Value() interface{}   { return s }
 
 func (s Series) MarshalJSON() ([]byte, error) {
@@ -605,7 +605,7 @@ func (e *State) walkFunc(node *parse.FuncNode, T miniprofiler.Timer) *Results {
 				panic(err)
 			}
 		}
-		if node.Return() == parse.TypeNumber {
+		if node.Return() == parse.TypeNumberSet {
 			for _, r := range res.Results {
 				e.AddComputation(r, node.String(), r.Value.(Number))
 			}
diff --git a/cmd/bosun/expr/funcs.go b/cmd/bosun/expr/funcs.go
index 10372ca..0919e76 100644
--- a/cmd/bosun/expr/funcs.go
+++ b/cmd/bosun/expr/funcs.go
@@ -86,13 +86,13 @@ func tagRename(args []parse.Node) (parse.Tags, error) {
 var Graphite = map[string]parse.Func{
 	"graphiteBand": {
 		Args:   []parse.FuncType{parse.TypeString, parse.TypeString, parse.TypeString, parse.TypeString, parse.TypeScalar},
-		Return: parse.TypeSeries,
+		Return: parse.TypeSeriesSet,
 		Tags:   graphiteTagQuery,
 		F:      GraphiteBand,
 	},
 	"graphite": {
 		Args:   []parse.FuncType{parse.TypeString, parse.TypeString, parse.TypeString, parse.TypeString},
-		Return: parse.TypeSeries,
+		Return: parse.TypeSeriesSet,
 		Tags:   graphiteTagQuery,
 		F:      GraphiteQuery,
 	},
@@ -102,13 +102,13 @@ var Graphite = map[string]parse.Func{
 var TSDB = map[string]parse.Func{
 	"band": {
 		Args:   []parse.FuncType{parse.TypeString, parse.TypeString, parse.TypeString, parse.TypeScalar},
-		Return: parse.TypeSeries,
+		Return: parse.TypeSeriesSet,
 		Tags:   tagQuery,
 		F:      Band,
 	},
 	"change": {
 		Args:   []parse.FuncType{parse.TypeString, parse.TypeString, parse.TypeString},
-		Return: parse.TypeNumber,
+		Return: parse.TypeNumberSet,
 		Tags:   tagQuery,
 		F:      Change,
 	},
@@ -119,13 +119,13 @@ var TSDB = map[string]parse.Func{
 	},
 	"q": {
 		Args:   []parse.FuncType{parse.TypeString, parse.TypeString, parse.TypeString},
-		Return: parse.TypeSeries,
+		Return: parse.TypeSeriesSet,
 		Tags:   tagQuery,
 		F:      Query,
 	},
 	"window": {
 		Args:   []parse.FuncType{parse.TypeString, parse.TypeString, parse.TypeString, parse.TypeScalar, parse.TypeString},
-		Return: parse.TypeSeries,
+		Return: parse.TypeSeriesSet,
 		Tags:   tagQuery,
 		F:      Window,
 		Check:  windowCheck,
@@ -136,106 +136,106 @@ var builtins = map[string]parse.Func{
 	// Reduction functions
 
 	"avg": {
-		Args:   []parse.FuncType{parse.TypeSeries},
-		Return: parse.TypeNumber,
+		Args:   []parse.FuncType{parse.TypeSeriesSet},
+		Return: parse.TypeNumberSet,
 		Tags:   tagFirst,
 		F:      Avg,
 	},
 	"dev": {
-		Args:   []parse.FuncType{parse.TypeSeries},
-		Return: parse.TypeNumber,
+		Args:   []parse.FuncType{parse.TypeSeriesSet},
+		Return: parse.TypeNumberSet,
 		Tags:   tagFirst,
 		F:      Dev,
 	},
 	"diff": {
-		Args:   []parse.FuncType{parse.TypeSeries},
-		Return: parse.TypeNumber,
+		Args:   []parse.FuncType{parse.TypeSeriesSet},
+		Return: parse.TypeNumberSet,
 		Tags:   tagFirst,
 		F:      Diff,
 	},
 	"first": {
-		Args:   []parse.FuncType{parse.TypeSeries},
-		Return: parse.TypeNumber,
+		Args:   []parse.FuncType{parse.TypeSeriesSet},
+		Return: parse.TypeNumberSet,
 		Tags:   tagFirst,
 		F:      First,
 	},
 	"forecastlr": {
-		Args:   []parse.FuncType{parse.TypeSeries, parse.TypeScalar},
-		Return: parse.TypeNumber,
+		Args:   []parse.FuncType{parse.TypeSeriesSet, parse.TypeScalar},
+		Return: parse.TypeNumberSet,
 		Tags:   tagFirst,
 		F:      Forecast_lr,
 	},
 	"last": {
-		Args:   []parse.FuncType{parse.TypeSeries},
-		Return: parse.TypeNumber,
+		Args:   []parse.FuncType{parse.TypeSeriesSet},
+		Return: parse.TypeNumberSet,
 		Tags:   tagFirst,
 		F:      Last,
 	},
 	"len": {
-		Args:   []parse.FuncType{parse.TypeSeries},
-		Return: parse.TypeNumber,
+		Args:   []parse.FuncType{parse.TypeSeriesSet},
+		Return: parse.TypeNumberSet,
 		Tags:   tagFirst,
 		F:      Length,
 	},
 	"max": {
-		Args:   []parse.FuncType{parse.TypeSeries},
-		Return: parse.TypeNumber,
+		Args:   []parse.FuncType{parse.TypeSeriesSet},
+		Return: parse.TypeNumberSet,
 		Tags:   tagFirst,
 		F:      Max,
 	},
 	"median": {
-		Args:   []parse.FuncType{parse.TypeSeries},
-		Return: parse.TypeNumber,
+		Args:   []parse.FuncType{parse.TypeSeriesSet},
+		Return: parse.TypeNumberSet,
 		Tags:   tagFirst,
 		F:      Median,
 	},
 	"min": {
-		Args:   []parse.FuncType{parse.TypeSeries},
-		Return: parse.TypeNumber,
+		Args:   []parse.FuncType{parse.TypeSeriesSet},
+		Return: parse.TypeNumberSet,
 		Tags:   tagFirst,
 		F:      Min,
 	},
 	"percentile": {
-		Args:   []parse.FuncType{parse.TypeSeries, parse.TypeScalar},
-		Return: parse.TypeNumber,
+		Args:   []parse.FuncType{parse.TypeSeriesSet, parse.TypeScalar},
+		Return: parse.TypeNumberSet,
 		Tags:   tagFirst,
 		F:      Percentile,
 	},
 	"since": {
-		Args:   []parse.FuncType{parse.TypeSeries},
-		Return: parse.TypeNumber,
+		Args:   []parse.FuncType{parse.TypeSeriesSet},
+		Return: parse.TypeNumberSet,
 		Tags:   tagFirst,
 		F:      Since,
 	},
 	"sum": {
-		Args:   []parse.FuncType{parse.TypeSeries},
-		Return: parse.TypeNumber,
+		Args:   []parse.FuncType{parse.TypeSeriesSet},
+		Return: parse.TypeNumberSet,
 		Tags:   tagFirst,
 		F:      Sum,
 	},
 	"streak": {
-		Args:   []parse.FuncType{parse.TypeSeries},
-		Return: parse.TypeNumber,
+		Args:   []parse.FuncType{parse.TypeSeriesSet},
+		Return: parse.TypeNumberSet,
 		Tags:   tagFirst,
 		F:      Streak,
 	},
 
 	// Group functions
 	"rename": {
-		Args:   []parse.FuncType{parse.TypeSeries, parse.TypeString},
-		Return: parse.TypeSeries,
+		Args:   []parse.FuncType{parse.TypeSeriesSet, parse.TypeString},
+		Return: parse.TypeSeriesSet,
 		Tags:   tagRename,
 		F:      Rename,
 	},
 
 	"t": {
-		Args:   []parse.FuncType{parse.TypeNumber, parse.TypeString},
-		Return: parse.TypeSeries,
+		Args:   []parse.FuncType{parse.TypeNumberSet, parse.TypeString},
+		Return: parse.TypeSeriesSet,
 		Tags:   tagTranspose,
 		F:      Transpose,
 	},
 	"ungroup": {
-		Args:   []parse.FuncType{parse.TypeNumber},
+		Args:   []parse.FuncType{parse.TypeNumberSet},
 		Return: parse.TypeScalar,
 		F:      Ungroup,
 	},
@@ -243,8 +243,8 @@ var builtins = map[string]parse.Func{
 	// Other functions
 
 	"abs": {
-		Args:   []parse.FuncType{parse.TypeNumber},
-		Return: parse.TypeNumber,
+		Args:   []parse.FuncType{parse.TypeNumberSet},
+		Return: parse.TypeNumberSet,
 		Tags:   tagFirst,
 		F:      Abs,
 	},
@@ -254,26 +254,26 @@ var builtins = map[string]parse.Func{
 		F:      Duration,
 	},
 	"des": {
-		Args:   []parse.FuncType{parse.TypeSeries, parse.TypeScalar, parse.TypeScalar},
-		Return: parse.TypeSeries,
+		Args:   []parse.FuncType{parse.TypeSeriesSet, parse.TypeScalar, parse.TypeScalar},
+		Return: parse.TypeSeriesSet,
 		Tags:   tagFirst,
 		F:      Des,
 	},
 	"dropge": {
-		Args:   []parse.FuncType{parse.TypeSeries, parse.TypeScalar},
-		Return: parse.TypeSeries,
+		Args:   []parse.FuncType{parse.TypeSeriesSet, parse.TypeScalar},
+		Return: parse.TypeSeriesSet,
 		Tags:   tagFirst,
 		F:      DropGe,
 	},
 	"drople": {
-		Args:   []parse.FuncType{parse.TypeSeries, parse.TypeScalar},
-		Return: parse.TypeSeries,
+		Args:   []parse.FuncType{parse.TypeSeriesSet, parse.TypeScalar},
+		Return: parse.TypeSeriesSet,
 		Tags:   tagFirst,
 		F:      DropLe,
 	},
 	"dropna": {
-		Args:   []parse.FuncType{parse.TypeSeries},
-		Return: parse.TypeSeries,
+		Args:   []parse.FuncType{parse.TypeSeriesSet},
+		Return: parse.TypeSeriesSet,
 		Tags:   tagFirst,
 		F:      DropNA,
 	},
@@ -283,26 +283,26 @@ var builtins = map[string]parse.Func{
 		F:      Epoch,
 	},
 	"filter": {
-		Args:   []parse.FuncType{parse.TypeSeries, parse.TypeNumber},
-		Return: parse.TypeSeries,
+		Args:   []parse.FuncType{parse.TypeSeriesSet, parse.TypeNumberSet},
+		Return: parse.TypeSeriesSet,
 		Tags:   tagFirst,
 		F:      Filter,
 	},
 	"limit": {
-		Args:   []parse.FuncType{parse.TypeNumber, parse.TypeScalar},
-		Return: parse.TypeNumber,
+		Args:   []parse.FuncType{parse.TypeNumberSet, parse.TypeScalar},
+		Return: parse.TypeNumberSet,
 		Tags:   tagFirst,
 		F:      Limit,
 	},
 	"nv": {
-		Args:   []parse.FuncType{parse.TypeNumber, parse.TypeScalar},
-		Return: parse.TypeNumber,
+		Args:   []parse.FuncType{parse.TypeNumberSet, parse.TypeScalar},
+		Return: parse.TypeNumberSet,
 		Tags:   tagFirst,
 		F:      NV,
 	},
 	"sort": {
-		Args:   []parse.FuncType{parse.TypeNumber, parse.TypeString},
-		Return: parse.TypeNumber,
+		Args:   []parse.FuncType{parse.TypeNumberSet, parse.TypeString},
+		Return: parse.TypeNumberSet,
 		Tags:   tagFirst,
 		F:      Sort,
 	},
@@ -659,7 +659,7 @@ func windowCheck(t *parse.Tree, f *parse.FuncNode) error {
 	if !ok {
 		return fmt.Errorf("expr: Window: unknown function %v", name)
 	}
-	if len(v.Args) != 1 || v.Args[0] != parse.TypeSeries || v.Return != parse.TypeNumber {
+	if len(v.Args) != 1 || v.Args[0] != parse.TypeSeriesSet || v.Return != parse.TypeNumberSet {
 		return fmt.Errorf("expr: Window: %v is not a reduction function", name)
 	}
 	return nil
diff --git a/cmd/bosun/expr/logstash.go b/cmd/bosun/expr/logstash.go
index 1ab0ad4..c7a9280 100644
--- a/cmd/bosun/expr/logstash.go
+++ b/cmd/bosun/expr/logstash.go
@@ -21,13 +21,13 @@ var lsClient *elastic.Client
 var LogstashElastic = map[string]parse.Func{
 	"lscount": {
 		Args:   []parse.FuncType{parse.TypeString, parse.TypeString, parse.TypeString, parse.TypeString, parse.TypeString, parse.TypeString},
-		Return: parse.TypeSeries,
+		Return: parse.TypeSeriesSet,
 		Tags:   logstashTagQuery,
 		F:      LSCount,
 	},
 	"lsstat": {
 		Args:   []parse.FuncType{parse.TypeString, parse.TypeString, parse.TypeString, parse.TypeString, parse.TypeString, parse.TypeString, parse.TypeString, parse.TypeString},
-		Return: parse.TypeSeries,
+		Return: parse.TypeSeriesSet,
 		Tags:   logstashTagQuery,
 		F:      LSStat,
 	},
@@ -122,6 +122,10 @@ func (e *LogstashElasticHosts) GenIndices(r *LogstashRequest) (string, error) {
 	if err != nil {
 		return "", err
 	}
+	// Short-circut when using concrete ES index name
+	if strings.HasSuffix(r.IndexRoot, "/") {
+		return r.IndexRoot[:len(r.IndexRoot)-1], nil
+	}
 	indices, err := lsClient.IndexNames()
 	if err != nil {
 		return "", err
@@ -147,7 +151,7 @@ func (e *LogstashElasticHosts) GenIndices(r *LogstashRequest) (string, error) {
 		}
 	}
 	if len(selectedIndices) == 0 {
-		return "", fmt.Errorf("no elastic indices available during this time range")
+		return "", fmt.Errorf("no elastic indices available during this time range, index[%s], start/end [%s|%s]", r.IndexRoot, start.Format("2006.01.02"), end.Format("2006.01.02"))
 	}
 	return strings.Join(selectedIndices, ","), nil
 }
diff --git a/cmd/bosun/expr/parse/node.go b/cmd/bosun/expr/parse/node.go
index d2d341e..565ef19 100644
--- a/cmd/bosun/expr/parse/node.go
+++ b/cmd/bosun/expr/parse/node.go
@@ -254,14 +254,14 @@ func (b *BinaryNode) StringAST() string {
 func (b *BinaryNode) Check(t *Tree) error {
 	t1 := b.Args[0].Return()
 	t2 := b.Args[1].Return()
-	if t1 == TypeSeries && t2 == TypeSeries {
+	if t1 == TypeSeriesSet && t2 == TypeSeriesSet {
 		return fmt.Errorf("parse: type error in %s: at least one side must be a number", b)
 	}
 	check := t1
-	if t1 == TypeSeries {
+	if t1 == TypeSeriesSet {
 		check = t2
 	}
-	if check != TypeNumber && check != TypeScalar {
+	if check != TypeNumberSet && check != TypeScalar {
 		return fmt.Errorf("parse: type error in %s: expected a number", b)
 	}
 	if err := b.Args[0].Check(t); err != nil {
@@ -327,7 +327,7 @@ func (u *UnaryNode) StringAST() string {
 
 func (u *UnaryNode) Check(t *Tree) error {
 	switch rt := u.Arg.Return(); rt {
-	case TypeNumber, TypeSeries, TypeScalar:
+	case TypeNumberSet, TypeSeriesSet, TypeScalar:
 		return u.Arg.Check(t)
 	default:
 		return fmt.Errorf("parse: type error in %s, expected %s, got %s", u, "number", rt)
diff --git a/cmd/bosun/expr/parse/parse.go b/cmd/bosun/expr/parse/parse.go
index 0e46027..3f252fe 100644
--- a/cmd/bosun/expr/parse/parse.go
+++ b/cmd/bosun/expr/parse/parse.go
@@ -40,11 +40,11 @@ type FuncType int
 
 func (f FuncType) String() string {
 	switch f {
-	case TypeNumber:
+	case TypeNumberSet:
 		return "number"
 	case TypeString:
 		return "string"
-	case TypeSeries:
+	case TypeSeriesSet:
 		return "series"
 	case TypeScalar:
 		return "scalar"
@@ -56,8 +56,8 @@ func (f FuncType) String() string {
 const (
 	TypeString FuncType = iota
 	TypeScalar
-	TypeNumber
-	TypeSeries
+	TypeNumberSet
+	TypeSeriesSet
 )
 
 type Tags map[string]struct{}
@@ -206,7 +206,7 @@ func (t *Tree) startParse(funcs []map[string]Func, lex *lexer) {
 	for _, funcMap := range funcs {
 		for name, f := range funcMap {
 			switch f.Return {
-			case TypeSeries, TypeNumber:
+			case TypeSeriesSet, TypeNumberSet:
 				if f.Tags == nil {
 					panic(fmt.Errorf("%v: expected Tags definition: got nil", name))
 				}
diff --git a/cmd/bosun/expr/parse/parse_test.go b/cmd/bosun/expr/parse/parse_test.go
index 9834603..2ab02d2 100644
--- a/cmd/bosun/expr/parse/parse_test.go
+++ b/cmd/bosun/expr/parse/parse_test.go
@@ -150,29 +150,29 @@ func tagNil(args []Node) (Tags, error) {
 
 var builtins = map[string]Func{
 	"avg": {
-		[]FuncType{TypeSeries},
-		TypeNumber,
+		[]FuncType{TypeSeriesSet},
+		TypeNumberSet,
 		tagNil,
 		nil,
 		nil,
 	},
 	"band": {
 		[]FuncType{TypeString, TypeString, TypeString, TypeScalar},
-		TypeSeries,
+		TypeSeriesSet,
 		tagNil,
 		nil,
 		nil,
 	},
 	"q": {
 		[]FuncType{TypeString, TypeString},
-		TypeSeries,
+		TypeSeriesSet,
 		tagNil,
 		nil,
 		nil,
 	},
 	"forecastlr": {
-		[]FuncType{TypeSeries, TypeScalar},
-		TypeNumber,
+		[]FuncType{TypeSeriesSet, TypeScalar},
+		TypeNumberSet,
 		tagNil,
 		nil,
 		nil,
diff --git a/cmd/bosun/sched/template.go b/cmd/bosun/sched/template.go
index 0cf2ad3..6e73632 100644
--- a/cmd/bosun/sched/template.go
+++ b/cmd/bosun/sched/template.go
@@ -200,7 +200,7 @@ func (c *Context) evalExpr(e *expr.Expr, filter bool, series bool, autods int) (
 			return nil, "", err
 		}
 	}
-	if series && e.Root.Return() != parse.TypeSeries {
+	if series && e.Root.Return() != parse.TypeSeriesSet {
 		return nil, "", fmt.Errorf("need a series, got %T (%v)", e, e)
 	}
 	res, _, err := e.Execute(c.runHistory.Context, c.runHistory.GraphiteContext, c.runHistory.Logstash, c.runHistory.Cache, nil, c.runHistory.Start, autods, c.Alert.UnjoinedOK, c.schedule.Search, c.schedule.Conf.AlertSquelched(c.Alert), c.runHistory)
@@ -234,7 +234,7 @@ func (c *Context) eval(v interface{}, filter bool, series bool, autods int) (res
 	}
 	if series {
 		for _, k := range res {
-			if k.Type() != parse.TypeSeries {
+			if k.Type() != parse.TypeSeriesSet {
 				return nil, "", fmt.Errorf("need a series, got %v (%v)", k.Type(), k)
 			}
 		}
diff --git a/cmd/bosun/web/chart.go b/cmd/bosun/web/chart.go
index b8b20ab..1a79ea4 100644
--- a/cmd/bosun/web/chart.go
+++ b/cmd/bosun/web/chart.go
@@ -197,7 +197,7 @@ func ExprGraph(t miniprofiler.Timer, w http.ResponseWriter, r *http.Request) (in
 	e, err := expr.New(q, schedule.Conf.Funcs())
 	if err != nil {
 		return nil, err
-	} else if e.Root.Return() != parse.TypeSeries {
+	} else if e.Root.Return() != parse.TypeSeriesSet {
 		return nil, fmt.Errorf("egraph: requires an expression that returns a series")
 	}
 	// it may not strictly be necessary to recreate the contexts each time, but we do to be safe
diff --git a/cmd/bosun/web/search.go b/cmd/bosun/web/search.go
index 5e9b143..fb5433f 100644
--- a/cmd/bosun/web/search.go
+++ b/cmd/bosun/web/search.go
@@ -12,7 +12,17 @@ import (
 
 // UniqueMetrics returns a sorted list of available metrics.
 func UniqueMetrics(t miniprofiler.Timer, w http.ResponseWriter, r *http.Request) (interface{}, error) {
+	includeAll := r.FormValue("all") != ""
 	values := schedule.Search.UniqueMetrics()
+	if !includeAll {
+		filtered := []string{}
+		for _, v := range values {
+			if len(v) < 2 || v[0:2] != "__" {
+				filtered = append(filtered, v)
+			}
+		}
+		values = filtered
+	}
 	return values, nil
 }
 
diff --git a/cmd/bosun/web/static.go b/cmd/bosun/web/static.go
index 5794fed..b6417e3 100644
--- a/cmd/bosun/web/static.go
+++ b/cmd/bosun/web/static.go
@@ -5542,7 +5542,7 @@ var _escData = map[string]*_escFile{
 
 	"/js/bosun.js": {
 		local: "web/static/js/bosun.js",
-		size:  92796,
+		size:  92814,
 		compressed: "" +
 			"\x1f\x8b\b\x00\x00\tn\x88\x00\xff\xec\xbd{w\xdbF\x928\xfa\xf7\xe6S\xc0\x1c\xc7\x04c\t\x94\x948\x93\x91#\xfb:\xb6\xf3؉3Y\xdb\xc9\xce\xfcd\xad\x06$@\x12\x16\bP\x00(\x89c\xeb\xbbߪ\xean\xa0\xd1/\x80\x922\u05ff{\x16\xe7$\x16\x81\xea\xeaWuu\xbd\xbaz<\x1e{\xdf\x16\xf1,.\xe2l\x1a{\xab" +
 			"\xb0Z\x1c\r\xc2l\xbeN\xc3\"\x88\x82\xaa\x1cx\xe3'\x9f\xb9\xa0v\x8b|]\xc5=a\xcb0K\xaa\xe4_]\xe0\x93<\xafʪ\bW\x1dp\xcb|\x19gU/\xa0\xddh]\x84U\x92g\xbb\xb3\xbcX\x86]\x85\xa2/;\x00\xd6Y\x14\x17\xe54/\xa4\xbe\\\x84\x857\xc9\xcbu\xf6l\xb5\xf2\x8e<1\x8c\xcb<Z\xa7\xb1?\x14" +
@@ -5598,140 +5598,140 @@ var _escData = map[string]*_escFile{
 			"oLZ\x1b\x8046ZL\x8d\t]\xa7e\xe6\x93גM\x8b\x9c7\xba\xca]\x92\t\xe1\xeaR\xaf\xa9Ɉ\xae\x13\x93\xa2\xbb\x03s\xecD^7\xb3=,N\xe7a?m\xbe\xa5\x8e\x1b\x14[Bpd>\xb2#\xab\xf1N%\xb7>\bT\xeb\xd7\xcc~\xf0\xad\x14\xde߁\xff\xa0\x13\xbf\xbb|\x87\x99A\x1f\xbaO\xc7\xd0H\xb3\xc7" +
 			"Ҧ\"u\x98\x8aW\xb9\xad0P\x96\xbbh= 6\f\x12\xc73\x95'\x1e\xd41\x02\x04ciy\x8b\xf9t\xe0i\x03\xff{\r\xaf\x92=\\\xb6\xaaꂉ\xe0\x948٧<O\x9f(A\x86\x1b\x9e\x93O/Y\x1f\x1d\xfb1,\x8d\x92<\xa1\xd7\xf8:z\xf7yT2+\xd9GR\xec\xb0#\u007f\xea6\xe1F\xe6\xb1x\xf5\x1c" +
 			"\xb6c\xb7P\xf6\xaf\xcbv2$[֨\vt_\xa7\xe14\xf6\xc7\xfe\xf1·k\u007ft2\x1a\xcf1\xd6y\xff\xdd\x1a\x04\xf6\x89;\xff\x15\xba@p\xdbBy\xfaWL\x97Ԫ4\xc6L\x8b;\x9e1)\xd9E\x10\xc1\xa2\x10!\xba\xb8{\\\x04֩\xe8a\x8f\xad\xe7I7i\xb5\xab2\x8e5\x1d\xbd\xc6#\x89\xd4\xe4\xf6\x89\x04" +
-			"\xf1\x1d\xfa\x9b}\x87\x06&\xb4=\x9e\xd5Q\x9d\x83\x0f&+\xdd\x14\xedQ&\xe8k\x13t(\xc5{\x020;/\x84g\x17\xeb:M\xd2Ec\xaa\xacˠXִ\xf3\xa1\x87G\x99\xea\x96\xfc1~\xa8\xb0\ti\xddvK\x90d\x80\v\xe6\x84\xea\xda z\xb1Y\x01\xf5\xef\xe5\xac\x17A\x13#\xcb\xf8*\xfb\xa9/ꋀǽ\x12" +
-			"\xd8w\xf0\xf7\x1dr\xad\x8b?\x86a\xa9kH\xd7\xd1,\xfc\xa8\x89mTY\xb5\xc5\xcc\xdfc\x109(\x1fE<X\x11@{\xca\xeaY\xf9c\xb5L\xfdzX\xcd\xc2??)\xa4\xe4\xfc\xa3B\x98\x1f֒\xfbOB \x06\x98\x8a\x90\x12]v\xa8\xab\x04\xf9\xdf\xec\xa71\x04\x8escV\x90\x01t\x9fiig\x13\xefq\xac\xa5\xfb\xe0" +
-			"\xcam\x0e\xa8\xa45q\x88\x93\x17\x86\xb3\x13\x06\x1b\x80УDj5qXEɰ&\xc7ҙ\x93\xb8\xa9\x88\xe4\x13t\xec\xe5\xc0\x9c\x83@\xd7\xfc\tZ\xd2\xfb\xeb\xf4k\x8aNɲ<˃!\x9d\x93e\x9f̍\xe4\xa9\xe9\xfcv\x87\x82\ns\x05\xf7\x12\x1d\xa4\xd16\xe4\xb3\xed0\xb9\\\xb7\x92\x93\x9a\xb3\xaeݨ\x9e\xdf2\f" +
-			"b'w\x1a\xc6ұ\x8d\xad\xac\rK\x0e\x8e\xa1\x92\x03l\xc1Q~\xd9Ntp\x9f\U000a86a4\t\xf6\x05\v=\xa7\xb3+\xa0\xc9}i\xcc\xcc\xd8:Iǉ\xc20\xcdx~\xd6p\x98\x8e\xdawsjiwT1LO\x17\xf1\xf4\xect\x9a&\xd33\x16\xdbזR\xc4n\x85P\x9dQg-\\7\x13\xa8\xd4\xe6X\x8dr\x12" +
-			"\x81\xbc\xe6\xe2\xeckL,\xf8\x1c\x11Xcc:\x8c\x81\x16\x03\x8d\x1a)\f\xf2\xb3)\xb1\x8bش\xd9\x12\xbcy\xe2A]\x03\xb8c\xf9\u07fd\xb8:(B\xc1\xc5u\x04t\x86R6\x156\x84Ђ\xae]\xba\x9d\xb7\x9a\xa5\xfbN.b\u007fX\x95|\xbfv\x1d\xfbn\xfa\xd6NT>\xaeS\x00\xf3\xd3hj\xa2r\xcc\x01\"\xe7\xf6\xe6" +
-			";R\x9c\xc6\xcb\x1d\x0f\x93\xd1h\xa9U\xb9\xe9\xa3|C\xf9b\xdd\xea\x8d\xd4B\fs\xcbg\x04C\xc7\xffs\x92(T\x8e\xa8\xb2\"\xf9\x1c\xb96.(k\xae+\x1aݞ\x83Cm?T\x1a9\x95\xd0\xc0\x90\x1d\xa9\x88[\xc0\x15\xa5\xfc\x18\x1e)\xafY\xb6s\xfa\xd0\xf4`\xa7sR\xe4\xaao?3\xe4\xfbg\xb6\x8dD\x0f\xca\xc4G" +
-			"\xf8`$\x91_*\xa0\x13u\xf3\xf1װ\b\xb1\xe4\xe0\x01\xfa\xe3X\xce\n\x83*!4\x87\x01f^\xd9}\xf5j\xf7ŋ\xc1\x88\x92O<@,\xdd\xe5(M\xcb@\r\x8b\xb96P`w\xd2g\x89\x04z%~\xa6\x9a,\x14XW3[V\"\x95RS\xa3d\x1e\x15\xc9ej\x18\x90\xfe\x96I\x9a&e\fRcT\ni\x96" +
-			"\xac\xdc\xecϖ1\xf3\x82Y2\x15+\xa6H\xfd\x04u\x88\xa1\x1a\x96\xe5qy24\xe5\xach\x81E\xc7\xd1\xc9bq\xbc8Y.\x8f\x97'u\xa1\xebV\x97(iJ\xab;\r\x99\xc0{\xd9@L\xa7f(\xf4\x92\u007f־.K>\x16\x00\xc6,\xc5K\xe9k8\xcf%N\xcbLƙ\xf4\x86\xdc\xcf\f\xc3\x13\xc5V̋\xe2\xbf" +
-			"C\xb9ۊɖ\xe3K2oh\x18\x9c\xc6\xfcI\xb6\u007f\x9f\xa2Y\xa1\xc4\xc3\xd6Բ\x16 \bV\n\x80\xa3ak\xcc(\xd6\xddL\b+X\x9cq\x81M\x18\x93[ۏ>n>f\x1f\x17\x1f\x97\x1f\xcb\x11&\x00\x1a?n\x8d2\x87g\xb1$\"Y\xb8h\xacBM,\xc4\x1eW\f:2w\xbc\xe5\xf1\xc1Im;\x1aҡ" +
-			"\xf9W\xc3\x11M\xaf\x81g\x0e\xaa\x12'\xdax\x0e@\xe3\x957\xdd\x19\xee_\x92o\x97 \x02V\xe1N\xd7*u\x12\x9c\nȏ\f5Tk6~\x8a\x06\xbc\xcc\xc86f3\x81jK\x97sD\x90e\xc3TC2jӳ\x11Y\x13}'\x13\x14\x91\x93\xb9\x948|9\xa08,:\xed\xc2K\xf51\xbe6}\xcd\xd0\xc7}f\xeb" +
-			"(N\\\x80U\xf9dd\xe9\x83\xda\x11\x01@Gc\xd0j\xd5\xe4\x10\"\xa1\x9eG\x8b\xfb\xc3PU\xdb\x1b\xa4\x01\x9fA\xfd\xb4\xa4\x04\xb3\x00\xdd\fW1ϗsyy)g\xc1\xa6\x8c9\x97y\x91FSP\x04\xce0\xe4\xe3\x02t\x9c\x98]\xfe\xf54)\xf3#\xcb\xfd\"\x025\x8cw\xcd\t(OثW/^\xbc\xfd\xf1\xc7\xe5" +
-			"\xd2\xd1pQr\xf8`\xb5\u007f\xb4g\xa9A\xc4,\x00\xf2\x97!\xac\x84f\x13\xe5\x8do-\x87\x1d\xcf:cz\xa5t\x0e\x0f-\x8a\aļ\xc8\xf4van\x85)\x95\x1aC\bd\x80\x83\xe4ǪRD\xc5:tC\xbb@\x06\xcc\xe5M\x92M\xff\xbd܅j\xbc;\xf6Ҭ\x91%y\x94\u007f\xc1s2\x9d\x87\x87]c\x92\xe7i\x95" +
-			"\xac\xfe\xa81\x11\xa4\x16\xf3U\x87\xff\x1e\uf74c\x02^\xaf\xff\xc1\xa3\xad\x01?\x1ez\x83I^U\xf9r\xb0U\x17@\xce~\x1bN\xfa\x89\xd7\xdbw\x80\xf89\x8aq\xbc\xe5\xed\xa1\xa6\xe9\xe0&\bYO\xbc0\xc6\xde!#\x84O\xc1\xb4*ҿ\xc6\x1b۪\xb2\x05\x87\xea\xec\x0ft\xb8\xb7\x8b\xa4\xc4C\x95e\ue54bdV\xedR" +
-			"v^o\x1af\xde$\x86\u007f\xd6x\xfa\xac\xca=P\x81\xbd\xd0C\xdb=]4\xe5Ѡa\xc1)\xa8\xa1\xa06\"1\x99\xf0W\x8b\x98\x95Z\x85\xf3\xd8ڣ\x96A\x05\xbd4\xf8\x92\xdas'\xfd\x14WiHUِ\xd2]\x13\u007f9\xb4\xb3+@\x81\xd7\xea\xc00\xbd`\xe9\x15M\xcbL<8\xfb\x17\xb8\x11\x84,\x81\xa5\x1b\x92\xc5" +
-			"\x12\x13t)\xd2K\xbe\xc1w\xf6b\x021\x94\xba\x90\xfc9\x84\x89\xb4\x92w\x94ӣ\xfe\xc6>8\xf1\xb5\xabV\x9a\xf3\x92\x02\x87YC\x1f\xaaa\f\xf2\xe3\x8aP\xa61\xde\xff\xd2>\xc8tjLk\xc9=\xad)\u007f\\\x98\xf4'6\xcdTl=1β\xbbT\x1aR\xd4\x1c\x14\n\xf0ϟ\x84\u007f\x10\x83\xf7\xdd3؊\xd0ǲ" +
-			",H\x9f0\xb1\xd8DX\xa7\xe3c\xef]u2f\xe1\xeb\xf0\tc\xf0Y\xe8\xbesb\xdcm&\x9f2\xd6û\x8a\x95\xef@\xe5\xbb\xd4\f7\xf5v\xac\x86\fW\xc3e\xf9\a.\t\xc2/N\x14ܡ\xf4\x01\xdbT\x11\x97ɿ\xd0\xf0\xddo\xb3\x02p\xbc\v\xa9\xc2;\x13%\xb3\x8b\xd9D\x04\\\x1c\x8f\x96\x02\xec\x03\x8a\xddě" +
-			"zM\x86\x1ee\aD7'\xca\xe4=vB\xda\xeb\xea.\xa8ˉ\xbe\xe2\x1dg\x04\x11\xa3iQ\xb9\xda\fH`\x9dXO\x840\xab5\xef\x855\x95p\v\xcax\x86\xfb6\xf3\xf3\x16;\xf6&/*\xe6$k2\xbaI\xae\x05\xfe\xd2`\xfah7y{I\x03\x9f-«\xef\x93,5\n(\x1dP\x89\x99\x9b\v\xc3\x19\xecz\xe4" +
-			"\x00\xe0\xe7\x04s\xfc\x9a\x94Ǻ\xe3\xe6UoLz\xdc\xe5\xafp\x98\x8bQQ\xc5`g\xe32\x10y\x92\xeb\xac\xc7ї\xa4\x9apU\x88\x04\xe3\xc1\xe7\xff\x18\u007f\xbe\x1c\u007f\x1e\xed~\xfew\xe1\xabS\f\x1f\xe8\x15(\r\xb3$\x1b\x16G<Ĳ\x9d7\x97\x1dF(\xe6\t*Ȓ\xd9:_\x1dz\xfb{\xcdJ*\xf0`\u007f\xfb\x15" +
-			"\x13_\x0f\xbd/\xa5wi<\x03\xa8\x83G{\x9fI\x83sg\xda\x06\x9e\x04\xa5v*ItD\xccB\x9a\x86+%\xe7D\xb2\xe3\xd9\x02n\x14\xbc\xb0\x19@\xc9{\xed7f[\x86-\xcc\aEA\xac\f\xffh\xe3q\xafq\rS\x13$Թ\xe8M#\xc1\xb5\xb2a+N\r\xe8\x8f\xe5\"Qp\xd6cž\xfa\x1c\xdcƻ\xee9" +
-			"\xbe\xe3\xd3_\xce%\x9b\x05\xf4\x93\xb9-\x80\xf0\xf9\x8f\xba\x05\xe6\xc1\xbf\xc7\xc1\x1c9a\xb6k\x87\xc0\x87\\CbE\xe1\x8e7q#\xf7B\x94\xcfyFr\xb4d\x87E\xecO(Gl7\v\xc1\x87{\xd2\xea1\xe0\u007f\x99\xedl$+HP\xc12\\\xf9mM\xbb\x89_c\x82\x9d\xb1R\xc4\xc5S\xcd\xf6\xc1\x84Q_V<\x93\xb0" +
-			"`\u05fa\x00\xb2G{{ޘ\xb7\xd2*Q\xc8\x05\xc8ƾL2\xbf~\xb9\xe3}\xf5\xc8P\x93^(\xbc\x92\v\xed\x9b\n\xf1\xab\xb4~\x14\x05[\r\U000fe410>\xe4\f0@\aa\xfd\x83q73\u07ba5M\x05\xbb2\x92\xdd>H\xa0\xec\u007f\xe3\xed(\\\xdb\x0e\xe8\xaa\x14\x9b\x91\xf5\x92Cօ\xea*\x90\xe36\xbf\x88M" +
-			"\x9bQ\\\xbdA2\x95\xb6\x98\x12\u007f3\xd3K@\x99\xff|\xbcҋj2\x1d\xca!\x1cϮ\x12\xbeX\xf1B\x91\x10~\x19\xee\xf9\xc0\x87a\xf7Y\xa5\x16\x90\x1c\x88\x0fm\x93l\x94Lv>\x1a\x18<\x8b\xacݝ)\x8d\xa2'ߖ&L.\xe6\x1a\xed\xb7\xa65 \xed\xab\xc5\xf8x;\x81\x9b\x8b\xc6\x049tT\xdfQ9\xdd\x12" +
-			"\x82\x02\x00\xfa\x0f\xe8\a:+\xc93\"O\xfaCo\xb83T\xa9w82\x8d#MV\xbf\xca뛞\xae<\x9c^\xafJw\xf1\xdf\x1b\xb5x\x8f\xdaW/3s\xdb\x18\x89\x04Q\xbe\f\x81\x17\x1c\x1b\xab\x81\xf9EF\xc1ְ\xf5\"\x16\x06\x14\x05<\b[\x86\x9bJp\x8d\xc84\xe5I>\x90\xbf\xc1\u007fz\xe6\x18Q7\xf0\x9b\xee" +
-			"\xba\x01h\xab\xba\x85\x13\xc3^\xbdm\x19\xa6\xf1<&=n[\xba\x8f\x92\x8b\x9e\xb3\x0f\xd3\xcej1M\x19I\xad\xd0\xf4Ӻ!\xec\x8f\x1bWN6^6\u0098ʄ\x0f\"\xfei8\xfe#Z\xc0\xa4\x9b;m\x02\xee\x8b8\x8a\xe6\x15$.d\f\xae\x02גpށD\x10\xa8\xd3\xf9\xc4K-]û\x19\xf8\xfe\"\xaf[\x1d" +
-			"Xun\xf0\x1d}G\x8f77*\xa3\xf8P]\xf2\xddP\x01l\x8d\xb6\xceQ\xf3\xe9\x8a(\x16\x13Ns&\xe6\xcbQ\xc4t\x8bZ\v\xc0q\x05]\x1b\xaeE\xa6\xe6ň\xc4Kw\x11\xf2t\xbcƫ\x9d\x14\x8c\xf6[\xa6\x18\u007f\xf2\x9b\x95\x1b1\xa2\x1c\xf5A\x8bRw\"K\x1b\x9d%\xeaͤ\u007f\x11\xb1Y9ni\x94\x1f{\xbf" +
-			"j\xb7*\b\x14\xf6n[\xb4f{+\xd1P\xb2\xcc\xd7e\xbc\xcc/\xe2\x00G\xba\xfeuzջ\x9c~\x8b\x97\xb5\xa4\xcc\x19\xd8®O0ܰ\xf9\x14o6T\xeeC{\xefj\x03K\xba\xedѵ\xef\xa0\xd1QX\x03\xee\x81D\x99\xef\xed\x06<Yo\x1c\xb2ӜX\xf4\xc4\x18mh+\x98D\xdd\xf0\x0eE\xb6\xcbRݡ\xb5" +
-			"F\x0e\xfb\xa4݈\xcdUW\x96\xecЁa\xeb[\xb0\xf0!]\x13#\xb6\xfd\xc1\x9fX\xdapG\r\xf80M\xb3\v->\xd3<+\xf3\x14\x87c\xee\x0f\xb3\x1c\x17<І\xed\x14\xbd\xfct\x19\xfc\xf1\xb1\x8f\x17>\xf7\x81_T\xcb\x14\x98E\x1em\x86\xa3:\xc1\xc6ʏ\x83|6\x83\xa1\xf2\xd1\xec\xa3\x1e\xa7kU`]\x11\xfdt" +
-			"X}\xfbH\xc3I\x9cZwG\xda<p\x9f\xb5|w\xed\x14\xf5.\x81k\xbaC\"\x05\x88\xdd0\x9b.r\x8cA\x1e\xc6\xdae\xb9\n<r\xa5='D\x84 \xc3\xdd\xe0Q\xbct\xa3\x8a\x90S\r\x83\x83N\xc0\x8d\xcaP\xe4\v\x16}\xe4\x16\xc1\xa3\x91\xbcyXw\x1c\xc6\xe4,\xa2\xa9Y}\xd7筌W\xceIc\xf2\xd9m\xa6" +
-			"ͱ\xb9\xf7\x1e\x92\xfd\x9e#\xa2\xec\xa6\xfb\xb7\x9c}\xb1\xc7^:\xb4A\xf7>\xa7OA\xddQ\t\xcc\xca\xc9H\xfd\x06\x0e\xc6ե\x84\x02l|\xd4;\xb0\xb0_-@\x984\x8b\xae\xf8HҺ}\xa3c\xd1H\xb55ڿ2m\xf6\xb6\x04E\xf8X\xfc\x0f\x14[\xb9\xac~\xcb\x12:_{<\xc4\xf5qƂ\xe3\xe0\u007f?\xe0\xff" +
-			"\xde\xe2\xff~\xc5\xff\xbd\x1c\x9eH\xf1\x9d\x19\x14\xf4A\x9e\xc5+:A\xc1^\xcff\xc9\x15\x9e\x00\xacj\x131\xfe\rX韏\x1fk\xdb0\xc5Ez<\v\xee\xf7\xb0W\x01\x1a\xde\x1d\xca;W\xfe\x12\xfe\xe2gtD\x9f\xc7B\x97,\x12\x9a\x9d~\x1a\x1a\xac\xe9\xa5l8G$X'\xcb$\xd7PD&\x8cT,\xc3\\&\xd5y" +
-			"O\xba\xe5T\xa0\xa4\x0eyO\xbd\xe1\x1e\x1d\a\xe1\xbf\x0f\xe1\xf7\xd0\xd0X\xcc\x05\x98\x94\xdf'0\x921\xfc\xd6Ёt\xd1\xf4>\xf4\xa4\xa4wr;B\x8c\xe4\xdcWO5e\xeb\xe5\x84N\bQ\x99Y\x9a\xe7\x05\v\x83ō-\x1cyc\xaf\xfeE\x17\xf9J\xb4\x11b\xfa=\xfa\xba\xca/}6U\x12\x16\x86Y.@\xf9\xb78E" +
-			"\x1c\xb3Ϛ\x89\x9c\x0fő\xa7\x02\xd6ä\x91[\xddu\xecF\b\x1b\xdf\xf7\xc9U\x1c\xf9\x8fZ}\xff\xd6ۏw\x1f\xb5\xa6\x97C\x9b\xee\x15dW\xac\xa0\x8d)\x83\x92{8S \xc1\x1d\xd6\xe1\xb1\xe2Z:\x00y\xe8\xf9\x0f\xe9\xd6\aѺk\xfd\xca8$\xe7~\xf7ř\xdc9b1\xe0!\x1cX)x\x01\xa6`\xed\xaa\xab" +
-			"OT8\xd9T\xb13\x1a\xbfo\x8d\a_A\x8d\xdfa\x95\x1eQ6K\xa7\xebu֟\xb8OJlU\xfd\xa4w\xf5-\x0f\xdc\x0fE\xb8Z0/\xe7e\x92E\xf9%\xb2\x19D\xfd\xbd8\xa3$\xb9<\x19\xc4\x0eR\x9d~\xa0\xce\xe2-\xc3G\xf3\x98Q7t\xaf\x19>&\xcf\x19>\xcc{\xf6\xcd^C\u05cf\xd5\x111\xb8\xc5T\xef" +
-			"8>\xb8a\x1b\xceE\xe0öD\xcbG\xd8 \xe2\"\x04e\xde\xf2}R\xac\xcb\x05\xc5\x15 \xc0\x84\xe2\bl`/q\x96\x00\be/\x1d$\xa6Cq\xdf! @\xfd?\x06\x88exei\xc52\xc9\xdag;\xf0\xb9V\xc6\xf2F.i\xd5k\xf0\x90i%܄\t\xecw\xff\xd1\u07bf\xc1'\xe0p\x02\x98?m$\xe3>\xb3" +
-			"\xeb\xa3V\x16\x16\x8di_8K\x8c\"B\x97\u007f\xe0\xd6ހnS?\xf5b[\xf7¦\x8f{\x01W\x95\xd5V\aj=\xcf\b\x8b\xb6cX\xa8b\"\xc7\xde\xc1\xde\xc8Q\x8a\xcbH\r\x9b\xb0\x98ja\x1a\f\xd6D\x1e\xe2Ǩ\xab^t\xce0\xbfaX\xc4\xe1\xd0\x1e\x86F)=\x9b\xb1\x03`\x97\x16=\x81\xefg\xe6\xcf\xfc\"" +
-			"\xe6\xbe5\xe1\xaf\xee\xe0\x14|\xc8c\x88\v\xbe)L?ms|\xd5\xe1>\x02q\x9bʣ\xb1\f\xff\x8dMJ=6/\xd8Xt#F?~Di\xe8\x8cj\x12\x15\xbf\xb2\x14\xbf\x12\xc5\xe9\x1ezv4\xd6\xea+e\x97\xb9߹\xa7\xaa\xbf\xf3\xa9\xa5\xc7\f\xa1\xb5\x9f\xdb\xd6!s\xaaA\x83\xddm\xfb\xb7\xbb\xb1\xe8<G<+\x15" +
-			"\xcb8\xbe\xb26\x85\xc3L\xd3d\xf5+,sw\x93\x93\bۊ\xb0]\xf8\xbaU\xd9zb\xb8\x15w+K\xbf\v\xf1*\xa7\xb4M\xbb\x14\xefIΚ0M\xbb\xdc:\xc9j\x17o\xa8@h\xbc\x97\xf4O\xf8\xe6\x8e]\x85\u007f\x9c\x8b\xf0&m\xda\xf06\x99\x87\x1d\xc7\x02ɈYA\x9c.\x16\r\xa4\xe7\x900\xd6d@\b\x14ދ" +
-			"\x8c\xcaj\x83\x17\xdd\xe7\xabp\x9aT\x9bN\vE\xb7\r\xa3\x1b\x87J\xb3}8\x89\xb4\x96\xdd\x1d\x99\xae\x8b\x92Y\xe38\x05\xdb:.\x1b\xdc78\x8b\xec~\x19\xa73\xf4\xad\x85\xbb\xb6]\u007f\x169&ͧ\xb5\x03\xf1\xad4;\x962\b/:5C\xcb\x02\xf6\x89I\x19\x960\x19$\x05~C]\xefZ\xeaBZU\xa4U\xd8\xear" +
-			"\xf8\x86\xbbj\xe4\x0e\x131])ȏX\x1d\xc8lF:f\x97\xef\xa5,\xeb\x8b\x10;\xf3\"³\xfe\x8d\xdci\x9c\xe2\xe1\x9f\xe2\xaf\xf6\xc3\xfd\xa9A\xb6g\x9f\xbf\xfc\xf3\x9f\xe3\xc97\xd6\xcf_E\xe1\xec\xab\xd0\xfa\xf9/\xdf|\x15\x87_Z?\xcff\u007f\x9e\xed\xedY?\x87_?\xfa\xfa\xc0^\xf7\xec\xcf\xdf\xecOf\xf6\xba\xe91" +
-			"|\xb6\xc9\xddd\xbfC;\x87E\xb1\xa0\xef\x1b\xfb\xf7<\x8d\x1c\xa5\x17x\xa9\xfdv\xfbK\xcdèl\aw\xd27\xa3,\xcf\xe2\x8eBQR\xae\xd2p\xd3@;\xda\xfe+V\x00\x1d\xa0\x1f\xb2Xt8M\n\xa0Qw_\x90\x80m\xd1a\x84\xf15K\xab\xa4c\xef\xde\xe0A\xee\xc7\x04C\xc3\xcbER\xb9\xfb\xc0\x97\xbe^\x89ˏ" +
-			"!V}\x9eU\xbb\x14\xe0\x8eB\xdb\xc1\xea\xcaV\xd3,\x9f\xaeUɨ\xefLS\xd9\x1bδ\xc1\xae\x8d\xd8\xea6\xa0\x04m\x84Ҭ\xdfN\xdb\xf7\x8aGGK\xe6n\xb3\xfaR\xaf\xa7U\xa5\x9d`k\xc1l\x18\x8c-k\u007f\xe3\x1f\xb5%7\x13OT\x84\x97?\x13\xef\xb4i\\]ɬE'i\xb7\xfb?q\x91\xdb\x13\x9b\xd4\xc3" +
-			"&\xed\x8cց\x93\xf1ݫ\u007fX\xd4>\xe8E\u007f=\xae\xe93\xa0>\r\xaaE\x01\x9a=\xb4\xa4\xdb%+\xae\xf9,\xeb\xcdP\xf1Ba\x00Kg\xf8I33\u0590,\xba.٬\x8f\xe1Cm\xe8\x1f\x98b\x0f\x1db`\xed\x05%z\xe1\xac\xfa*\xa9\\5\x17|Q\x98q\x90\xe0\x92h\x0e!F\xfd\x962$\xb8\x90\x97g\xf8" +
-			"\x96%Nai\x16\xe8\xe0\xfeUb\x8b\xed \xed\x15kJ0\xcb\x10\x01\xa3;\x00\xf5]{\x81e\x92\xbd`W\xac\xb2\xd8U!\xe4;K\xfcBW\xce\xc1\x1f\xcfQ\xaep\x82\xfe\x9d\xe0\xfe\xe1\x18`\xfb\xc8\xc6\x18*\xd53\x96\x84\xc5q ?\x99`ΐʏxB<\xd7),r\xda@\xa1'\xc0\xb2\b\xbc#X\xbd.G\x15" +
-			"\xb5\x8ax\xbb\xaeco\xee\xabS\xe2\x96\x18\xe8\xe0\x99\xa2\x00c\xb2T\xfd1\xb4\xc5q\x9f\t]\xd0a\xbd\\W<\xb1P\xfe\x92\x8a\u0381\x11\xbb툌\x88\x19\x85\xb2\xe5\x8b*aM\xa6ܧ\xc0\x90t`a\xbdi\x1c\xa6>\xed\x06\xb5\x95\xa6GY\xdc\x1e6u\xd9\xcef\xb3B\xf5ES\xe59,\xc6\xda%\x86-\xd9\xe5;\xd3" +
-			"\x0ee\vp\xe2\xc2G*\xbb\x11e7X\xb6G\xe0\n\xb6\xe3[\xb1\x02\xfbİ4\x8b\x15\x8av\a\xae\xe0\xf2#X\xc3\xdd\xfb\x06\xd8\u007f\x10\xac!)\xb2\x01\x96\xe7{Ug߱O+\b\x9es\x8d\x844\x13NE\x1dCf_D\x96[{\x1cL[(OX\xbb5\xa4\xb0\xdd6\xeb\x0eE\xf2bז㲲\xe14\xd5\xe6" +
-			"5\x9c\a\x9b\x81\xa5\xae\x8d\xa4\xedZ\xf4d\x02\xae\x18TW9\x94p\xed-e)\x1c\xd8\xe4v\x8f]\xbfj\x89/\x97\xaf\xb9Ӆ\xba\xfa\x84o5c5\xa3|\xbb\xccw\xe4\x83`\x85\xfe\x01\x85\x1a\x83\xff\x8d;\xd8X`D\x93\x9ez\xbb\x8f\xbcC\xd0=\xba\nQ\x84\xa8h\x13\x94\xfa\x06J\xedw\x17k\xc775\xb5R\xa4\x13\xfa" +
-			"\xa7\x99k\xce1x\x19\xa50hz\x17d\x96KvE\x81ɄrHE谨\xbe\xfb.\xbf\xb2\x01\u05caU\x9f\x01\x9bL\x02䍖\xf8\x1ce\xa0\x00x\xd3\v\xb8\x89\xa2\x9d\x04\xb5q\xf1\xa0w$-\x94\x12RˁK\xfe\xa2$&\xc8\xd4\xed*ĕ K\x17\x1f\xb6(\xf0\xf8\x98Y\x10S\xb1D@:S\xb1:G{" +
-			"\x1fz抷\xe5`\a\xbd\xc06\xfbvk\xa2\fv\u0c80\xe3CY5\xae*\x10\xc4߰\x93\xefnY\x8cέ5\xe0n\t\x85\x01\xe2\x99\xf7{\xadR\x9d\x01\xae\x94\xe0\a(\x8dR\xb4\n$\xee]\x84\x97\xf1\x9b\"/0\x8f\x15\xcfUf+e\xdf{\x1a\xfb\x1f\xb1O\x9b\xe8fP-w\xbcG&\x11\xa7}6\x14U'" +
-			"ۑP|\xc8ጁ1JN\x1b\x1e х\xbf[\x0f\xe4{\xe1\xa5\xfd\xe0\x1bt\x84\x9d\xaf\xdf\xf1\f\xb7\xa9\xe3s\x19L\x12fF\xe7\x16\x92\xeej\xbb\u008cM\x9b\xb1\x94\xbe\x18\xeb\xb1\xe3\xee{\xa4\x0f\x1f\xb2/\x88\x02\xdfZ\xaea\x11\x8f+T\xd8LB\xb7<1\x88\x0f\xd7,{\x9c\r$ht\u07b7\x8f\xfd\xd9;~\x8f" +
-			"멎.\xd7v\x1c\xc1\x89-j\x90\xb9\xfbd\x053\x1f\xe5\xb3z\xbdKc\xac\xa7\xab\xb7,|@H\x1d_\xdb\x14\x8b\xedL+n\x83.\xd3B\x99b\xc7\xfen%\xedmY@\xd0\xfe\x05\x04M3\xee\xa0j~\xf0\xdbx@\x1e\x1f\x9a0\xf5\xea\xb7\v\x8aF\xbc\x10Z\xaa\xed\x1e!\xf1lO\xc0b\xad\xf5\x19\xb6\xba+l\xa4]" +
-			"\xfd\xe8g\xd2۾\xb9$\x0f\xb0C\x8c\x18\xe3j7\x16\xb2S\x8a=\xecW\xe28\xe3\v\x05H>O8\xe5S\x8c\xffq\xe5\xd6\xec\x98\x10U\x87W=\xab\xa6ӌwR\xb5þz\x0fi\xdd5\x0f|-\xf0\x81\xb5\xea\x80\xe6)i\x9f,\xe58\x1c\xe2\xdcfIsw\xd73\xb4_\x0f\x93\xab\xea\xf0\x8aW}\x973ԧj\x9e" +
-			"mӧ&\xec\xd2 \xa0u\xcf\x14熏\xf3\x8ap\xf1p\x9c[ql\x1a\xfd\xdd#*k.G-|\xe8\x82\xc0\xc6\xd5fnW\x03\t\x10+|\xe2f[uì\xf2\xb9\xbdC\xf8Է\xa3Qۿ\xedSY\xe8P\x06\xec\x95ٙҦaJؓ\x1d\xaa±&\x1bF\xff\v\xc5[sjD\xb2p5\x9eWC\xf7" +
-			"\xf5\x8a\xb0I(\xb3\r\x05\xb8j\x0f\xafzվ/\xd7\x1eZ\xd42\v\xfd\xb5\xb8\xc5\xc6\xc9-\x1a\xdfP\x1d\xbb\x87; \v\xd1s\xb5\x93E\xa3\xed\xf1\xc0E\u007f\xcfz\x9c\xd2*\xd4\xf4;\x84\x8cO\xf7Ad\x82r\x1eF\xd6j\xdd\xdce\xad\x9b\x8eZ{\x1c\xf7\"d$\xb6\r\xc8\xf92\xd8\xf1\x06\x1b:\x816\xe8,P\x9bΰ" +
-			"P\x91W(\x04\xed\xfeeo\xd4]r\x03%v;\x03_\xa4\x02WX\xc0o,M\x96\xc8R\xa9D\x84u\f\xf6㥫5\xa4\x19\x9e\x06\xeb,9\x976\rg>\x17<J\x81\x1b\xc2(x\x9f\x03\x9d\x0f\x1e{Zzw\xf1 \xf78_\x8b{\x05(d\xaa}Я\xc3\xecpG\x8e\xba-\x83e\xf1\xe9\x150\x8b\x0f\xef^\xa7" +
-			"\x1b\xb0\xee\x93 ɕ=\x96\xb0\rO\x1aEY\x15\xf9Y\xdc\xdf\x1e\xdc\x17o\xedo옊\xbaX\xdb\xc4z+\xeb\xb4x\x1c\x91\xc4\xf8tF\x13\xe3\xf3\xff\xafi؆\xa5\xd7=\xbf\x953\x98c\xe92\xc6E֮S\x107\x93&{\xe55\x90\xbd\x0et\x9f\xcfm\xf7\x83\x18V,3d\x86\xb6\x90#K\xf5\x8aӃ\xdb\x1e|" +
-			"\xa6Y\xd4y\f\x1a\r\x82\ueff0\xbbA\xe4s\xb1\xb4\xcb\xf28Ύ\xad\x8c\xa0\\\xbe\x8d\x86o\xf6Kq\xd1+\x14\x93\xe0\xebc\xa7\x14\xae\xd5\xc7\x06\x86\x0f\vF\xd2\x03\xb2&\x98\xc0\xddJý\x9a\xb16\x1fqۦ\x15\xb6Тލ\xc0\xd5\"\x1f\xc0\xddj\xb6\x81\x1cɀ\xeb\x9a%\xde暥`X\xe1\xacG\x01d\xbd" +
-			"\xbbML\xef0\xd8?xԧ\x9eE\xb8\x8aw\v`z1\x1dO\xc50\xf5\x02\xc6\xebe4\xb7Ǚ\xf4Ԟ\xdd\xf1K:\xdf2\x1b\xa6\x9cF\xf9\x06\xc0hGo>\xbf0\xeav51\xf1s\x1e\xce\xe0\"\x86\b\x036\x10\x98O\xa5\x8dsJ\xad\xf6\xe8J\xc2\x18\x8f\x1c\xb2\xb7\xf6\xe3ԍ_A+c\r\x14\x90|\x02\xed\xab" +
-			"(x\x1a\xfc\xa6<\xbfԢ\xf5\x1a\x9ab\x13Ӻ\xc3\xcf\x1auE:uG\xd9*o\xe0\x1f\xe1\xd7\xfd\xd4\a\x01\xfb\xfac\xa4rl\xe0z\xf8U\xfa\xe4\x04\xe9\x1b[\xb7\x841\xc7t,x\xb9\xc4\xf8ի\xf1\x8b\x17\xbbt\xbb\xd1!l\xdd\x0e\x8a\x13\xd3k\r\x12j\xa5Z\x050\x9eQ\x8f\xdfe\x81\xb5nq\x8a^K'k\xbb" +
-			"\xe6\xf2\xe5ժ\xe8{\xc3\xe5\xf0~\x01<9\xeeu\xd7%\xfcI\xc0\xea\xa9\xd7^w^RD\xf8\xba\x00.%\xd1\x01\xe6Cm\x8f\x1c\aA\xe7R\x95O|~\xb5e\f=\x92p5c2\rY:|u\x02\x1a4\xf2=qM9\xb2Tq \xb5\xac~_!V\x8f\x9e_\xbc\x86j\x18^\xcc\xfds\u007f\x10b\x1c0\xcc\xffa" +
-			"\x0e\x83\xbfZ\u007fX\xe4eu\xf4\x05\xcd\xcb\x17ר\x9e=\"\xd5\x11\xaf\xd4z\xe2}\xb37TW\xa8jE\xd6\xees\x8c\xd8M\xc5|\x04\xe8\xd7Ǐ\xa6{@\xf1@f\x03H\xbf̀\xd8\r\x8c~QgA\xbb[\xdb\x06Q\x85\x13\xa9\"\xf8\x81\xf5\xf0\xdb\xea\xf4\xea\fW\x12\xaa\xd7\x11b\x8b\x9e\x9e\x1f\xa9w(\x1b\xae\x00\xab\xe7" +
-			"\xaa\r9dw\x9c\xb9\xaf\x8f'/\xa6V\x90.9\xeb\xb8w\x9e\x92Z\xb5\xca\xf5\xbc߸\xbe\xb4\x14\xc7\xc6\xe3\xf7\xd9\xf2\xcb\x01\x1f\x9b \x1b]\x9a@\xff\x8b\xfd4\x822\xa4\xa7\x98\x99B\x80\xbfݬ\x94p\xe0\xfaN\xf9\xb7\x04vԄ\x9d\xda/W,/\xe6\xa7\xf2\xfd\xd6\xf1\x1c\x0fǏq\x8c\x88\xf4\x9b9\x00\xd1\x04\x80\x9ff" +
-			"\xf9%\x8d\xa0\x94\xcf\x01Ӂ\x05\x19\xde\xc5£@\r\f\x8eWG\xd8\xe9,\xe1s\x94\xb4|y\x8c\x94R\xd7\xc6q\xa8鵵ƕ\xf9\xeau\x0ft\xf7\xcd\xf5[\xd5\xd9}\xa5\xa5\xe5\x9azY\x9f\x16 1ݠe\xc7\xe4\xe4V\xd2\xcaW\x19\x90^\x10\xd7Is)\xab\xe08\x86+Y\xf5\xa2\xb8R\x9a\xa2\x82\a\x99\x8a\xd2\x0e" +
-			"\x12\xe8\xd7\x00\x9bn\xc0\x16\x94\x01\x14o\xba\x8dF\x10б\"\xbb\xaa\x89\x0f\v%7'f\xe12z\x96\xc8\xe5\xc1.\xbbVq\x9a\xf0F\xc1\xef\x98\xf6\xa8u\xa7Q\x98\xeex\x951}\x00>D\xe2+<\xd6|\xfc\xb0\x82F\x01\xb8I$4\x99U\xea\x05\xddé\xba]\x9e팅U\x0e?\x18D\x1d\xbd\xcb?`\xda9\xb9\xcb" +
-			"U8\xbf\x80>\x87s\xebe\x05\xd8t\xacD4\xfdI;\xc1\x8c\xfaP{0^f\xc7\x12\x1bc\xb6\x96\x88bؒ\xfa\xc6-l\\\xbf\xf1\xadk\xbd6\xd4ʤ\x1cΠ\xcd-\u007fAY5Ȗi\xfc\x8e\x86\xa3C\xaaEo\x8e^!\x916\x85Yӆ\xab\xef\x05j\x17\xb8\xa4I\xe5\x1cB\xc5\x1fsItêTA\xdc" +
-			",\xbd\xe2p\xbe\r\xe7o\x88\xb5\x19\xb8d\xfd\x86\x01\xd5\xef[\x97C\xb2o\x98\xdb\xc5oP\xfeލ\xf0w+\xba\xdfed\xaf\x81\xfd\xfdm\x85\x85\xca\x0e\x9c\x12\xa4\x19\xb5\x04 ׀{\xfc\xa6\x037\xc1\xf8\xe7\xf2\xa0c\xa8~\x10\xce\xe7E<g\xbe%\xef\x1cյs\xf9\x1d\xcae\xe5z)Q2\x95Z\xc6x\x8dJS\x82\xff" +
-			"V\xa4E\x02-\x98\xf4\xc9\x01\v\xbe\x17(\xe7\x8ej\xc8f\xa0\xa4\x02\xe2%n\x04\xf1e{\x14d*\xa3\"\xf7\xce\x03\xb4^\\\x84\x98\x98G\xa5\xb1\xf1\xd8\xc3kN\xf8\xf5\xbf\xb1\xd7@\xd2m]\u07b9F\xb9\xf7ꦙ\xe8\x95>JH`\xd5\xcf\xc3\xf5<V\xaf8n\v\xa5\xc2]\xab\xf6\x1at\xafuf\xb8]\xdfR\x13\x87\xee" +
-			"\xae\xab\x176l\x87\x15U\xf3\x97\x01\xa1\x8e\x8cϝ\xf4\x0e)#\\W\xb9Q\x87b\b\xa4I\x8fJ#)E%\xd7Pj0\x93\x8eB\xa0\xc0\xae%|\xf4\x8bS\x8fX\xed-p`8/J\x99\xe5\xd4o\xeb.\xb43v\xd1r\nVE^\xe5(>3\x04V\xf1\xaa\x9el\xdebL\a\xc7~\xaaS\xcd^\x03c-\xc3\xe5\x8a" +
-			"\x12\xe5\xc8\xe5DfW\xfe\xce4\x96\xd6\xf9\x91q\xea\xaa,g\xaa\xa6n\xc9\x13k\xee\x1eKXu%\x1ak\xa0\xe8W\xb2\x97\\f\v\xdd|@Y\xf1\xf2$\t\x9f\x9dB\x80\x9a\n\x8f~\xba\x01b\x1d\xe8\x0e\"\xb91\xe6T\xb6\x06\xd7\x13\xc3\xc8\xfbv#\xa4\xb6\x81ں\xc0+\x1awc\x14\x82V\x04\xc4\u05f8\xfa\x9d\xdf\x06f\b" +
-			"\x9b\xb1\xf6\x94xZG?-'I\x15\x9c-j\xe3\xbb\x1a\x11]kǌA\x89-\xbb\xb6t\x0e\xe5k[\x9a\xb8Ln\xb8\xbf\xd8mn\x8d\xae?7\n\xb2\x10\xcdY\xa38>\x89\xfaW\xa0\xa4\xb9\xa9\xfe\x141r\xba\x97\xd4\x0e\xf9\x9a\xb8=vG\x9c\\\xb5\xb8\xb8\x84.\x85\xb3\xdc\xee)\xe4d\xb9\xdcqr\xd2\xe7\x1aY\xf2\xa8c" +
-			"էJa}v\xea\x15ĒSZ\x833\x19\x19\xb0\xa4\x95\x06:\x10\x0fm\x98V$\xe2\x89\xe24\x06\x929O\x8e\xcf\x1c\xa7\xad\\1\xebV_0k\xe7$\xcf\xd38\xcc>\xfd\x86\xe6\x93\xf7\xf1\xb4\xeah\xe7\xdf\b\beg\xbc(\xbeo(\xec\x1f\xd8\xfe\x1e\x17\xc2\xe1?Bfe\xcbJ^ߤ[\xbc\x8eg\xc0\x8f\x16\x1d\x16" +
-			"hʪ\xb8\xbd\t\xdar\xd3\\\x879z\xc73\xddE'\x8c\x90\xb5PL\xacc\x00R1\x9ae\x97IF\xff\x84\x18|\x83\xb6\\\xfc'\x8a/\xf0\x9f\u007f%\xcb\x1aj)\x00\x93\faO4\xf3LT\xaa5 \xf8]ׂ\xcc\xfa4\xaf7\xd7\xe3\x01\neX\x82\xb1\xf8\x9dfW\xdb\xe1[\xa6\x8ec\x1afϠ\x94\u05fe\"m" +
-			"+\xfb\xfd\xfb\xc6\xfa\xfb\xbe\x94\xaf<''\x12\xfb0\xf9\xfa+\x95\xc0\xdf+\xd6|\x041\tA\x94\x9d\xb5\xdeD\xde{O\xbd\xff|\xf3\xb7_\x02\xca\xd2\xeb\xbf\x1fy\x87L\xaa\x10\x94\xa9\xf4/\xc1\vA=\x9e\xd4\x17\xef\xddoz\xb3\b1\x91\x1c\x05\xa5\xef\x19\x8c\xda\xf3\x8bR\xb1\xf8\b\x85\x16/\x13\x8cNѢ`\x81@.\xbd9" +
-			"])\x1fu\x03\x14ۣ8O\x97\x89\xfb\xdcp\xfbF\x1b7\xbb{\x0e{.\x94A\xb7\xbd\x90o\xa3\xa2β\xedy\x13\x06A\xf2\xb2\t\x98X\xf6\xb3\x89\x85\x03\xb4B\xc2=\x9f4\xfe\xfb\x1el\xd0$3\xe8\xf6\xfe\x82\xb1\x86\xa6H\xfd\xe2\b\x031\xd6r\x11\x89`(\xa6\xd88\x00,\xb6\xf6a\x03g\"\x1a\x19S\xa8Y\xf5\xee\xd7" +
-			"\xe1\x9e2\xa6PK\x0f,\xc8O\xdc\xe6\u007f\xba\fW\x9a\xa9gP\x0e\x0e\xf1\u007fm\x03\xcf`\x89o\x97\xea\xdb\x05\xbe]\xa8o#|\x1b\xa9o/\xf1\xed\xa5\xfa6÷\xafԷ\x1b|\xbb\x194\xedo/Ѥ|Mw\xfd\x8f\xff\xc7\u007f\x17=\x1c\xf9\xef.G(M\xdd\x1f\x1b̫\x00\xf96\u007f6)\xfd\xa5:lm\xbf\xa5p" +
-			"[\x96\xebIU\x84\xd3ʗ\xf2f/\xd1)\xbd\xd3\x1a\xb7\xe3\xe5\xf1\xc1\xc9I\xed\xe54.\xf5\xba\rP\xfd\xdb\x1c\x1a\xe2k:\xd5x\xfcK^y\xec\xe2WZ\xd4hw\ai\a\xef\xe1&\xb5\x8a_\x83\xe9}\x9f\xa3_\x9f\x94\xa4\x1d\xef\xfd\x1a\x98\xc7\xe0`o\xff\xab\x81w\x99\xa4)\xde\xfd}\x11\xa6I;\xb5\xb9\xc8Z!߁" +
-			"\xb9#~\xf1\xa84\x96\xc4s\xd4\\.o4\xb8U\xce\u07bd\xb9\fW\x94\x13C\xeb\x1d;ob\x12\x05\xccc\xaf\x0ff\xbbJ\xd1+<\xbbL4\x10\xc4W\xf1T;\x19\x88\xd5j\xb3-\xd5*\x91\x84\xab&\x0e-M\x9e\xc3\xe6\xf8\x86\xa4U\x1c\x06\xbb\xaa-\x81\v\x06V\x8f\x9d\xfc^\xf5&\xc8\xdcL-\x00o\xcd\xfe\x05\xfe\xfdY" +
-			"\x14\xbd%\x87fg\x93\xc4\xd6\xd2f\xccƋ\f\x15\x10\xb2\xf5\u05fc\xdb\xd9\x1cP\xf2~\xe2\xf5HW\x94v\xb4(qa\xfc!\xaeކ\xf3\xbf~\xb7y%\xec~\x12bD`AN;\xe21A\x88\xad\x87YGeX\"6\x81Wݱ\xa8(7/\xea\x04x\x8f}pX\x92\xb9\xacr\xcc\x00\xed\xf7\u0558\x1c\x1d\x8a\xafP\xf1" +
-			"8\xe3^N\x1eM\xde\x06\reO\a\xaf\x18\x82s[\xef\xf5\xc6\x12\xd3a\x06.\x93EK<\xc2,{\xcaa\xd5\vm\xf11\xa9\xaa\x92sȨ\xa2\xca\xcd\xe0\xb1I\xa1Q\xbb\xd4\x1aq\xdcqc\x10\x19q\xc9Z\xe7Rm\x1aL\f\x16\xfe6\xa3\xb3\x1f\x00\xb9\xc7\xcb\xf5\xabf\xb8\x95\xfb\x88-\x96\xdfKr\x0f\xd2\xe2\xe8R\xa1\xf0" +
-			"Q%=\xd65\xcd#\x88\x97K9\x9cc\x00\xd3\xd9%@\x81\x9d\x02о\xbd2y\xb9΅\x89\x15\xff\xd1?\x8f\xf1\"\x87\xb3\xd8+\xd7E\xecaD\v\xec%^\x98^\x86\x9b\x92\xf6\xddYR\xc0;(\x1b\xd8V\xae,27,DV\x86\x89N\xf4\xaa\xed巹|\x97]\xe3\x80\x02'\xb6\xdey܆\xefa\xbb[\x1dD\xab" +
-			"\x9d\x00\x93\xad*٪\x8e\xfa\x02a\xe5\xf2\xe0\x1e\x8ebC\xf8k\xbf\x00\b|\x94 \x88\xe1o\x14\x0f\xe8\x81\xca8\x8b\xd1\xdc\xc48Bɒ\xee\x18B$\xd4ƨ\xac\x17ʇ\xc8t\xc6\xf0\xea)Cvt\x87\x9c\xb8\xd1o-6M͗\xad\x9c;q\xacB\xbeH\x03\xb1\x91\x1e\x89\xad\xef\xc1\x03\\\x91,!ёpǸO" +
-			"\x9f\x88V\xda\xf9i\xbf\xa5l\xdd*\xf9\x9b\x1bQF\x0f\xba\x80\u007f\xed\xf3~\xddV\xf1\x8c\x02\x93\xd1\b֒\xc9\xcc:\x83\x81\x9e\xa0\xc7\xc3\xdb\xc4gq\x92满\xacW\u007f\xd65R\x9dAD[\xad\x1fy\f\xebj\xea-\xe9LlIj\x8d\xbapsA\xc2\r\x05@\xd0_.\xc9\xecVK\x8e\xc4\r\xe2\xccvڔ\x05\xc9\xe3" +
-			"\xb3\x13m\x98\rC\xdd\u007f\xb8o;\xe4\xea\xb0\x1b\xd47\x18Y\x93\xbb\x02\x9f\xc6Ne\xb4II \xb5B#\xeb1fH\xa6\xc74\xeaK\x1bJ\xe5_\xed\xa9\x959\xd9\xca4V$@\xad\x02\xbb\xec\xcdZ\xb2M\xe4\xd0y\xcb0e\xbaIP\x92y\x99\xe8\xe1\x10I\\B\xb1\xe6_Q\xa5,\x8bSEt\xfc\x029\xb5\x15\xa2i\x06" +
-			"\xa3RCȐy\x10L|Y1\xf61\x15\xf0\\ۨ\x8dքB\xa5#M\x99\x16A#v\x9dU\xdcq%\x13\xefM\t\xe9\xdc\xc2xD=K\x9aWIUЇ\x83)|\xb7\xa7\xb7nI\xfb\fs \xc2K\x17\x1d,\x8f\x01\xc0\xa9?l\x9f݃\xfbk\x8a\xc6eǘ,\xd1\x13V\xd7GnSȁ91Չ\xd3" +
-			"\xe3.'_\u007f%B=\xc9V\xce|}\xc9l\xe3\x17ڙ\x10\xbd4\xb3\xe96q\x9b\xdc\xc6\xfb\xd4[C\x0ffI\x16G\x98-\x8e\x99{;\x91qko\x83M\x98\u007f\x9fr\xeb/\xe0\xaa\xf1\x8e\f\xc6\x04\xb2\xf6jg\xfc\x1b[\xf0\b05\xbf\xa4;\xd9\xd01\xb0NS\x03J2\xfbZQ\xa2\xb9\xf8\xa9d\"\xeeB\xa9\xf7\x19" +
-			"\xda\xc1\xb2\x11v\x8e\x0e\xa0\xa7\xfb\x10T\xb5\xb2O<l\xb3ט\xd74-1\x95혓\xca\xdaO\x1dЭ\x80\xc2\xe6\xaf\xd2\xc3\xf0\x01\xfb\x93\xe4\xf5\xfb\xfe\xf0Ot6n8\x12Y\xac\xa4K\xef\xf0\x917P&2\xc3\xffC\u07fc\xf5X\xd5\x04\xbey˪\x82!T\x9f#\xbd\x95,\xa3\xfak\tN\x92V\xad\u1a8d\x18\x19" +
-			"J\x028YV\xf8\xcf.\xd6v+\xf1G\xbe^x\xf0\x92\x84 \x18\xc7\n\r\xe5b\x14\xc9Tĕ\x95A\xa3lm+\x06\xf9Y\xfe\x9a\x85\xbek\xd3\xc7}\xaf\xa8\x88L\xe3ԗ\xbd\xc4\x06\xe3\xf3=+\"i<\xa5({\x0e쌖\x13\xa4\xcbCZT\xbb\x8f4I\x06s\x9aɔf^KV\xab\x1a\xf6K)r\x9c\x9c\xb4" +
-			"b\xeb\x8ex\x1c\x9d\x8d\x90\xea\xe6c\x04\xf2\x03\xf1\x8bh>\xe9\xb3;\xb6\x17\x9a\xa11\xe6y\xbf\x19\x13\x1e>\x80?:\x8eδ9\xb4\xca \xea\xea\xfa0h\xa8.\xbcꪮŽM\xd5\xd9\x0f%\xd1W\x85\t\x11\x15?\xc5:q\x8b\xb5Un\xdcw\xd9؏\xe8(9g\xa0\x0f\xa5\xf9\xa5!~H;\xc1mX\x96\xf1\x80\xd1" +
-			"\x1bC\xa08>\xb4\xf0Z%:\x18\xdaeX\x88\x05\xf8K\xee\xbd\xd6Nx\x99\t\b\x1fK\xe4\xaa\x19w/\x8c[\x1c\x90\x92\a\xc6xPG\x01\xaa\xf5FK\xc8\xff\xba\x15\x13\x11N\xcaߊԤ\xee\"\xdc\x1aݣ@\x06\xfe\xde\x0e\xfcM\"\xe0\xdff\xfe\xf0\xe9\x90\xe5\x14xj\xa8bM\xab]\xd0W\x13\x1c\xd1E8\xd6\xfe\xb0" +
-			"\xc3[\xeb?N\xc16\xa8н\xc6\xdcԆ\xeeCR\x12j\xf5\xa0\x94x$#\x13\x177m\x94-\xefK8\xad|\xdbjWO[\x1d\xcb'\xcaR\xa5\x1aϯu\x9dz7o\xa7\xcd;\xac\x84\x84j\x11\x9b\\\x9f\xe8ծ\xa7\xfd5_\xadW\xae;r?HR\"\xf3\x95\x1f\xe25\xd9MЀ\xf1\x1aX \x94\xf6%\xa9\xd2" +
-			"\x05\xa9U\xbc\\a\xc6\f\x00\xf8v\xb2\xae*\xa8\x94r\x98\x1c\r&U\x06\xaaF\xb6\xcb\x1d\xe4\x03Z\x89\xbb\x8bj\x99\x1e\rp\xd0\xf8\v(=\xa5|\xb0P\x82RW\x0f\x9e\xc4\xc0֣o\xc7\f\xdd\x13\xa9u\xdb\xdf\xc4Jy.Y\xb3\x8eP\x14e\u007f\x0fY\x19e\xb2ZYg\t\x1b.\x11y4\xe1\xa7\xd5Vb\xf9\xd6\f~" +
-			"_3IŮ\xf8\x19~\x9bd\xabuEW\x8aÀ\xc1ˁ\x97g\xcf\xf123\xf8\xc9\"\xd7)\xd7\xc4\xe8\xf1\x00j\b\xa3<K7G\x03\xf1\xd7\xc0\xa3K\xf6\x8f\x06\x0f\xd2\xeaq\xe8-\x80ޏ\x1e\x9c\xaf\xf3\xea1r\x0f\\\xfa\xc0f؋\as\xf8\x0f\xa0\x92\xe5\xdc+\x8b\xa9\x01,Xe\xf3#\xf8\xaf\r?\x0e\xf1\xaf\xc1" +
-			"\x13\x03\xafb\xc3\x1c\xac\xf2\x15f\xe5\xf0\xcdÂ!\x800\xef\x87\xd4㭔\xde֝\xf0\xe6\xa5\xf0,\x8d\x8b\xea\xc7\x048A\xb1\xe9\xb7\"\x04%\xffF\xd4>^\x81ʒ\xc0\xb2\x1b\x87\x88i\xc10\x05H\xbeC\xadv[`#\xaf\xff\x93<]\x8f\xaa\x8b\"ඳ\xe6\xb1\xe4\xac|\x9fA\x97dW\x14s\x03ڲ\xb5\x99V" +
-			"\x05V~|a\xf6\x13\x9b\xf9\xa1AR $M\xa5:\xb6\xb6\xba\n\x13\x1a.KŽ\x88\xff\x1b9\xb2\x9c\r\xc33\x9b8wA\xe9\x8dX\xee\xb3ს\xe3\xdczY\x85պ$\xf9\x905\xe2FN\b6\xbb\xb8\xe4\xe3蔈\xd2\xe4\xef\xeft[\x01\xa34Z6\x89\x89ѐ\x86gV\x93\xd7\x16\x9c,\xe0į\f.\xee" +
-			"\xb8\xde\"x\xcb\xce\xf8H\x11U\xec\x9d%K\x98ګ\x1a\xbbܵ\x85!8R\xee]\x82\x99\x9fA_k\x9a\xd6}\x95\xce\"x\x99E\xbc\xb1u\xb9c\xc2tB\r\xde\xc6\xf4\xe7\x90vպ\xa4\x81韬\xc4\x00\xa9\x10\fέ\x16\xa8(\x1e\u07bbCi\x80\x8a\x18\xd8w\x19\x1b\xd2m]\xbbM\x92\xaa\x8dDiǨ9\xdc" +
-			"k\fp\x17\xea\x17\x02\x9fr\xdeK\x91\xa2-,.\xf5\xd42֪(\x0f\xfa\xca+\xdc\xefQ\x10}\xc6\xd6\xd4\xf7\xf9:\x8b\xec\x87\xe4\xba}}\xdd\xe9\x02$\x16\xa5\tuֽ$/\xabOn#\xe1]\xa3؏:\x90\x17\u007fi z\xda\x11\x1dĐ/d\x80\xbc\xb3\x1ch\xb0\x89\xe1\xe0=\xff4+\xed\xdf\x1a\x0f\xae\xfcQJ" +
-			"6\xf3\xdb\xeb\x9f[]^\xb7U8\x81\x06\x05і[EsY\b\xbf\x8a\xe4\xefSW\xb2\xee\x13S\x00Λ#\xb8K\xf5\x8b\b\xf7\xe2Q%\x87\xad\xa9\xb8V\xfd\x03N\xef\x92\xf0&\x19\xad\xc9M\xb8\xa1\x1a\xfd\xd8#\x13\x0eL\xe2P\xbfެ5ݕ\xb9V\xa3\xf3~\x8c\x9d\x93\xfd\xd4\xf8\xfb\xee\x1c\xfaHo2Y\\+\x12\x93" +
-			"\xf0\xcc:\xe3\x9c\xeb\\\\\xad\xa40\x06cw\x1bZ\x93\x92\xf8\xd5\xd2U\\\xa0\xe62f\xe1\xd9\xd1\xc7\xcd\xc7\xec\xe3\xe2\xe3\xf2cIq\xdac\x83\x8d\x8c\xce4P9\x16\xd3{a\x9em\x11\xbd,\x1aP\x9f\x83\xe0!\xda\x18\x95\r쟴3\u007fHL\xe5U++\x913Ң\x89\xdc\xc1Ь#\x9c\xa7\a\xe8\xde\xef\xb0\xcb\xd1|" +
-			"\xderBC\xbe\xfaO\x03~ɛ*\x01\x19e\x84\xf6\xa8\xe0\xc4&L\x1e\x81\x1d\xca\xe0\x82\xbf\xb6\x9c\xaah\xb9Ej7\xc8\xfe\xde\xdeP\xe16\xab\xf5\xa9\x83;\xd0g5\x12\xa0\xcd3\x19\x88ṯվ\x86\xa5\xe8]eD\x0f*\x0eKEe\xb8_\xb81E\x1f6\a\xd0u0dA\x87(\xcd\xc1\xac)\xfc\xc7f\xce9\xb1" +
-			"/qɆ\x8a\xa7\x85l\x94\xa2\xd8Oi\x18$\xe3鍈\x87%\xa2oL\xa2v\x02qI\x1c\x12\x82\xe3\xbd\x13\x1e\xe4\xe5\r\u007f\x8d\x8b)\xe6\x16\xfb\xad\x8cU\xa9B\xc4d\xad\xd66\x93\xacJ[\xcbx\xe9\xa2\x1b\xfa\xec\xa6\x1b\x06\xd2\xda\x0fl\xc4\"\be\x90c.\x88eP\xe5U\x98*\aL\xfa\xd0\xc0\xf5Hk\xe2\x8d\xea_" +
-			"\xc3\b\u07b6\xfa\xbb\xa1:\xeaħGu\xfb5\xd5\r\x90\xda\x06Fjö\xd3Lz\xfc~It\x86\xb0\xb4\x88\xe8\xc3\xdeQ\xe9\xf8\x85\x9e\x06\xbc}3\f\xbb\x19¼\xc7Cețڍ\xb4l\xb1\xc6\xf0\xb4d\x06\xfb\xcf\x18\b \x8b\xab`\xb2\xa9\xe2\xf2)\xa5λ\v!\xa0KUN\xac\x99\x9fd!T\xa4\xdd1\xebT" +
-			",\x8fO\xb2\xad\xfaT7\"ô\xec\x8e\xfcSB\x0e\xd6Zd6~\xdfK\x84\xa0#ɻ\xf74\x81\xf7\x8e2E\xc5\xd5)M\x99\x8be\x89G\x02v30S\x01\xdb6\xd8\xc0ڷC\xf1\xc8ܦ&\xb6\x81\xfd\n\x1c\xca\xe6H\x06'7\f\xcfˀ\\\x8ao\xa5\xbc\x94\xd7dj8\xf4\xf6e\x9b\xba\xfaX\xb9\x1c\x10(\xae" +
-			"\x8fCF\x06\x01\xbb\xf3\x98\x9bA\xf3\f\xfa\xf2Š\xffţ\x06\x92\xb9\x1bn)͔\x95g\x8ag\v\x9f&>}xh=\x19[\x87j\x99\x18\x04\xafH\xcd~n\xad\x95eB\xf7\uaad8\x15N\xba\x92X\xe9q\xb4\x02\x86\v\x13\xb8\xc2\xcbG\xbe\xf0\xbe9q\xa7̧\x1co4\xe9\xb5\x03qPO\xfe\x11\xe8\xf4\x83\x11\xae\xed" +
-			"]g\xfa\xb4[\xb6qw\xbf\xa3\x91\f\xbfؖ\xb0Qv؎\xcbo\xba:!*I\xb2\xad\xeb\xb0\xf5@c\xab\xf5H\xb9\x1c薴\xe2=}\x98\xf8\b\xb6\x8fv\xc6>\a9>\xd3\n\xef\xd9\xce}\x9bv\xd9()\xcfp\x93\xc5\u007f\x83Y\x19\x94+\xe0*LJ\xf8\x14\xb6[f\xbcŨ\x98q\x14_\x8c\xcb\xc5\xd2\x1a\x19\xb3" +
-			"\xdd\x0e5\xeb\xb55\xcdz\xefI\xb3\xb2\xafl+\x1ey\xd71\x8c\xbee\xffql\b\x88\x04\xf6\x03\xa3y\xd8ַ;j\xb1A>\xbf\xfb\x06\xb7\x8c|w\"{\x11\xd6;\xd9\xe8f\xff\xd7\xedpf\xedah\xd0U\xc5C\x1e\xea?\\}\x90k\x9b\x9e^PmJ[\tq\x99&\xd3؇\x1d\x0e\xaa\xb2^J@\xa64\xa6\x85\x13" +
-			"\x8d\xe2\xa1'\xc29\xe6=\xa1+\a\x9d\x1b\x80Dn\x81\xe8=\xfdۻ\x94\xe8\x05\xfdۻ\x94\xd2l\xf9go\x1c|ǲ+a\xe2qz\xdc{\xfb)~ʦI\x04\x8d\xfc\xe4|\x15L]j<\f\x894\x84\\7\xea\xf0\xdc\f\x96\x98.\xa2\\#\xb5{\t\xef'\xe2\fK\xba7g\xc3ܻ1f\xd61\x19]\xfb\x18O" +
-			"\x05\xdarL\xd9T˧I\xc4\xe2:\xa3\xdb\xd8E\xeb\xc6\xf2e$&ɨ\xb4\xb3\x8a\x05\xe8K\xfae\x04\f\xa7\"\xc5\x10A>\x9b*\xe9:\xff?\xf3\x95\xfdT\xc5\xcb\xd2A\x80\x16Jk%\x84\xfa\xbf\xe3\xf8 \v-\xb8\xcd\xf9A\xa3@\x88[\xf3\xd3\x12\xa8&>\xe2\xe1[\xb7\xea9\xa2\xfbw\xf5\x9b\xear\xf6ZN*\xecu" +
-			"&\x00\xb6\xe6\xff\x95\x93\x9d\xbd\xf8\xb5\x03ы_\xcdx^\xfc*\xd08\t\xfa\u05f5\x9b\x9fv\xb3P\x8do6\x87.\xc9n\u008f\xd3)^\xd1h\xc5\xc5cl\xa7\xf8\x10\xad\x823\xdd\r\xa6\xa7\x9c\xe15D+\xaa Z9\x8c\xff\x9f\xe8\xea\xba\xf5\xe1\\\x91\xd3f=Y&\xee\xc4\xfc\x8ed\xf2ҩȮh\x1fiR\xfb\x9cw" +
-			"\xa4\xb3\x8e0\x99t\xfd\xb65S\"\x9dL\x030:\xeb\x18\x98\x12\xa4[\xc5\x06G\x1b\x81,\xb6i\"\x1e\x9d\xb77\x91\x86\x88]-)ܘ\x8d'\x0f\x8ac\x96\xfdh\x82\xb7M\xd4y\x9a\x18\xb9\x0e\xff\xae]\xb5\"\x9e&\xfb~\xb7ѰE\x83\x0eC\x1ef5\xaa\xc2\xe5\xea\x10\xdac\a\xbb`6A)o\x16v\xbd\xcb>\x88\xff" +
-			"\xefm\xdcpO\x99\x1e\xa1]\x12\x05\xd3Y!\x1a\x97 0\xfb\xb2\xf8\x92\xb5\x9f\xab\xb1\x05\xd13\x8e\xb0\x02\xe6\xcdY\u008a\xf2:҂\xd7Zo\xe0\f\xfd\xce\aك\xfb\xa5\x86\x93\xc0̖l\xa5\xe9Aw\x11\x1f\xbf\xd5i\x03\xfa\x97\xfd\x02\xfa*\xcbp\ue297\xd4X\x0f\xa5H\x98w\xb2\x9e4,e\xeb\x06\xaex\xe9o\x11\xad" +
-			"\xb5\xeb\xa9:\x16.O,\xcbV(\xfde\\\xa42\xb2\xda\xcc\x00\r\xb3\x1a\xb2\x8c=\xa1mv\x9b\x8e\x00\x939n\xfe\xbc}7\xac{\xa2xZ{#q\x1f\x86Vg@a\x14\xf9\xfb\x8fv\xf0\xa6\x1d\xd8\xe9\xa3rh\xcb\xda&\r\x01\xf6\x81F/ROϻ\x06ΕثG\x8e\x8839\xe2\xe6\x0eRA\x90\xae\xa5\x86\x19\x13" +
-			"\xf0\xed\x8dz\x9dB\x8dxn\x9b\x12K\xa4r 9\xd0\x04T\x11\x1d8\xb3fik\xa2\xc7\xf5n\x9fL\xfa\x8b\xbe\xaa؛\x04Ft\x1a\u007fr\xd6\x009\xbdFc\x13p\xa5?\x15\x97\xcb\x19\xb2\x9f\x8a(\xaa\x06J\xbc\xd1@)r\xb5\x81\xa3\x9f\x1a\x90З\xa4\x80\xcaR\x03\xe2D^\xc7K\xceu\x908J\xa4\xba\xf0\x97\x06\x02\v" +
-			"a\x1eK@\xec\xb7b\x19\x91\xc6\x01/\xdfPzm\x11\x9e\xa5A\x19\xee/\x8cwB\xb4\xce\fw\xb1\xa2\x92Q\x12F\x95\x19n9\xdd\xfe0$ǧk\f\xd4\xc6?\xf6\x18\x9c\xf9\x8cü}#\x8e<:(\x93\x18\xf7;N\x05\xb2\xe4\xcf\xee\xca\x18\x05\xe5*M`\xf0v\xd4d\f\xd2)8\xa2,S\x17\x1a\xa6449\x80J" +
-			"\x8e||\xec\xed|<y8\x16\xc7 >j\xd2t\x9b\u007fI\xe9\xe4Dx\x9e\xf9\xdc\xc5\x05z.\a\x03ݷ(\xe9Iz\xabi\xf9\x1e\xb6ֶ.5\x03\x15\x1fJ+\xdb\x10\xfe\xc6\t\xf7P\xa5d\x1d\x94\x96\xefakm\xdb\xe2\xe4\xa8\xcfl\x94`F\f͂\xd5y(/\\\x1d\x84\xad\xcdCe\xe9J\t3\xd0\x02\xdf\x1e}" +
-			"\x93\x19RU\x90[\xcc3\xcc6\n;Drjx\x9f\xf4\xab^\xe0\xcd+\xc6ݚߌ\x915\xbf\x05yZ\x98\r\x8f\xb2\xa5s\xf95\xd1k,k\xba\x00\xe9\xc1~e\x83\x04\x19%%nq\xb07͒b\xa9\x9f\x0fj\xb39\xe8z\x87\x1d\xc0\x90\xe4CU[\x04\x97*cT_\xa83\xb7\x97\x96\\\x0e\"\xb1\x18\xbc\xa1\x8fW" +
-			"]\x8f\x86\x87,\xa3\x9d\xc9\xcde\x17\x98@-}\xf3\xc9\xf1C\xa9q\xee\xd9\xd6\x02ωp\x9b\xdc25\x1d\xf7\xba\x9d\x10\xa8\xbc)\xcaI\xbeWA\xb1 \xa4[\x11\xa5%\xd2\v\x05- )ŎXO\xbd\n\xd3jk\n\u05cb\xafߝ\x8c\xb04\xa5;\x19\xc5eJ}\x8a\xb2e\xdc\x14\xe6\x8c\xe9\xe6W:\x8a\x85^\xaf\xdb\xce" +
-			"\x95\xeeX\xa1F\n\xd7\xe1h\xa9JU\xaa9\xe8\t\xd7\xcdV\xfb\x9d.\x14\x1d\xbd\b+\x811w\x0fg\n\xf3\xd5\x1aL\xdd\xe3E\xec\xe62ɢ\xfcR\x8c\x85?|N\x05\xe9\x16\x1c\xdea\xcaS\xa0\xb7\xbfG\x82\xe5\x1b3Tj=\f\xf2\a/\x890\xe0\xed\x8fgI7\x1fi~\xd8\xc9q\bV\x1c\xd5\xe0F\xf4\x8b\x91\xe9\xa8" +
-			"\x9f8\x94`ʍ\xaf\xea_\xfa\x01\xe8\xe9\x19]\xbe\xd9\xef\xf03\xb5[=\xf7\x1fN\xcf\xe8\xdc\u007f[\x12\x99#V\xd4\x12\x8f\xe4J\xdaki\xba\x88\xa3u\x1a\x1bJ\xe3ЄY\x14\xb1\x94\x01\xee\x9c\x02\xdaI\xec\xe9\x19U\xceNa\xdf&-\x00_\x10a\x06\x1dx\xc3\x0f\x15\xa2\xd8\xc3ݚg\x14l\xf4K\x1cG\xa5\a\x10Y~" +
-			"\x99\xc6ќ\xb2\x14(\x1c\x81\x95X\x85Y\x9c>Ǵ\a5\x92\xfb\x98\x857\xab\xa4O\xa6\x82\x98\x12F+\x82/M\xc0,\x00E\x03g\xafM\x05\xca\x05\xbb\xbcS\xf5\x1a\b\ue6a6\xe1\xaal\x13\xaa\xf1p\x8c\x84\x8d]/r\xaf\xfd\xe6\xb1K\xe6\x14\xbc'\x99\xb6O̱\xdbB\xad1_\xed6R\b\xb4.\xcfH\xb7\x8e\x96\x8b" +
-			"dV\xfd5ޠ\x82\xca[ǉ\x10\xe4\xc5xz\xf6St\x85*E\x93R\xceaܡ\x02\x12A0\x8a?\xb6\xa0=\t8\xbc\xd9\xca#\x9f\x1cc\x013\xa0\x02@wvl\xcdt\x84\xc20C\x84\b\xbb\xb9\t\x96\x96\u074bY;\xd0\xf6u\x84\xa8\x9dF/1\xdc\x14\x87g\x993\xf9A\x1bP\x92\xd9r\x16\xe3c\x8f\xf6l\x8d" +
-			"zR\x8f/FϸF\xda\x10Af#e\x8d4\xa8O:Z\x06\xbe^E\x86$PF:g'\x94[\x84\xce\xdbl\x1a0\x93\x15R\xee|\x1fk\xe4\r\x06\xcb6,[\xf4\x93\x81:%\xb3\x06\x18\xf8\xec\xf34/c\x89Ӛ\xd3Y\xd7\xe0ߓ\x04\xd9\x13\x1e\xf46\tҒ\xce\xfb.\x86\x9a\xae5S\xb9\x82ͺK\x92\xd4" +
-			"<p̾x\xdcKżLL=w_\xb90\xa7\xf8\x9c\v\xba\x97t\x1e\xbca\xf1\x13x?\xd3:\xc3\r.\x1bj\x1fH(r\xa6'\xb7N\xafe\x12\xec\xfda-4\xb4\xaaW\xf5\x1a\xb9lU\xffu7\xb9/\xd7)\x88 SnΔ\xce@oV\xc6+\x83)\x1d\x18\xa5\xd7\x02!\x96`\x9fR\x1e\x1f\xba\xd7\x15\xfeЛ" +
-			"\xa6%S\x91hL\x96\xe0\xe8\x8d3X\x94\x89H=\xe8n\xfbpQ\x9a%BO\xb9\x12\xfej\xbf\xa7\x02\x1f\xca\x1e\x84\xc7`\xcf\xe2\x8d-\x82V\xc1\xb6Mc\xd4\x11c\xa8\x9e/\x924\x02\xb9h\xa7Ł\xe1\xddm[JH:[\xda#X\x1f\x1f.\u007fC\xbd=xm\x93\xff\xc2\xcdle\xa2\xe3eLy\xe4\xfe\x97\xd2\xfe\x97\xd2" +
-			"Z\x94fΦ5\x03\xbe\x05\x14D\xb64`\xca\xccyW\xbb\xec\xce\xe9\xff\xe5T\xf1\xd4q\x0f\xdd9\x99\x824\xc7\xdc\x14\x06/\xf6\xf4\x1b%\xc9\xfd\x18\xabY9j\xb4\xf4Y\xa3x\xa4\x10^\xb0\xeb\xba\xd4n\xb3\x04\xb6\x82\xee\x02a\b\x8f\xf7\f!X!\xea/y\xa0^\x96*\xb2x\xe4\xc1\xb9ɒ\xa1e\x81\xb2'\x94\n\xcfn" +
-			"\x97\x97\xb8G\xea'kN\xfb\x8b\xe0m\xbeF\xa9X\xb2I\x88WFۄ\xadRcf&Wͼv9\xed\x91\xcf~;뵝غ\bx\x04H\x93\xadI\xcd\xf7d\x88\xff\x10\x0f\x8b6\xe3\x81\xcc,\xe6\x8c\xff\xe8HX\xd4T\xff3T\xffLH\nuq\x8d\xa2\xea~Xz\xf1\x1aԓ\xdf83'C\xdc\x1c\x8f\xa3X" +
-			"\xebe\x86ck\xaa2\xc6M\xf0x\xc7ȅ\xe4\x01\xde^\xf8B\xa4\x126\"\xa2p\x16\x9c\x1da\x94\x1a\xfc\x03\x9e\xddW\xafv_\xbc\x18\x8c\xba\xb1c\xd1m\xb0\xff\xf8\xe3\xe1r9p\x9d\x0fa;\x97!nR<:\x89\x92\xcdj\x1b\x02\xe5:\x029D\xf1\xb6\x94\xc1\x11f\xc7VS\xab\x88\xc7F\x9b\xf5\xa6֟\x9a\x04\x19О" +
-			"!\xecb\xa7\x84Ĺ\xd1I\xaeƭ\xb6\xba\x8b\xe0\xbb<ڰ\x00\xaa8\x00\x8d\x02\x88\xb9\xfc\xb1Z\xa6>\xfbbAF\x9c\xddz\x1b\x86\xf9j\xb1\".\xf3\xf4\"\xf6YYL:\xd7m\x80e\xf6],\x8b\xa9\xc5n\x9c&V\xec\x1bd42\x1e\xf9c[\x8e\xda u\xcfćo\xb0҅c\x1a%\xd57\xff\x9d\xe3m\xa1q" +
-			"\xa1\"F\xbahF\xc1\xd0\xde\x1e\x83\xd5\xfae9.+\xba͂Z1\xb7\xe1\xf0\x10\xb65\xd8\xc9\xcf\xe1\x8fs\xe3<\x99\xb7Y\xeb\x91b\xe3\xc0\xe9\r4\xde\x0fz\x8e\xb7\xf2/\x93R\xf7\xd0:\xccܨ2\xc6$\x9c\xd4r\x8a\x1c9D\xef\xe4\xc6j\x96o|\x9c\xa9?\x99cH19㳽\xd9\x19\x1f&ng줝p" +
-			"h\xcb\x02\x9f\xcd́\xfe2\x165jV\xf4yg}\x13\xceQP-\xe2LZ\x15\xa55\xa7ws\xbe\x82\x1ah\xb8]\xc7\xd4$\x8b\xc2}-φ\xe5\xc20|h\xa0\t\xe0vՙ2 r\x9b~o\xdd\x1d\x1f\x9e \x15=C:\x83mf\xd0\xd2Z\x91;Ԩ\xfaSB]!\xfd\x9f\x99\xa6\xdb\xe0\xb8gU\xfe\xeb\xb2t" +
-			"{\x95\xc4Cڙ\xf5\xab\xdcĭ.\xbd\x14\xb19u^\xb0\xb1\u007f\xbc\xf3\xe1\xda\x1f\x9d\x8c\xc6s\xd4\a\xf6߭\x0f\xf6\xf6&j\xc0\x91\xa1SZ\xbc\xaaۓu\xab\x9c\xd6\x0ew\x92%\x9f\xaf\xd6\x04\xb2o\xfd!\x8d\x98\"\xe6\xbe\xcd\xf8^8\xda\xef\xbe\x1d\xccg\xaf7\xe4\xff\r\x00\x00\xff\xff\x9f-\xcc\xd3|j\x01\x00",
+			"\xf1\x1d\xfa\x9b}\x87\x06&\xb4=\x9e\xd5Q\x9d\x83\x0f&+\xdd\x14\xedQ&\xe8k\x13t(\xc5{\x020;/\x84g\x17\xeb:M\xd2Ec\xaa\xacˠXִ\xf3\xa1\x87G\x99\xea\x96\xfc1~\xa8\xb0\ti\xddvK\x90d\x80\v\xe6\x84\xea\xda z\xb1Y\x01\xf5\xef\xe5\xac\x17A\x13#\xcb\xf8*\xfb\xa9/ꋀǽ\xe2" +
+			"\x91\x80\x00\xb4\x9d\xb2zV\xfeX-S\xc66\xbf\x83\x8fw\xc9\xc7.\xfe\x18\x16\xa6\xae*]k\xb3p\xa8&\xdaQe\xde\x16\xc3\u007f\x8fa\xe5\xa0ێ\xab\xd0`\xd8\xd9!%\v \x15\u008c\xb1\x96l\x80\x12\x021\xc0T\x84\xd4\xea\xb2C\x81%\xc8\xfff?\x8dAq\x9c?\xb3\x82\f\xa0\xfb\x94K;\xbfx\x8f\x83.\xddGYn" +
+			"sd%\xad\x89C\x9c\xc50\x9c\xa60X\x05\x84f%\x92\xad\x89\xe3+J\xce59\xbaΜ\xd6ME$\x9f\xa9c/\a\xe6\xac\x04\xba-\x80\xa0%K@\x9d\x90M\xd12Y\xdegy0\xa4\x93\xb3쓹\x91<Y\x9d\xdf\xeePPa\xf6\xe0^\u00844چ\f\xb7\x1dF\x98\xebV\xbaRs\x1e\xb6\x1b\xd5\xf3[\x86a\xed" +
+			"\xe4`\xc3\xe8:\xb6Օ\xb5\xa9\xc9\xc11Tr\x80M9\xca/۩\x0f\xeeSfU\x93|\xc1\xbe`\xa1\xe7t\x9a\x05t\xbb/\x8d\xb9\x1a[g\xeb8Q\x18\xa6\x19O\xd4\x1a\x8e\xd7Q\xfbnN-\xed\x8e*\xa6\xea\xe9\"\x9e\x9e\x9dN\xd3dzƢ\xfd\xdar\x8bؿ\x10\xaa3\x0e\xad\x85\xebf\"\x96\xda\x1c\xab\x99N\"\x90" +
+			"\xd7\\\xc0}\x8d\xa9\x06\x9f#\x02k\xb4L\x87y\xd0b\xb2Qc\x87A\xa26\xa5z\x11\xdb8[\x827OE\xa8\xeb\x04w\xac\x11\xb8\x17W\aE(\xb8\xb8ր\xeeQʯ\u0086\x10ZеK\xb73Y\xb3\x04\xe0\xc9E\xec\x0f\xab\x92\xef\u05ee\x83\xe0M\xdfک\xcb\xc7uR`~>MM]\x8eYA\xe4l\xdf|G" +
+			"\x8a\xd3x\xb9\xe3az\x1a-\xd9*7\x86\x94o(\x83\xac[\xe1\x91Z\x88\x81o\xf9\x8c`(!@N\x12\x85\xca\x11UV$\x9f,\xd7\xc6\x05\xa5\xcfuE\xa3\xdbsp\xa8\xed\x87J#\xa7\x12\x1a\x18\xb2#\x15q\v\xb8\xa2$ \xc3#\xe55\xcb\u007fN\x1f\x9a\x1e\xectN\x8a\\\xf5\xedg\x86\xa2\x01\x98\xb5#\xd1\xc34\xf1\x11^" +
+			"\x19I\t\x90\n\xe8D\xdd|\xfc5,B,9x\x80\x1e:\x96\xc5\u00a0\\\b]b\x80\xb9Xv_\xbd\xda}\xf1b0\xa2t\x14\x0f\x10Kw9J\xdc2P\x03e\xae\r\x14\u061d\x06Z\"\x81^\xa9\xa0\xa9&\v\x05\xd6\xd5̖\x95H\xae\xd4\xd4(\x19LE\xba\x99\x1a\x06\xa4\xbfe\x92\xa6I\x19\x83\xd4\x18\x95B\x9a%\xbb" +
+			"7\xfb\xb3e\u07bc`\xb6MŮ)\x92AA\x1db\xa8\x86ey\\\x9e\fMY,Z`\xd1qt\xb2X\x1c/N\x96\xcb\xe3\xe5I]\xe8\xba\xd5%J\xa3\xd2\xeaNC&\xf0^6\x19\xd39\x1a\n\xc6䟵\xaf˒\x8f\x05\x801\xdb\xf1R\xfa\x1a\xces\x89\xd32#r&\xbd!\x874\xc3\xf0D\xb1\x1e\xf3\xa2\xf8\xefP" +
+			"\xee\xb6b\xc4\xe5\xf8\x92\xcc\x1b\x1a\x06\xa71\x88\x927\xc0\xa7\xf8V(\xf1\xb05\xb5\xac\x05\b\x82\x95\x02\xe0h\xd8\x1a3\x8a~7\x13\xc2\n\x16g\\`\x13\xc6\xe4\xe8\xf6\xa3\x8f\x9b\x8f\xd9\xc7\xc5\xc7\xe5\xc7r\x84)\x81Ə[\xa3\xcc\xe1Yt\x89H\x1f.\x1a\xabP\x13\v\xba\xc7\x15\x83\xae\xcd\x1doy|pR[\x93\x86t\x8c\xfe" +
+			"\xd5pD\xd3k\xe0\x99\x83\xaaĉ6\x9e\f\xd0x\xe5Mw\x86\xfb\x97\xe4\xed%\x88\x80U\xb8ӵJ\x9d\x04\xa7\x02\xf2CD\r՚͡\xa2\x01/3\xb2\x96ٌ\xa2\xda\xd2\xe5\x1c\x11d\xd90Ր\x8c\xda\xf4lD\xd6\xc4\xe3\xc9\x04E\xe4d.%\x8ec\x0e(2\x8bο\xf0R}̱M_3\xf4z\x9f\xd9:\x8a" +
+			"\x13\x17`U>\x99]\xfa\xa0v\xc4\x04\xd0a\x19\xb4c5Y\x85H\xa8\xe7\xf1\xe3\xfe0T\xd5\xf6\x06i\xc0gP??)\xc1,@7\xc3U\xcc3\xe8\\^^\xcay\xb1)\x87\xcee^\xa4\xd1\x14\x14\x813\f\x02\xb9\x00\x1d'fׁ=M\xca\xfc\xc8r\xe3\x88@\r\xe3]s\x02\xca\x1c\xf6\xeaՋ\x17o\u007f\xfcq\xb9t" +
+			"4\\\x94\x1c>X\xed\x1f\xedYj\x10Q\f\x80\xfce\b+\xa1\xd9Dy\xe3[\xcbaǳΘ^)\x9d\xccC\x1b\xe3\x011/2\xc6]\x98[aJ\xae\xc6\x10\x02\x19\xe0 \xf9\xb1\xaa\x14Q\xb1\x0e\xdd\xd0.\x90\x01sy\x93d\xd3\u007f/w\xa1\x1a\uf3bd4kdI>\xe6_\xf0\xe4L\xe7qbט\xe4yZ%\xab" +
+			"?jL\x04\xa9\xc5|\xd5\xe1\xbf\xc7{'\xa3\x80\xd7\xeb\u007f\xf0hk\xc0\x8f\x87\xde`\x92WU\xbe\x1cl\xd5\x05\x90\xb3߆\x93~\xe2\xf5\xf6\x1d ~\x8eb\x1coy{\xa8i:\xb8\tB\xd6\x13/\x8c\xd1x\xc8\b\xe1S0\xad\x8a\xf4\xaf\xf1ƶ\xaal\xe1\xa2:\xfb\x03\x1d\xee\xed\")\xf1\x98e\x99{\xe5\"\x99U\xbb\x94\xaf" +
+			"כ\x86\x997\x89\xe1\x9f5\x9eG\xabr\x0fT`/\xf4КOWOy4hXp\nj(\xa8\x8dHL&\xfc\xd5\"f\xa5V\xe1<\xb6\xf6\xa8ePA\xbf\r\xbe\xa4\xf6\xdcI?\xc5\xe5\x1aRU6\xa4t\xfb\xc4_\x0e\xed\xec\nP\xe0E;0L/X\xc2E\xd32\x13\x0f\xce\xfe\x05n\x04!Ki\xe9\x86d\xd1\xc5" +
+			"\x04]\x8a\x84\x93o\U0001df58@\f\xa5.$\x0f\x0fa\"\xad\xe4\x1de\xf9\xa8\xbf\xb1\x0fN|\xed\xaa\x95漤Pb\xd6Їj`\x83\xfc\xb8b\x96i\x8c\xf7\xbf\xb4\x0f2\x9d#\xd3ZrOk\xca\x1f\x178\xfd\x89M3\x15[O\x8c\xb3\xec.\x95\x86\x14G\a\x85\x02\xfc\xf3'\xe11\xc4p~\xf7\f\xb6b\xf6\xb1,\v" +
+			"\xdb'L,Z\x11\xd6\xe9\xf8\xd8{W\x9d\x8cY@;|¨|\x16\xcc\xef\x9c\x18w\x9b\xc9ˌ\xf5\xf0\xaeb\xe5;P\xf9.5\xc3M\xbd\x1d\xab!\xc3\xd5pY\xfe\x81K\x82\xf0\x8b3\x06w(}\xc06U\xc4e\xf2/4|\xf7۬\x00\x1coG\xaa\xf0\x16E\xc9\xecb6\x11\x01\x17\xc7æ\x00\xfb\x80\xa29\xf1\xee^" +
+			"\x93\xa1G\xd9\x01\xd1\xf1\x892y\x8f\x9d\x90\xf6\xba\xba\v\xear\xa2\xafx\xeb\x19A\xc4hZT.;\x03\x12X'\xd63\"\xccj\xcd{aM.܂2\x9e\xea\xbe\xcd\xfc\xbcŎ\xbdɋ\x8a9ɚ\x1co\x92k\x81\xbf4\x98>\xdaM\xde^\xd2\xc0g\x8b\x80\xeb\xfb$K\x8d\x02J\x10Tb.\xe7\xc2p*\xbb\x1e9\x00" +
+			"\xf89\xc1\xac\xbf&\xe5\xb1\xee\xb8y\xd5\x1b\xd3 w\xf9+\x1c\xe6bTT1\xfcٸ\fD\xe6\xe4:\x0fr\xf4%\xa9&\\\x15\"\xc1x\xf0\xf9?Ɵ/ǟG\xbb\x9f\xff]\xf8\xea\x14\xc3\az\x05J\xc3,Ɇ\xc5\x11\x0f\xbalg\xd2e\xc7\x13\x8ay\x82\n\xb2d\xb6\xceW\x87\xde\xfe^\xb3\x92\n<\xea\xdf~\xc5\xc4" +
+			"\xd7C\xefK\xe9]\x1a\xcf\x00\xea\xe0\xd1\xdeg\xd2\xe0ܙ\xb6\x81gC\xa9\x9dJZ\x1d\x11Ő\xa6\xe1J\xc9B\x91\xecx\xb6\x10\x1c\x05/l\x06P\xf2^\xfb\x8dٖa\v\xfcAQ\x10+\xc3?\xdax\xdck\\\xc3Ԅ\ru.z\xd3Hp\xadl؊\\\x03\xfac\xd9I\x14\x9c\xf5X\xb1\xaf>\a\xb7\xf1\xae{\x8e\xef" +
+			"\xf8\xf4\x97s\xc9f\x01\xfddn\v |\xfe\xa3n\x81y\xf0\xefq0G\x96\x98\xed\xda!\xf0!אXQ\xb8\xe3M\xdcȽ\x10\xe5s\x9e\xa3\x1c-\xd9a\x11\xfb\x13\xca\x1a\xdb\xcdB\xf0឴z\f\xf8_f;\x1b\xc9\n\x12T\xb0\fW~[\xd3n\"ژ`g\xac\x14q\xf1\xe4\xb3}0a\x1c\x98\x15\xcf$,\xd8" +
+			"E/\x80\xec\xd1ޞ7歴J\x14r\x01\xb2\xb1/\x93̯_\xeex_=2Ԥ\x17\n\xaf\xe4B\xfb\xa6B\xfcr\xad\x1fE\xc1Vü/$\xa4\x0f9\x03\f\xd0AX\xff`\xdc͌\xb7nMS\xc1\xae\x8cd\xb7\x0f\x12(\xfb\xdfx_\n\u05f6\x03\xba<\xc5fd\xbd\xe4\x90u\xa1\xba\n\xe4\xb8\xcd/b\xd3f" +
+			"\x14Wo\x90L\xa5-\xa6\xc4\xdf\xcc\xf4\x12P.@\x1f/\xf9\xa2\x9aL\xc7t\bǳ\xab\x84/V\xbcb$\x84_\x86\x9b?\xf0a\xd8}V\xa9\x05$\a\xe2C\xdb$\x1b%\x93\x9d\x8f\x06\x06O'k\xb7iJ\xa3\xe8\xc9\xf7\xa7\t\x93\x8b\xb9F\xfb=j\rH\xfb\xb21>\xdeN\xe0\xe6\xea1A\x0e\x1d\xd5wTN\xf7\x86\xa0" +
+			"\x00\x80\xfe\x03\xfa\x81\xceJ\xf2\x8cȓ\xfe\xd0\x1b\xee\fU\xea\x1d\x8eL\xe3H\x93կ\xf2\xfa\xee\xa7+\x0f\xa7\u05eb\xd2]\xfc\xf7F-ޣ\xf6\xd5\xcb\xcc\xdc6F\"A\x94/C\xe0\x05\xc7\xc6j`~\x91Q\xb05l\xbd\x9a\x85\x01E\x01\x0f˖\xe1\xa6\x12\\#2My\xda\x0f\xe4o\xf0\x9f\x9eKF\xd4\r\xfc\xa6\xbbn" +
+			"\x00ڪn\xe1İWo[\x86i<\x8fI\x8fۖ\xee\xa3\xe4\xa2\xe7\xecô\xb3ZLSFR+4\xfd\xb4n\b\xfb\xe3ƕ\x93\x8d\x97\x8d0&7\u10c8\u007f\x1a\x0e\x04\x89\x160\xe9\xe6N\x9b\x80\xfb\"\x8e\xa2y\x05\x89+\x1a\x83\xab\xc0\xb5$\x9c\xb7\"\x11\x04\xeat>\xf1RK\xd7\xf0\xb6\x06\xbe\xbf\xc8\xebV\aV" +
+			"\x9d\x1b|G\xdf\xd1#Ѝ\xca(>T\x97|[T\x00[\xa3\xads\xd4|\xba4\x8aE\x89Ӝ\x89\xf9r\x141ݫ\xd6\x02p\\J׆k\x91\xa9y1\"\xf1\xd2\xed\x84<A\xaf\xf1\xb2'\x05\xa3\xfd\xde)Ɵ\xfcf\xe5F\x8c(G}Тԝ\xc8\xd2Fg\x89z3\xe9_DlV\x8e{\x1b\xe5\xc7ޯ\xda" +
+			"\xad\n\x02\x85\xbd\xdb\x16\xad\xd9\xdeJ4\x94,\xf3u\x19/\xf3\x8b8\xc0\x91\xae\u007f\x9d^\xf5.\xa7\xdf\xebe-)s\x06\xb6\xb0\xeb3\r7l>ś\r\x95\x1b\xd2\u07bb\xda\xc0\xd2p{t\x11<ht\x14ր{ Q\xe6{\xbb\x01O\xd6\x1b\x87\xec|'\x16=1F\x1b\xda\n&Q7\xbcC\x91\xed\xb2Twh\xad\x91" +
+			"\xc3>i7bsՕ\xa5?t`\xd8\xfa^,|H\xd7Ĉm\u007f\xf0'\x96H\xdcQ\x03>L\xd3\xecB\x8b\xcf4\xcf\xca<\xc5\xe1\x98\xfb\xc3,\xc7\x05\x0f\xb4a;W/?]\x06\u007f|\xec\xe3\x85\xcf}\xe0\x17\xd52\x05f\x91G\x9b\xe1\xa8N\xb9\xb1\xf2\xe3 \x9f\xcd`\xa8|4\xfb\xa8\a\xecZ\x15XWD?\x1dV" +
+			"\xdf>\xd2p\x12\xa7\xd6ݑ6\x0f\xdcg-\xdf];E\xbdK\xe0\x9a\xee\x90H\x01b7̦\x8b\x1cc\x90\x87\xb1v}\xae\x02\x8f\\i\xcf\t\x11!\xc8p7x\x14/ݨ\"\xe4T\xc3\xe0\xa0\x13p\xa32\x14\xf9\xcaE\x1f\xb9E\xf0h$o\x1e\xd6\x1d\x8719\x8bhjV\xdf\xf5y+\xe3\x95sҘ|v\x9bis" +
+			"l\uef47d\xbf\xe7\x88(\xbb\xe9\xfe-g_챗\x0emн\xcf\xe9SPwT\x02\xb3r2R\xbf\x81\x83qu)\xa1\x00\x1b\x1f\xf5\x0e,\xecW\v\x10&͢+>\x92\xb4n\xdf\xe8X4Rm\x8d\xf6\xafL\x9b\xbd-e\x11>\x16\xff\x03\xc5V.\xab߲\x84N\xdc\x1e\x0fq}\x9c\xb1\xe08\xf8\xdf\x0f\xf8\xbf\xb7" +
+			"\xf8\xbf_\xf1\u007f/\x87'R|g\x06\x05}\x90g\xf1\xd2NP\xb0׳Yr\x85g\x02\xab\xdaD\x8c\u007f\x03V\xfa\xe7\xe3\xc7\xda6Lq\x91\x1eϋ\xfb=\xecU\x80\x86w\x872ѕ\xbf\x84\xbf\xf8\x19\x1d\xda\xe7\xb1\xd0%\x8b\x84f\xa7\x9f\x86\x06kz)\x1b\xce\x11\t\xd6\xc9r\xcb5\x14\x91\t#\x15\xcb9\x97Iuޓ" +
+			"\xee=\x15(\xa9C\xdeSo\xb8G\xc7A\xf8\xefC\xf8=44\x16\xb3\x03&\xe5\xf7\t\x8cd\f\xbf5t ]4\xbd\x0f=)\r\x9e\u070e\x10#9\xf7\xd5SM\xd9z9\xa1\x13BTf\x96\xe6y\xc1\xc2`qc\vG\xdeث\u007f\xd1վ\x12m\x84\x98\x90\x8f\xbe\xae\xf2K\x9fM\x95\x84\x85a\x96\vPF.N\x11\xc7" +
+			"\xec\xb3f\"\xe7Cq䩀\xf50i\xe4Vw\x1d\xbb\x11\xc2\xc6\xf7}r\x15G\xfe\xa3V\u07ff\xf5\xf6\xe3\xddG\xad\xe9\xe5Ц\x9b\x06٥+hcʠ\xe4\x1e\xce\x14Hp\x87ux\xac\xb8\xa8\x0e@\x1ez\xfeC\xba\aB\xb4\xeeZ\xbfD\x0eɹ\xdf\rr&w\x8eX\fx\b\aV\n^\x89)X\xbb\xea\xea\x13" +
+			"\x15N6U\xec\x8c\xc6\xef[\xe3\xc1WP\xe3wX\xa5G\x94\xcd\x12\xecz\x9d\xf5'\xee\x93\x12[U?\xe9]}\xcb\x03\xf7C\x11\xae\x16\xcc\xcby\x99dQ~\x89l\x06Q\u007f/\xce(I.O\x06\xb1\x83T\xa7\x1f\xa8\xb3x\xcb\xf0\xd1<f\xd4\r\xddk\x86\x8f\xc9s\x86\x0f\xf3\x9e}\xb3\xd7\xd0\xf5cuD\fn1\xd5;\x8e" +
+			"\x0fn؆s\x11\xf8\xb0-\xd1\xf2\x116\x88\xb8\bA\x99\xb7|\x9f\x14\xebrAq\x05\b0\xa18\x02\x1b\xd8K\x9c%\x00B\xd9K\a\x89\xe9P\xdcw\b\bP\xff\x8f\x01b\x19^YZ\xb1L\xb2\xf6\xd9\x0e|\xae\x95\xb1\xbc\x91KZ\xf5\x1a<dZ\t7a\x02\xfb\xdd\u007f\xb4\xf7o\xf0\t8\x9c\x00\xe6O\x1bɸ\xcf\xec\xfa" +
+			"\xa8\x95\x85Ec\xda\x17\xce\x12\xa3\x88\xd0\xe5\x1f\xb8\xb57\xa0\xdb\xd4O\xbd\xd8ֽ\xb0\xe9\xe3^\xc0Ue\xb5ՁZ\xcfsĢ\xed\x18\x16\xaa\x98ȱw\xb07r\x94\xe22R\xc3&,\xa6Z\x98\x06\x835\x91\x87\xf81\xea\xaa\x17\x9d3\xcco\x18\x16q8\xb4\x87\xa1Q\x92\xcff\xec\x00إEO\xe0\xfb\x99\xf93\xbf\x9a\xb9" +
+			"oM\xf8\xab;8\x05\x1f\xf2\x18\xe2\x82o\n\xd3O\xdb\x1c_u\xb8\x8f@ܦ\xf2h,\xc3\u007fc\x93R\x8f\xcd\v6\x16݈я\x1fQb:\xa3\x9aDů,ůDq\xba\x99\x9e\x1d\x8d\xb5\xfaJ\xd9\xf5\xeew\xee\xa9\xea\xef|j\xe91Ch\xed\xe7\xb6uȜj\xd0`w\xdb\xfe\xedn,:\xcf\x11\xcfJ\xc52" +
+			"\x8e\xaf\xacM\xe10\xd34Y\xfd\n\xcb\xdc\xdd\xe4$¶\"l\x17\xbenU\xb6\x9e\x18n\xc5\xdd\xca\xd2\xefB\xbc\xca)\x91\xd3.\xc5{\x92\xb3&L\xd3.\xb7N\xb2\xda\xc5;+\x10\x1ao*\xfd\x13\xbe\xb9cW\xe1\x1f\xe7\"\xbcI\x9b6\xbcM\xe6aǱ@2bV\x10\xa7\x8bE\x03\xe99$\x8c5\x19\x10\x02\x85\xf7\"\xa3" +
+			"\xb2\xda\xe0\xd5\xf7\xf9*\x9c&զ\xd3B\xd1m\xc3\xe8ơ\xd2l\x1fN\"\xadewG\xa6\xeb\xa2d\xd68N\xc1\xb6\x8e\xcb\x06\xf7\r\xce\"\xbbq\xc6\xe9\f}k\xe1\xaemןE\x8eI\xf3i\xed@|+͎\xa5\f\u008bN\xcdв\x80}bR\x86%L\x06I\x81\xdfY\u05fb\x96\xba\x90V\x15i\x15\xb6\xba\x1c\xbe" +
+			"\xe1\xae\x1a\xb9\xc3DLW\n\xf2#V\a2\x9b\x91\x8e\xd9u|)\xcb\xfa\"\xc4μ\x88\xf0\xac\u007f#w\x1a\xa7x\xf8\xa7\xf8\xab\xfdp\u007fj\x90\xed\xd9\xe7/\xff\xfc\xe7x\xf2\x8d\xf5\xf3WQ8\xfb*\xb4~\xfe\xcb7_\xc5\xe1\x97\xd6ϳٟg{{\xd6\xcf\xe1\u05cf\xbe>\xb0\xd7=\xfb\xf37\xfb\x93\x99\xbdnz\f\x9f" +
+			"mr7\xd9\xef\xd0\xceaQ,\xe8\xfb\xc6\xfe=O#G\xe9\x05^s\xbf\xdd\xfeR\xf30*\xdb\xc1\x9d\xf4\xcd(˳\xb8\xa3P\x94\x94\xab4\xdc4Ў\xb6\xff\x8a\x15@\a\xe8\x87,\x16\x1dN\x93\x02h\xd4\xdd\x17$`[t\x18a|\xcd\xd2*\xe9ػ7x\x90\xfb1\xc1\xd0\xf0r\x91T\xee>\xf0\xa5\xafW\xe2\xf2c\x88" +
+			"U\x9fg\xd5.\x05\xb8\xa3\xd0v\xb0\xba\xb2\xd54˧kU2\xea;\xd3T\xf6\x863m\xb0k#\xb6\xba\r(A\x1b\xa14\xeb\xb7\xd3\xf6\xbd\xe2\xd1ђ\xb9۬\xbe\xd4\xebiUi'\xd8Z0\x1b\x06c\xcb\xe3\xdf\xf8Gm\xe9\xce\xc4\x13\x15\xe1\xe5\xcf\xc4;m\x1aWWzk\xd1I\xda\xed\xfeO\\\xe4\xf6\xc4&\xf5\xb0I" +
+			";\xa3u\xe0d|\xf7\xea\x1f\x16\xb5\x0fz\xd1_\x8fk\xfa\f\xa8O\x83jQ\x80f\x0f-\xe9vɊ\x8b?\xcbz3T\xbcP\x18\xc0\xd2\x19~\xd2̌5$\x8b.P6\xebc\xf8P\x1b\xfa\a\xa6\xd8C\x87\x18X{A\x89^8\xab\xbeJ*W\xcd\x05_\x14f\x1c$\xb8$\x9aC\x88Q\xbf\xa5\f\t.\xe4\xe5\x19\xbee" +
+			"\x89SX\x9a\x05:\xb8\u007f\x95\xd8b;H{Ś\x12\xcc2D\xc0\xe8\x0e@}\xd7^`\x99d/إ\xab,vU\b\xf9\xce\x12\xbf\xd0%t\xf0\xc7s\x94+\x9c\xa0\u007f'\xb8\u007f8\x06\xd8>\xb21\x86J\xf5\x8c%aq\x1c\xc8O&\x983\xa4\xf2#\x9e\x10\xcfu\n\x8b\x9c6P\xe8\t\xb0,\x02\xef\bV\xaf\xcbQE\xad" +
+			"\"ޮ\xeb؛\xfb2\x95\xb8%\x06:x\xa6(\xc0\x98,U\u007f\fmq\xdcpBWvX\xaf\xdb\x15O,\x94\xbf\xa4\xa2s`\xc4n;\"#bF\xa1l\xf9\xa2JX\x93)\xf7)0$\x1dXXo\x1a\x87\xa9O\xbbAm\xa5\xe9Q\x16\xb7\x87M]\xb6\xb3٬P}\xf5Ty\x0e\x8b\xb1v\x89aKv\xf9δC" +
+			"\xd9\x02\x9c\xb8\xf0\x91\xcanD\xd9\r\x96\xed\x11\xb8\x82\xed\xf8V\xac\xc0>1,\xcdb\x85\xa2݁+\xb8\xfc\b\xd6p\x1b\xbf\x01\xf6\x1f\x04kH\x93l\x80\xe5\x19`\xd5\xd9w\xec\xd3\n\x82\xe7\\#!̈́SQǐ\xd9\x17\x91\xe5\x1e\x1f\a\xd3\x16\xca\x13\xd6n\r)l\xb7ͺC\x91\xbcص帬l8M\xb5y\r" +
+			"\xe7\xc1f`\xa9k#i\xbb\x16=\x99\x80+\x06\xd5U\x0e%\\{KY\n\a6\xb9\xddc\u05efZ\xe2\xcb\xe5k\xeet\xa1\xae>\xe1[\xcdX\xcd1\xdf.\xf3\x1d\xf9 X\xa1\u007f@\xa1\xc6\xe0\u007f\xe3\x0e6\x16\x18Ѥ\xa7\xde\xee#\xef\x10t\x8f\xaeB\x14!*\xda\x04\xa5\xbe\x81R\xfb\xdd\xc5\xda\xf1MM\xad\x14\xe9\x84\xfei" +
+			"\xe6\x9as\f^F)\f\x9a\xde\x05\x99\xe5\xda]Q`2\xa1\x1cR\x11:,\xaa\xef\xbe˯l\xc0\xb5b\xd5g\xc0&\x93\x00y\xa3%>G\x19(\x00\xde\xf4\x02n\xa2h'Am\\<\xe8\x1dI\v\xa5\x84\xd4r\xe0\x92\xbf(\x89\t2u\xbb\nq%\xc8\xd2Ň-\n<>f\x16\xc4T,\x11\x90\xceT\xac\xce\xd1އ" +
+			"\x9e\xb9\xe2m9\xd8A/\xb0;ݚ(\x83\x1d\xb8,\xe0\xf8PV\x8d\xab\n\x04\xf17\xec\xe4\xbb[\x16\xa3sk\r\xb8[Ba\x80x\xe6\xfd^\xabTg\x80+%\xf8\x01J\xa3\x14\xad\x02\x89{\x17\xe1e\xfc\xa6\xc8\v\xccc\xc5s\x95\xd9J\xd9\xf7\x9e\xc6\xfeG\xec\xd3&\xba\x19T\xcb\x1d\xef\x91I\xc4i\x9f\rE\xd5\xc9v" +
+			"$\x14\x1fr8c`\x8c\x92ӆ\aHt\xe1\xef\xd6\x03\xf9^xi?\xf8\x06\x1da\xe7\xebw<\xc3\xfd\xea\xf8\\\x06\x93\x84\x99ѹ\x85\xa4\xbbڮ0c\xd3f,\xa5/\xc6z\xec\xb8\xfb\x1e\xe9Ç\xec\v\xa2\xc0\xb7\x96\x8bY\xc4\xe3\n\x156\x93\xd0-O\f\xe2\xc35\xcb\x1eg\x03\t\x1a\x9d\xf7\xedc\u007f\xf6\x8e\xdf\xe3z" +
+			"\xaa\xa3˵\x1dGpb\x8b\x1ad\xee>Y\xc1\xccG\xf9\xac^\xef\xd2\x18\xeb\xe9\xea-\v\x1f\x10R\xc7\xd76\xc5b;ӊ۠˴P\xa6ر\xbf[I{[\x16\x10\xb4\u007f\x01Aӌ;\xa8\x9a\x1f\xfc6\x1e\x90Ǉ&L\xbd\f\ue0a2\x11/\x84\x96j\xbbYH<\xdb\x13\xb0Xk}\x86\xad\xee\n\x1biW?" +
+			"\xfa\x99\xf4\xb6o.\xc9\x03\xec\x10#Ƹڍ\x85\xec\x94b\x0f\xfb\x958\xce\xf8B\x01\x92\xcf\x13N\xf9\x14\xe3\u007f\\\xb95;&D\xd5\xe1UϪ\xe94\xe3\x9dT\xed\xb0\xaf\xdeCZw\xcd\x03_\v|`\xad:\xa0yJ\xda'K9\x0e\x878\xb7Y\xd2\xdc\xdd\xf5\f\xed\xd7\xc3\xe4\xaa:\xbc\xe2U\xdf\xe5\f\xf5\xa9\x9ag\xdb" +
+			"\xf4\xa9\t\xbb4\bh\xdd3Ź\xe1\xe3\xbc4\\<\x1c\xe7V\x1c\x9bF\u007f\xf7\x88ʚ\xcbQ\v\x1f\xba \xb0q\xb5\x99\xdb\xd5@\x02\xc4\n\x9f\xb8\xd9V\xdd0\xab|n\xef\x10>\xf5}i\xd4\xf6o\xfbT\x16:\x94\x01{ev\xa6\xb4i\x98\x12\xf6d\x87\xaap\xacɆ\xd1\xffB\xf1֜\x1a\x91,\\\x8d\xe7\xd5\xd0\r\xbe" +
+			"\"l\x12\xcalC\x01\xae\xdaë^\xb5\xef˵\x87\x16\xb5\xccB\u007f-n\xb1qr\x8b\xc67T\xc7\xee\xe1\x0e\xc8B\xf4\\\xedd\xd1h{<p\xd1߳\x1e\xa7\xb4\n5\xfd\x0e!\xe3\xd3}\x10\x99\xa0\x9c\x87\x91\xb5Z7wY릣\xd6\x1eǽ\b\x19\x89m\x03r\xbe\fv\xbc\xc1\x86N\xa0\r:\vԦ3,T" +
+			"\xe4\x15\nA\xbb\u007f\xd9\x1bu\x97\xdc@\x89\xdd\xce\xc0\x17\xa9\xc0\x15\x16\xf0\x1bK\x93%\xb2T*\x11a\x1d\x83\xfdx\xe9j\ri\x86\xa7\xc1:KΥMÙ\xcf\x05\x8fR\xe0\x860\n\xde\xe7@\xe7\x83Ǟ\x96\xde]<\xc8=\xce\xd7\xe2^\x01\n\x99j\x1f\xf4\xeb0;ܑ\xa3n\xcb`Y|z\x05\xcc\xe2û\xd7\xe9\x06" +
+			"\xac\xfb$Hre\x8f%lÓFQVE~\x16\xf7\xb7\a\xf7\xc5[\xfb\x1b;\xa6\xa2.\xd66\xb1\xde\xca:-\x1eG$1>\x9d\xd1\xc4\xf8\xfc\xffk\x1a\xb6a\xe9u\xcfo\xe5\f\xe6X\xba\x8cq\x91\xb5\xeb\x14\xc4ͤ\xc9^y\rd\xaf\x03\xdd\xe7s\xdb\xfd \x86\x15\xcb\f\x99\xa1-\xe4\xc8R\xbd\xe2\xf4\xe0\xb6\a\x9fi" +
+			"\x16u\x1e\x83F\x83\xa0\xfb/\xecn\x10\xf9\\,\xed\xb2<\x8e\xb3c+#(\x97o\xa3\xe1\x9b\xfdR\\\xf4\n\xc5$\xf8\xfa\xd8)\x85k\xf5\xb1\x81\xe1Â\x91\xf4\x80\xac\t&p\xb7\xd2p\xaff\xac\xcdGܶi\x85-\xb4\xa8w#p\xb5\xc8\ap\xb7\x9am G2\xe0\xbaf\x89\xb7\xb9f)\x18V8\xebQ\x00Y\xefn" +
+			"\x13\xd3;\f\xf6\x0f\x1e\xf5\xa9g\x11\xae\xe2\xdd\x02\x98^L\xc7S1L\xbd\x80\xf1z\x19\xcd\xedq&=\xb5gw\xfc\x92η̆)\xa7Q\xbe\x010\xdaћ\xcf/\x8c\xba]ML\xfc\x9c\x873\xb8\x88!\u0080\r\x04\xe6Si\xe3\x9cR\xab=\xba\x920\xc6#\x87\xec\xad\xfd8u\xe3W\xd0\xcaX\x03\x05$\x9f@\xfb*\n" +
+			"\x9e\x06\xbf)\xcf/\xb5h\xbd\x86\xa6\xd8Ĵ\xee\xf0\xb3F]\x91N\xddQ\xb6\xca\x1b\xf8G\xf8u?\xf5A\xc0\xbe\xfe\x18\xa9\x1c\x1b\xb8\x1e~\x95>9A\xfa\xc6\xd6-a\xcc1\x1d\v^.1~\xf5j\xfc\xe2\xc5.\xddnt\b[\xb7\x83\xe2\xc4\xf4Z\x83\x84Z\xa9V\x01\x8cg\xd4\xe3wY`\xad[\x9c\xa2\xd7\xd2\xc9ڮ\xb9" +
+			"|y\xb5*\xfa\xdep9\xbc_\x00O\x8e{\xddu\t\u007f\x12\xb0z\xea\xb5ם\x97\x14\x11\xbe.\x80KIt\x80\xf9P\xdb#\xc7AйT\xe5\x13\x9f_m\x19C\x8f$\\͘LC\x96\x0e_\x9d\x80\x06\x8d|O\\S\x8e,U\x1cH-\xab\xdfW\x88գ\xe7\x17\xaf\xa1\x1a\x86\x17s\xff\xdc\x1f\x84\x18\a\f\xf3\u007f\x98\xc3" +
+			"\xe0\xaf\xd6\x1f\x16yY\x1d}A\xf3\xf2\xc55\xaag\x8fHu\xc4+\xb5\x9ex\xdf\xec\r\xd5\x15\xaaZ\x91\xb5\xfb\x1c#vw1\x1f\x01\xfa\xf5\xf1\xa3\xe9\x1eP<\x90\xd9\x00\xd2/3 v\x03\xa3_\xd4Y\xd0n۶AT\xe1D\xaa\b~`=\xfc\xb6:\xbd:Õ\x84\xeau\x84آ\xa7\xe7G\xea\xadʆ+\xc0\xea\xb9j" +
+			"C\x0e\xd9\x1dg\xee\v\xe5ɋ\xa9\x15\xa4K\xce:n\xa2\xa7\xa4V\xadr=o<\xae/-ű\xf1\xf8}\xb6\xfcr\xc0\xc7&\xc8F\x97&\xd0\xffb?\x8d\xa0\f\xe9)f\xa6\x10\xe0o7+%\x1c\xb8\xbee\xfe-\x81\x1d5a\xa7\xf6\xcb\x15ˋ\xf9\xa9|\xe3u<\xc7\xc3\xf1c\x1c#\"\xfdf\x0e@4\x01\xe0\xa7Y~" +
+			"I#(\xe5s\xc0t`A\x86w\xb1\xf0(P\x03\x83\xe3\xd5\x11v:K\xf8\x1c%-_\x1e#\xa5Եq\x1cjzm\xadqe\xbez\xdd\x03\xdd}\x97\xfdVuv_ii\xb9\xb8^֧\x05HL7h\xd919\xb9\x95\xb4\xf2U\x06\xa4\x17\xc4u\xd2\\\xca*8\x8e\xe1JV\xbd(\xae\x94\xa6\xa8\xe0A\xa6\xa2\xb4\x83\x04" +
+			"\xfa5\xc0\xa6\x1b\xb0\x05e\x00śn\xa3\x11\x04t\xacȮj\xe2\xc3B\xc9͉Y\xb8\x8c\x9e%ry\xb0ˮU\x9c&\xbcQ\xf0;\xa6=j\xddi\x14\xa6;^eL\x1f\x80\x0f\x91\xf8\n\x8f5\x1f?\xac\xa0Q\x00n\x12\tMf\x95zA\xf7p\xaan\x97g;ca\x95\xc3\x0f\x06QG\xef\xf2\x0f\x98vN\xeer\x15" +
+			"\xce/\xa0\xcf\xe1\xdczY\x016\x1d+\x11M\u007f\xd2N0\xa3>\xd4\x1e\x8c\x97ٱ\xc4Ƙ\xad%\xa2\x18\xb6\xa4\xbeq\v\x1b\xd7o|\xebZ\xaf\r\xb52)\x873hs\xcb_PV\r\xb2e\x1a\xbf\xa3\xe1\xe8\x90jћ\xa3WH\xa4Maִ\xe1\xea{\x81\xda\x05.iR9\x87P\xf1\xc7\\\x12ݰ*U\x107K" +
+			"\xaf8\x9co\xc3\xf9\x1bbm\x06.Y\xbfa@\xf5\xfb\xd6\xe5\x90\xec\x1b\xe6v\xf1\x1b\x94\xbfw#\xfc݊\xeew\x19\xd9k`\u007f\u007f[a\xa1\xb2\x03\xa7\x04iF-\x01\xc85\xe0\x1e\xbf\xe9\xc0M0\xfe\xb9<\xe8\x18\xaa\x1f\x84\xf3y\x11ϙo\xc9;Gu\xed\\~\x87rY\xb9^J\x94L\xa5\x961^\xa3Ҕ\xe0\xbf\x15" +
+			"i\x91@\v&}r\xc0\x82\xef\x05ʹ\xa3\x1a\xb2\x19(\xa9\x80x\x89\x1bA|\xd9\x1e\x05\x99ʨȽ\xf3\x00\xad\x17\x17!&\xe6Qil<\xf6\xf0\x9a\x13~\xfdo\xec5\x90t[\x97w\xaeQ\uef7ai&z\xa5\x8f\x12\x12X\xf5\xf3p=\x8f\xd5+\x8e\xdbB\xa9pת\xbd\x06\xddk\x9d\x19n\u05f7\xd4ġ\xbb\xeb" +
+			"\xea\x85\r\xdbaE\xd5\xfce@\xa8#\xe3s'\xbdC\xca\b\xd7Unԡ\x18\x02iң\xd2HJQ\xc95\x94\x1a̤\xa3\x10(\xb0k\t\x1f\xfd\xe2\xd4#V{\v\x1c\x18\u038bRf9\xf5ۺ\v\xed\x8c]\xb4\x9c\x82U\x91W9\x8a\xcf\f\x81U\xbc\xaa'\x9b\xb7\x18\xd3\xc1\xb1\x9f\xeaT\xb3\xd7\xc0X\xcbp\xb9\xa2D" +
+			"9r9\x91ٕ\xbf3\x8d\xa5u~d\x9c\xba*˙\xaa\xa9[\xf2Ě\xbb\xc7\x12V]\x89\xc6\x1a(\xfa\x95\xec%\x97\xd9B7\x1fPV\xbc<I\xc2g\xa7\x10\xa0\xa6£\x9fn\x80X\a\xba\x83Hn\x8c9\x95\xad\xc1\xf5\xc40\xf2\xbe\xdd\b\xa9m\xa0\xb6.\xf0\x8a\xc6\xdd\x18\x85\xa0\x15\x01\xf15\xae~緁\x19\xc2f" +
+			"\xac=%\x9e\xd6\xd1O\xcbIR\x05g\x8b\xda\xf8\xaeFD\xd7\xda1cPbˮ-\x9dC\xf9ږ&.\x93\x1b\xee/v\x9b[\xa3\xebύ\x82,Ds\xd6(\x8eO\xa2\xfe\x15(in\xaa?E\x8c\x9c\xee%\xb5C\xbe&n\x8f\xdd\x11'W-..\xa1K\xe1,\xb7{\n9Y.w\x9c\x9c\xf4\xb9F\x96<\xeaX\xf5" +
+			"\xa9RX\x9f\x9dz\x05\xb1\xe4\x94\xd6\xe0LF\x06,i\xa5\x81\x0e\xc4C\x1b\xa6\x15\x89x\xa28\x8d\x81dΓ\xe33\xc7i+W̺\xd5\x17\xcc\xda9\xc9\xf34\x0e\xb3O\xbf\xa1\xf9\xe4}<\xad:\xda\xf97\x02B\xd9\x19/\x8a\xef\x1b\n\xfb\a\xb6\xbfǅp\xf8\x8f\x90Yٲ\x92\xd77\xe9\x16\xaf\xe3\x19\xf0\xa3E\x87\x05\x9a" +
+			"\xb2*no\x82\xb6\xdc4\xd7a\x8e\xde\xf1Lw\xd1\t#d-\x14\x13\xeb\x18\x80T\x8cf\xd9e\x92\xd1?!\x06ߠ-\x17\xff\x89\xe2\v\xfc\xe7_ɲ\x86Z\n\xc0$C\xd8\x13\xcd<\x13\x95j\r\b~\u05f5 \xb3>\xcd\xeb\xcd\xf5x\x80B\x19\x96`,~\xa7\xd9\xd5v\xf8\x96\xa9㘆\xd93(嵯H\xdb\xca" +
+			"~\xff\xbe\xb1\xfe\xbe/\xe5+\xcfɉ\xc4>L\xbe\xfeJ%\xf0\xf7\x8a5\x1fALB\x10eg\xad7\x91\xf7\xdeS\xef?\xdf\xfc헀\xb2\xf4\xfa\xefG\xde!\x93*\x04e*\xfdK\xf0BP\x8f'\xf5\xc5{\xf7\x9b\xde,BL$GA\xe9{\x06\xa3\xf6\xfc\xa2T,>B\xa1\xc5\xcb\x04\xa3S\xb4(X \x90KoNW" +
+			"\xcaG\xdd\x00\xc5\xf6(\xce\xd3e\xe2>7ܾ\xd1\xc6\xcd\xee\x9eÞ\ve\xd0m/\xe4ۨ\xa8\xb3l{ބA\x90\xbcl\x02&\x96\xfdlb\xe1\x00\xad\x90p\xcf'\x8d\xff\xbe\a\x1b4\xc9\f\xba\xbd\xbf`\xac\xa1)R\xbf8\xc2@\x8c\xb5\\D\"\x18\x8a)6\x0e\x00\x8b\xad}\xd8\xc0\x99\x88F\xc6\x14jV\xbd\xfbu\xb8" +
+			"\xa7\x8c)\xd4\xd2\x03\v\xf2\x13\xb7\xf9\x9f.Õf\xea\x19\x94\x83C\xfc_\xdb\xc03X\xe2ۥ\xfav\x81o\x17\xea\xdb\b\xdfF\xea\xdbK|{\xa9\xbe\xcd\xf0\xed+\xf5\xed\x06\xdfn\x06M\xfb\xdbK4)_\xd3]\xff\xe3\xff\xf1\xdfE\x0fG\xfe\xbb\xcb\x11JS\xf7\xc7\x06\xf3*@\xbe͟MJ\u007f\xa9\x0e[\xdbo)ܖ" +
+			"\xe5zR\x15\xe1\xb4\xf2\xa5\xbc\xd9KtJ\xef\xb4\xc6\xedxy|prR{9\x8dK\xbdn\x03T\xff6\x87\x86\xf8\x9aN5\x1e\xff\x92W\x1e\xbb\xf8\x95\x165\xda\xddA\xda\xc1{\xb8I\xad\xe2\xd7`z\xdf\xe7\xe8\xd7'%i\xc7{\xbf\x06\xe618\xd8\xdb\xffj\xe0]&i\x8aw\u007f_\x84i\xd2Nm.\xb2V\xc8w`\xee" +
+			"\x88_<*\x8d%\xf1\x1c5\x97\xcb\x1b\rn\x95\xb3wo.\xc3\x15\xe5\xc4\xd0z\xc7Λ\x98D\x01\xf3\xd8\xeb\x83ٮR\xf4\n\xcf.\x13\r\x04\xf1U<\xd5N\x06b\xb5\xdalK\xb5J$᪉CK\x93\xe7\xb09\xbe!i\x15\x87\xc1\xaejK\xe0\x82\x81\xd5c'\xbfW\xbd\t27S\v\xc0[\xb3\u007f\x81\u007f\u007f\x16E" +
+			"oɡ\xd9\xd9$\xb1\xb5\xb4\x19\xb3\xf1\"C\x05\x84l\xfd5\xefv6\a\x94\xbc\x9fx=\xd2\x15\xa5\x1d-J\\\x18\u007f\x88\xab\xb7\xe1\xfc\xaf\xdfm^\t\xbb\x9f\x84\x18\x11X\x90ӎxL\x10b\xeba\xd6Q\x19\x96\x88M\xe0Uw,*\xca͋:\x01\xdec\x1f\x1c\x96d.\xab\x1c3@\xfb}5&G\x87\xe2+T<\xce" +
+			"\xb8\x97\x93G\x93\xb7AC\xd9\xd3\xc1+\x86\xe0\xdc\xd6{\xbd\xb1\xc4t\x98\x81\xcbd\xd1\x12\x8f0˞rX\xf5B[|L\xaa\xaa\xe4\x1c2\xaa\xa8r3xlRh\xd4.\xb5F\x1cw\xdc\x18DF\\\xb2ֹT\x9b\x06\x13\x83\x85\xbf\xcd\xe8\xec\a@\xee\xf1r\xfd\xaa\x19n\xe5>b\x8b\xe5\xf7\x92܃\xb48\xbaT(|T" +
+			"I\x8fuM\xf3\b\xe2\xe5R\x0e\xe7\x18\xc0tv\tP`\xa7\x00\xb4o\xafL^\xaesab\xc5\u007f\xf4\xcfc\xbc\xc8\xe1,\xf6\xcau\x11{\x18\xd1\x02{\x89\x17\xa6\x97ᦤ}w\x96\x14\xf0\x0e\xca\x06\xb6\x95+\x8b\xcc\r\v\x91\x95a\xa2\x13\xbdj{\xf9m.\xdfe\xd78\xa0\xc0\x89\xadw\x1e\xb7\xe1{\xd8\xeeV\a\xd1j'" +
+			"\xc0d\xabJ\xb6\xaa\xa3\xbe@X\xb9<\xb8\x87\xa3\xd8\x10\xfe\xda/\x00\x02\x1f%\bb\xf8\x1b\xc5\x03z\xa02\xceb471\x8eP\xb2\xa4;\x86\x10\t\xb51*\xeb\x85\xf2!2\x9d1\xbczʐ\x1d\xdd!'n\xf4[\x8bMS\xf3e+\xe7N\x1c\xab\x90/\xd2@l\xa4Gb\xeb{\xf0\x00W$KHt$\xdc1\xee\xd3'" +
+			"\xa2\x95v~\xdao)[\xb7J\xfe\xe6F\x94у.\xe0_\xfb\xbc_\xb7U<\xa3\xc0d4\x82\xb5d2\xb3\xce`\xa0'\xe8\xf1\xf06\xf1Y\x9c\xa4\xf9n(\xeb՟u\x8dTg\x10\xd1V\xebG\x1eú\x9azK:\x13[\x92Z\xa3.\xdc\\\x90pC\x01\x10\xf4\x97K2\xbbՒ#q\x838\xb3\x9d6eA\xf2\xf8\xec" +
+			"D\x1bf\xc3P\xf7\x1f\xee\xdb\x0e\xb9:\xec\x06\xf5\rF\xd6\xe4\xae\xc0\xa7\xb1S\x19mR\x12H\xad\xd0\xc8z\x8c\x19\x92\xe91\x8d\xfa҆R\xf9W{jeN\xb62\x8d\x15\tP\xab\xc0.{\xb3\x96l\x139t\xde2L\x99n\x12\x94d^&z8D\x12\x97P\xac\xf9WT)\xcb\xe2T\x11\x1d\xbf@Nm\x85h\x9a\xc1\xa8" +
+			"\xd4\x102d\x1e\x04\x13_V\x8c}L\x05<\xd76j\xa35\xa1P\xe9HS\xa6EЈ]g\x15w\\\xc9\xc4{SB:\xb70\x1eQϒ\xe6UR\x15\xf4\xe1`\n\xdf\xed\xe9\xad[\xd2>\xc3\x1c\x88\xf0\xd2E\a\xcbc\x00p\xea\x0f\xdbg\xf7\xe0\xfe\x9a\xa2q\xd91&K\xf4\x84\xd5\xf5\x91\xdb\x14r`NLu\xe2\xf4\xb8" +
+			"\xcb\xc9\xd7_\x89PO\xb2\x953__2\xdb\xf8\x85v&D/\xcdl\xbaM\xdc&\xb7\xf1>\xf5\xd6ЃY\x92\xc5\x11f\x8bc\xe6\xdeNd\xdc\xda\xdb`\x13\xe6ߧ\xdc\xfa\v\xb8j\xbc#\x831\x81\xac\xbd\xda\x19\xff\xc6\x16<\x02L\xcd/\xe9N6t\f\xac\xd3Ԁ\x92̾V\x94h.~*\x99\x88\xbbP\xea}\x86v" +
+			"\xb0l\x84\x9d\xa3\x03\xe8\xe9>\x04U\xad\xec\x13\x0f\xdb\xec5\xe65MKLe;椲\xf6S\at+\xa0\xb0\xf9\xab\xf40|\xc0\xfe$y\xfd\xbe?\xfc\x13\x9d\x8d\x1b\x8eD\x16+\xe9\xd2;|\xe4\r\x94\x89\xcc\xf0\xff\xd07o=V5\x81o\u07b2\xaa`\b\xd5\xe7Ho%˨\xfeZ\x82\x93\xa4Uk\xb8j#F\x86\x92" +
+			"\x00N\x96\x15\xfe\xb3\x8b\xb5\xddJ\xfc\x91\xaf\x17\x1e\xbc$!\bƱBC\xb9\x18E2\x15qee\xd0([ۊA~\x96\xbff\xa1\xef\xda\xf4q\xdf+*\"\xd38\xf5e/\xb1\xc1\xf8|ϊH\x1aO)ʞ\x03;\xa3\xe5\x04\xe9\xf2\x90\x16\xd5\xee#M\x92\xc1\x9cf2\xa5\x99גժ\x86\xfdR\x8a\x1c''\xad\xd8" +
+			"\xba#\x1eGg#\xa4\xba\xf9\x18\x81\xfc@\xfc\"\x9aO\xfa\xec\x8e\xed\x85fh\x8cy\xdeoƄ\x87\x0f\xe0\x8f\x8e\xa33m\x0e\xad2\x88\xba\xba>\f\x1a\xaa\v\xaf\xba\xaakqoSu\xf6CI\xf4UaBD\xc5O\xb1N\xdcbm\x95\x1b\xf7]6\xf6#:J\xce\x19\xe8Ci~i\x88\x1f\xd2Np\x1b\x96e<`\xf4\xc6" +
+			"\x10(\x8e\x0f-\xbcV\x89\x0e\x86v\x19\x16b\x01\xfe\x92{\xaf\xb5\x13^f\x02\xc2\xc7\x12\xb9j\xc6\xdd\v\xe3\x16\a\xa4\xe4\x811\x1e\xd4Q\x80j\xbd\xd1\x12\xf2\xbfn\xc5D\x84\x93\xf2\xb7\"5\xa9\xbb\b\xb7F\xf7(\x90\x81\xbf\xb7\x03\u007f\x93\b\xf8\xb7\x99?|:d9\x05\x9e\x1a\xaaX\xd3j\x17\xf4\xd5\x04Gt\x11\x8e\xb5?\xec\xf0" +
+			"\xd6\xfa\x8fS\xb0\r*t\xaf17\xb5\xa1\xfb\x90\x94\x84Z=(%\x1e\xc9\xc8\xc4\xc5M\x1be\xcb\xfb\x12N+߶\xda\xd5\xd3V\xc7\xf2\x89\xb2T\xa9\xc6\xf3k]\xa7\xde\xcd\xdbi\xf3\x0e+!\xa1Z\xc4&\xd7'z\xb5\xebi\u007f\xcdW\xeb\x95\xeb\x8e\xdc\x0f\x92\x94\xc8|\xe5\x87xMv\x134`\xbc\x06\x16\b\xa5}I\xaatA" +
+			"j\x15/W\x981\x03\x00\xbe\x9d\xac\xab\n*\xa5\x1c&G\x83I\x95\x81\xaa\x91\xedr\a\xf9\x80V\xe2\xee\xa2Z\xa6G\x03\x1c4\xfe\x02JO)\x1f,\x94\xa0\xd4Ճ'1\xb0\xf5\xe8\xdb1C\xf7Dj\xdd\xf67\xb1R\x9eK֬#\x14E\xd9\xdfCVF\x99\xacV\xd6Y\u0086KD\x1eM\xf8i\xb5\x95X\xbe5\x83\xdf\xd7" +
+			"LR\xb1+~\x86\xdf&\xd9j]ѕ\xe20`\xf0r\xe0\xe5\xd9s\xbc\xcc\f~\xb2\xc8u\xca51z<\x80\x1a\xc2(\xcf\xd2\xcd\xd1@\xfc5\xf0\xe8\x92\xfd\xa3\xc1\x83\xb4z\x1cz\v\xa0\xf7\xa3\a\xe7\xeb\xbcz\x8c\xdc\x03\x97>\xb0\x19\xf6\xe2\xc1\x1c\xfe\x03\xa8d9\xf7\xcabj\x00\vV\xd9\xfc\b\xfekÏC\xfck\xf0\xc4" +
+			"\xc0\xab\xd80\a\xab|\x85Y9|\xf3\xb0`\b \xcc\xfb!\xf5x+\xa5\xb7u'\xbcy)<K\xe3\xa2\xfa1\x01NPl\xfa\xad\bAɿ\x11\xb5\x8fW\xa0\xb2$\xb0\xec\xc6!bZ0L\x01\x92\xefP\xab\xdd\x16\xd8\xc8\xeb\xff$Oף\xea\xa2\b\xb8\xed\xacy,9+\xdfg\xd0%\xd9\x15\xc5܀\xb6lm\xa6U\x81" +
+			"\x95\x1f_\x98\xfd\xc4f~h\x90\x14\bIS\xa9\x8e\xad\xad\xae\u0084\x86\xcbRq/\xe2\xffF\x8e,g\xc3\xf0\xcc&\xce]Pz#\x96\xfbl\xf8`\xe88\xb7^Va\xb5.I>d\x8d\xb8\x91\x13\x82\xcd..\xf98:%\xa24\xf9\xfb;\xddV\xc0(\x8d\x96Mbb4\xa4\xe1\x99\xd5\xe4\xb5\x05'\v8\xf1+\x83\x8b;\xae" +
+			"\xb7\b\u07b23>RD\x15{g\xc9\x12\xa6\xf6\xaa\xc6.wma\b\x8e\x94{\x97`\xe6g\xd0ך\xa6u_\xa5\xb3\b^f\x11ol]\xee\x980\x9dP\x83\xb71\xfd9\xa4]\xb5.i`\xfa'+1@*\x04\x83s\xab\x05*\x8a\x87\xf7\xeeP\x1a\xa0\"\x06\xf6]Ɔt[\xd7n\x93\xa4j#Q\xda1j\x0e\xf7\x1a" +
+			"\x03܅\xfa\x85\xc0\xa7\x9c\xf7R\xa4h\v\x8bK=\xb5\x8c\xb5*ʃ\xbe\xf2\n\xf7{\x14D\x9f\xb15\xf5}\xbe\xce\"\xfb!\xb9n__w\xba\x00\x89EiB\x9du/\xc9\xcb\xea\x93\xdbHx\xd7(\xf6\xa3\x0e\xe4\xc5_\x1a\x88\x9evD\a1\xe4\v\x19 \xef,\a\x1alb8x\xcf?\xcdJ\xfb\xb7ƃ+\u007f\x94\x92\xcd" +
+			"\xfc\xf6\xfa\xe7V\x97\xd7m\x15N\xa0AA\xb4\xe5V\xd1\\\x16¯\"\xf9\xfbԕ\xac\xfb\xc4\x14\x80\xf3\xe6\b\xeeR\xfd\"½xT\xc9ak*\xaeU\xff\x80ӻ$\xbcIFkr\x13n\xa8F?\xf6Ȅ\x03\x938ԯ7kMwe\xae\xd5\xe8\xbc\x1fc\xe7d?5\xfe\xbe;\x87>қL\x16\u05ca\xc4$<" +
+			"\xb3\xce8\xe7:\x17W+)\x8c\xc1\xd8݆֤$~\xb5t\x15\x17\xa8\xb9\x8cYxv\xf4q\xf31\xfb\xb8\xf8\xb8\xfcXR\x9c\xf6\xd8`#\xa33\rT\x8e\xc5\xf4^\x98g[D/\x8b\x06\xd4\xe7 x\x886Fe\x03\xfb'\xed\xcc\x1f\x12Sy\xd5\xcaJ䌴h\"w04\xeb\b\xe7\xe9\x01\xba\xf7;\xecr4\x9f\xb7" +
+			"\x9cА\xaf\xfeӀ_\xf2\xa6J@F\x19\xa1=*8\xb1\t\x93G`\x872\xb8\xe0\xaf-\xa7*Zn\x91\xda\r\xb2\xbf\xb77T\xb8\xcdj}\xea\xe0\x0e\xf4Y\x8d\x04h\xf3L\x06\"\x1dsl\xb5\xafa)zW\x19у\x8a\xc3RQ\x19\xee\x17nLч\xcd\x01t\x1d\fY\xd0!Js0k\n\xff\xb1\x99sN\xecK" +
+			"\\\xb2\xa1\xe2i!\x1b\xa5(\xf6S\x1a\x06\xc9xz#\xe2a\x89\xe8\x1b\x93\xa8\x9d@\\\x12\x87\x84\xe0x\xef\x84\ayy\xc3_\xe3b\x8a\xb9\xc5~+cU\xaa\x101Y\xab\xb5\xcd$\xab\xd2\xd62^\xba\xe8\x86>\xbb醁\xb4\xf6\x03\x1b\xb1\bB\x19\xe4\x98\vb\x19Ty\x15\xa6\xca\x01\x93>4p=Қx\xa3\xfa\xd70" +
+			"\x82\xb7\xad\xfen\xa8\x8e:\xf1\xe9Q\xdd~Mu\x03\xa4\xb6\x81\x91ڰ\xed4\x93\x1e\xbf_\x12\x9d!,-\"\xfa\xb0wT:~\xa1\xa7\x01o\xdf\f\xc3n\x860\xef\xf1P\x19\xf2\xa6v#-[\xac1<-\x99\xc1\xfe3\x06\x02\xc8\xe2*\x98l\xaa\xb8|J\xa9\xf3\xeeB\b\xe8R\x95\x13k\xe6'Y\b\x15iw\xcc:\x15\xcb" +
+			"\xe3\x93l\xab>Ս\xc80-\xbb#\xff\x94\x90\x83\xb5\x16\x99\x8d\xdf\xf7\x12!\xe8H\xf2\xee=MལLQquJS\xe6bY⑀\xdd\f\xccT\xc0\xb6\r6\xb0\xf6\xedP<2\xb7\xa9\x89m`\xbf\x02\x87\xb29\x92\xc1\xc9\r\xc3\xf32 \x97\xe2[)/\xe55\x99\x1a\x0e\xbd}٦\xae>V.\a\x04\x8a\xeb\xe3" +
+			"\x90\x91A\xc0\xee<\xe6f\xd0<\x83\xbe|1\xe8\u007f\xf1\xa8\x81d\xee\x86[J3e\xe5\x99\xe2\xd9§\x89O\x1f\x1eZO\xc6֡Z&\x06\xc1+R\xb3\x9f[ke\x99н\xfa*f\x85\x93\xae$Vz\x1c\xad\x80\xe1\xc2\x04\xae\xf0\xf2\x91/\xbcoN\xdc)\xf3)\xc7\x1bMz\xed@\x1cԓ\u007f\x04:\xfd`\x84k{\xd7" +
+			"\x99>\xed\x96m\xdc\xdd\xefh$\xc3/\xb6%l\x94\x1d\xb6\xe3\xf2\x9b\xaeN\x88J\x92l\xeb:l=\xd0\xd8j=R.\a\xba%\xadxO\x1f&>\x82\xed\xa3\x9d\xb1\xcfA\x8eϴ\xc2{\xb6sߦ]6J\xca3\xdcd\xf1\xdf`V\x06\xe5\n\xb8\n\x93\x12>\x85\xed\x96\x19o1*f\x1c\xc5\x17\xe3r\xb1\xb4F\xc6l\xb7" +
+			"C\xcdzmM\xb3\xde{Ҭ\xec+ۊG\xdeu\f\xa3o\xd9\u007f\x1c\x1b\x02\"\x81\xfd\xc0h\x1e\xb6\xf5\xed\x8eZl\x90\xcf\xef\xbe\xc1-#ߝ\xc8^\x84\xf5N6\xba\xd9\xffu;\x9cY{\x18\x1atU\xf1\x90\x87\xfa\x0fW\x1f\xe4ڦ\xa7\x17T\x9b\xd2VB\\\xa6\xc94\xf6a\x87\x83\xaa\xac\x97\x12\x90)\x8di\xe1D\xa3" +
+			"x\xe8\x89p\x8eyO\xe8\xcaA\xe7\x06 \x91[ zO\xff\xf6.%zA\xff\xf6.\xa54[\xfe\xd9\x1b\a߱\xecJ\x98x\x9c\x1e\xf7\xde~\x8a\x9f\xb2i\x12A#?9_\x05S\x97\x1a\x0fC\"\r!\u05cd:<7\x83%\xa6\x8b(\xd7H\xed^\xc2\xfb\x898Ò\xee\xcd\xd90\xf7n\x8c\x99uLF\xd7>\xc6S\x81" +
+			"\xb6\x1cS6\xd5\xf2i\x12\xb1\xb8\xce\xe86vѺ\xb1|\x19\x89I2*\xed\xacb\x01\xfa\x92~\x19\x01éH1D\x90ϦJ\xba\xce\xff\xcf|e?U\xf1\xb2t\x10\xa0\x85\xd2Z\t\xa1\xfe\xef8>\xc8B\vns~\xd0(\x10\xe2\xd6\xfc\xb4\x04\xaa\x89\x8fx\xf8֭z\x8e\xe8\xfe]\xfd\xa6\xba\x9c\xbd\x96\x93\n{\x9d\t" +
+			"\x80\xad\xf9\u007f\xe5dg/~\xed@\xf4\xe2W3\x9e\x17\xbf\n4N\x82\xfeu\xed\xe6\xa7\xdd,T\xe3\x9b͡K\xb2\x9b\xf0\xe3t\x8aW4Zq\xf1\x18\xdb)>D\xab\xe0Lw\x83\xe9)gx\rъ*\x88V\x0e\xe3\xff'\xba\xban}8W\xe4\xb4YO\x96\x89;1\xbf#\x99\xbct*\xb2+\xdaG\x9a\xd4>\xe7\x1d\xe9" +
+			"\xac#L&]\xbfm͔H'\xd3\x00\x8c\xce:\x06\xa6\x04\xe9V\xb1\xc1\xd1F \x8bm\x9a\x88G\xe7\xedM\xa4!bWK\n7f\xe3Ƀ\xe2\x98e?\x9a\xe0m\x13u\x9e&F\xaeÿkW\xad\x88\xa7ɾ\xdfm4lѠÐ\x87Y\x8d\xaap\xb9:\x84\xf6\xd8\xc1.\x98MPʛ\x85]\xef\xb2\x0f\xe2\xff{" +
+			"\x1b7\xdcS\xa6Gh\x97D\xc1tV\x88\xc6%\b̾,\xbed\xed\xe7jlA\xf4\x8c#\xac\x80ys\x96\xb0\xa2\xbc\x8e\xb4\xe0\xb5\xd6\x1b8C\xbf\xf3A\xf6\xe0~\xa9\xe1$0\xb3%[iz\xd0]\xc4\xc7ouڀ\xfee\xbf\x80\xbe\xca2\x9c\xbb\xe2%5\xd6C)\x12杬'\rKٺ\x81+^\xfa[Dk\xed" +
+			"z\xaa\x8e\x85\xcb\x13˲\x15J\u007f\x19\x17\xa9\x8c\xac63@ì\x86,cOh\x9bݦ#\xc0d\x8e\x9b?o\xdf\r\xeb\x9e(\x9e\xd6\xdeH܇\xa1\xd5\x19P\x18E\xfe\xfe\xa3\x1d\xbci\av\xfa\xa8\x1cڲ\xb6IC\x80}\xa0ы\xd4\xd3\xf3\xae\x81s%\xf6\xea\x91#\xe2L\x8e\xb8\xb9\x83T\x10\xa4k\xa9a\xc6\x04|" +
+			"{\xa3^\xa7P#\x9eۦ\xc4\x12\xa9\x1cH\x0e4\x01UD\aάYښ\xe8q\xbd\xdb'\x93\xfe\xa2\xaf*\xf6&\x81\x11\x9dƟ\x9c5@N\xaf\xd1\xd8\x04\\\xe9O\xc5\xe5r\x86\xec\xa7\"\x8a\xaa\x81\x12o4P\x8a\\m\xe0\xe8\xa7\x06$\xf4%)\xa0\xb2Ԁ8\x91\xd7\xf1\x92s\x1d$\x8e\x12\xa9.\xfc\xa5\x81\xc0B\x98" +
+			"\xc7\x12\x10\xfb\xadXF\xa4q\xc0\xcb7\x94^[\x84giP\x86\xfb\v\xe3\x9d\x10\xad3\xc3]\xac\xa8d\x94\x84Qe\x86[N\xb7?\f\xc9\xf1\xe9\x1a\x03\xb5\xf1\x8f=\x06g>\xe30o߈#\x8f\x0e\xca$\xc6\xfd\x8eS\x81,\xf9\xb3\xbb2FA\xb9J\x13\x18\xbc\x1d5\x19\x83t\n\x8e(\xcbԅ\x86)\rM\x0e\xa0\x92#" +
+			"\x1f\x1f{;\x1fO\x1e\x8e\xc51\x88\x8f\x9a4\xdd\xe6_R:9\x11\x9eg>wq\x81\x9e\xcb\xc1@\xf7-Jz\x92\xdejZ\xbe\x87\xad\xb5\xadK\xcd@Ň\xd2\xca6\x84\xbfq\xc2=T)Y\a\xa5\xe5{\xd8Z۶89\xea3\x1b%\x98\x11C\xb3`u\x1e\xca\vW\aak\xf3PY\xbaR\xc2\f\xb4\xc0\xb7G\xdfd" +
+			"\x86T\x15\xe4\x16\xf3\f\xb3\x8d\xc2\x0e\x91\x9c\x1a\xde'\xfd\xaa\x17x\xf3\x8aq\xb7\xe67cd\xcdoA\x9e\x16fãl\xe9\\~M\xf4\x1a˚.@z\xb0_\xd9 AFI\x89[\x1c\xecM\xb3\xa4X\xea\xe7\x83\xdal\x0e\xba\xdea\a0$\xf9P\xd5\x16\xc1\xa5\xca\x18\xd5\x17\xea\xcc\xed\xa5%\x97\x83H,\x06o\xe8\xe3U\xd7" +
+			"\xa3\xe1!\xcbhgrs\xd9\x05&PK\xdf|r\xfcPj\x9c{\xb6\xb5\xc0s\"\xdc&\xb7LMǽn'\x04*o\x8ar\x92\xefUP,\b\xe9VDi\x89\xf4BA\vHJ\xb1#\xd6S\xaf´ښ\xc2\xf5\xe2\xebw'#,M\xe9NFq\x99R\x9f\xa2l\x197\x859c\xba\xf9\x95\x8eb\xa1\xd7\xeb\xb6s\xa5" +
+			";V\xa8\x91\xc2u8Z\xaaR\x95j\x0ez\xc2u\xb3\xd5~\xa7\vEG/\xc2J`\xcc\xddÙ\xc2|\xb5\x06S\xf7x\x11\xbb\xb9L\xb2(\xbf\x14c\xe1\x0f\x9fSA\xba\x05\x87w\x98\xf2\x14\xe8\xed\xef\x91`\xf9\xc6\f\x95Z\x0f\x83\xfc\xc1K\"\fx\xfb\xe3Y\xd2\xcdG\x9a\x1fvr\x1c\x82\x15G5\xb8\x11\xfdbd:\xea'" +
+			"\x0e%\x98r\xe3\xab\xfa\x97~\x00zzF\x97o\xf6;\xfcL\xedV\xcf\xfd\x87\xd33:\xf7ߖD\xe6\x88\x15\xb5\xc4#\xb9\x92\xf6Z\x9a.\xe2h\x9dƆ\xd284a\x16E,e\x80;\xa7\x80v\x12{zF\x95\xb3SطI\v\xc0\x17D\x98A\a\xde\xf0C\x85(\xf6p\xb7\xe6\x19\x05\x1b\xfd\x12\xc7Q\xe9\x01D\x96_\xa6" +
+			"q4\xa7,\x05\nG`%Va\x16\xa7\xcf1\xedA\x8d\xe4>f\xe1\xcd*铩 \xa6\x84ъ\xe0K\x130\v@\xd1\xc0\xd9kS\x81r\xc1.\xefT\xbd\x06\x82\xbb\xa6i\xb8*ۄj<\x1c#ac\u05cb\xdck\xbfy\xec\x929\x05\xefI\xa6\xed\x13s\xec\xb6Pk\xccW\xbb\x8d\x14\x02\xad\xcb3ҭ\xa3\xe5\"\x99" +
+			"U\u007f\x8d7\xa8\xa0\xf2\xd6q\"\x04y1\x9e\x9e\xfd\x14]\xa1JѤ\x94s\x18w\xa8\x80D\x10\x8c\xe2\x8f-hO\x02\x0eo\xb6\xf2\xc8'\xc7X\xc0\f\xa8\x00Н\x1d[3\x1d\xa10\xcc\x10!\xc2nn\x82\xa5e\xf7b\xd6\x0e\xb4}\x1d!j\xa7\xd1K\f7\xc5\xe1Y\xe6L~\xd0\x06\x94d\xb6\x9c\xc5\xf8أ=[\xa3\x9e" +
+			"\xd4\xe3\x8b\xd13\xae\x916D\x90\xd9HY#\r\ua4ce\x96\x81\xafW\x91!\t\x94\x91\xce\xd9\t\xe5\x16\xa1\xf36\x9b\x06\xccd\x85\x94;\xdf\xc7\x1ay\x83\xc1\xb2\r\xcb\x16\xfdd\xa0Nɬ\x01\x06>\xfb<\xcd\xcbX\xe2\xb4\xe6t\xd65\xf8\xf7$A\xf6\x84\a\xbdM\x82\xb4\xa4\U000fe2e1\xa6k\xcdT\xae`\xb3\xee\x92$5\x0f" +
+			"\x1c\xb3/\x1e\xf7R1/\x13S\xcf\xddW.\xcc)>\xe7\x82\xee%\x9d\aoX\xfc\x04\xdeϴ\xcep\x83ˆ\xda\a\x12\x8a\x9c\xe9ɭ\xd3k\x99\x04{\u007fX\v\r\xad\xeaU\xbdF.[\xd5\u007f\xddM\xee\xcbu\n\"Ȕ\x9b3\xa53Л\x95\xf1\xca`J\aF\xe9\xb5@\x88%ا\x94Ǉ\xeeu\x85?\xf4\xa6i" +
+			"\xc9T$\x1a\x93%8z\xe3\f\x16e\"R\x0f\xba\xdb>\\\x94f\x89\xd0S\xae\x84\xbf\xda\xef\xa9\xc0\x87\xb2\a\xe11سxc\x8b\xa0U\xb0m\xd3\x18u\xc4\x18\xaa\xe7\x8b$\x8d@.\xdaiq`xwۖ\x12\x92Ζ\xf6\b\xd6Ǉ\xcb\xdfPo\x0f^\xdb\xe4\xbfp3[\x99\xe8x\x19S\x1e\xb9\xff\xa5\xb4\xff\xa5\xb4\x16" +
+			"\xa5\x99\xb3ìo\x01\x05\x91-\r\x982s\xde\xd5.\xbbs\xfa\u007f9U<u\xdcCwN\xa6 \xcd17\x85\xc1\x8b=\xfdFIr?\xc6jV\x8e\x1a-}\xd6(\x1e)\x84\x17\xec\xba.\xb5\xdb,\x81\xad\xa0\xbb@\x18\xc2\xe3=C\bV\x88\xfaK\x1e\xa8\x97\xa5\x8a,\x1eypn\xb2dhY\xa0\xec\t\xa5³\xdb\xe5" +
+			"%\xee\x91\xfaɚ\xd3\xfe\"x\x9b\xafQ*\x96l\x12\xe2\x95\xd16a\xabԘ\x99\xc9U3\xaf]N{\xe4\xb3\xdf\xcezm'\xb6.\x02\x1e\x01\xd2dkR\xf3=\x19\xe2?\xc4â\xcdx 3\x8b9\xe3?:\x12\x165\xd5\xff\f\xd5?\x13\x92B]\\\xa3\xa8\xba\x1f\x96^\xbc\x06\xf5\xe47\xce\xcc\xc9\x107\xc7\xe3(\xd6z" +
+			"\x99\xe1ؚ\xaa\x8cq\x13<\xde1r!y\x80\xb7\x17\xbe\x10\xa9\x84\x8d\x88(\x9c\x05gG\x18\xa5\x06\xff\x80g\xf7ի\xdd\x17/\x06\xa3n\xecXt\x1b\xec?\xfex\xb8\\\x0e\\\xe7C\xd8\xcee\x88\x9b\x14\x8fN\xa2d\xb3چ@\xb9\x8e@\x0eQ\xbc-ep\x84ٱ\xd5\xd4*\xe2\xb1\xd1f\xbd\xa9\xf5\xa7&A\x06\xb4g\b" +
+			"\xbb\xd8)!qnt\x92\xabq\xab\xad\xee\"\xf8.\x8f6,\x80*\x0e@\xa3\x00b.\u007f\xac\x96\xa9ϾX\x90\x11g\xb7ކa\xbeZ\xac\x88\xcb<\xbd\x88}V\x16\x93\xceu\x1b`\x99}\x17\xcbbj\xb1\x1b\xa7\x89\x15\xfb\x06\x19\x8d\x8cG\xfeؖ\xa36H\xdd3\xf1\xe1\x1b\xact\xe1\x98FI\xf5\xcd\u007f\xe7x[h\\\xa8" +
+			"\x88\x91.\x9aQ0\xb4\xb7\xc7`\xb5~Y\x8eˊn\xb3\xa0V\xccm8<\x84m\rv\xf2s\xf8\xe3\xdc8O\xe6m\xd6z\xa4\xd88pz\x03\x8d\xf7\x83\x9e\xe3\xad\xfcˤ\xd4=\xb4\x0e37\xaa\x8c1\t'\xb5\x9c\"G\x0e\xd1;\xb9\xb1\x9a\xe5\x1b\x1fg\xeaO\xe6\x18RL\xce\xf8lovƇ\x89\xdb\x19;i'\x1c\xda" +
+			"\xb2\xc0g3s\xa0\xbf\x8cE\x8d\x9a\x15}\xdeY߄s\x14T\x8b8\x93VEi\xcd\xe9ݜ\xaf\xa0\x06\x1an\xd715ɢp_˳a\xb90\f\x1f\x1ah\x02\xb8]u\xa6\f\x88ܦ\xdf[wǇ'HEϐ\xce`\x9b\x19\xb4\xb4V\xe4\x0e5\xaa\xfe\x94PWH\xffg\xa6\xe968\xeeY\x95\xff\xba,\xdd^" +
+			"%\xf1\x90vf\xfd*7q\xabK/ElN\x9d\x17l\xec\x1f\xef|\xb8\xf6G'\xa3\xf1\x1c\xf5\x81\xfdw냽\xbd\x89\x1apd\xe8\x94\x16\xaf\xea\xf6d\xdd*\xa7\xb5Ýd\xc9\xe7\xab5\x81\xec[\u007fH#\xa6\x88\xb9o3\xbe\x17\x8e\xf6\xbbo\a\xf3\xd9\xeb\r\xf9\u007f\x03\x00\x00\xff\xff\xa7 z\xee\x8ej\x01\x00",
 	},
 
 	"/js/config.ts": {
 		local: "web/static/js/config.ts",
-		size:  10607,
+		size:  10625,
 		compressed: "" +
 			"\x1f\x8b\b\x00\x00\tn\x88\x00\xff\xccZos\xdb6\xd2\u007f-\u007f\nD\x93)\xa1H\xa5\xec\xcc<\xcf\v+N'Is\x97t\xd2\xf6&v\xdb\x17\x96\xeb@$$1\xa6H\x95\x04\xe5\xb8\n\xbf\xfb\xed.\x00\x12\xa0$\xdb7\xf7\xb73\xa9\xc8\xc5\xeeb\xb1X\xec\xfe\x16t\x92)Y\xccE$\xd9\xfb7y6O\x16\xe7Q\xbe\x96L" +
 			"~Q2\x8bK\xf6\xfeu^V\x99\xa6m\x8fz\xe31S0\xc4\xd2\\\xc4I\xb6\x18gb\x93,\x84J\xf2\xec\xa8\x17\x91\xf85\x8e\x9f\xb2R\x150>9\xea\x952\x95\x91\x92\xf1\xb5He\xe1\x0e$J\xae\xcaS\xb6e\x97\xean-\xed\xc0\x95}\xb8\xbc\x9a\xb0\x1a\xe5\xa3\"OӋ\xfc\x94q\xe2ӣ#\x96\x89\x95}\x19\xb0\xb3\x97" +
@@ -5764,9 +5764,9 @@ var _escData = map[string]*_escFile{
 			"M\xee[\xab\x97?\x9c5\xef|Ci\x95\x1c\xe8\"\xfe\xa70\xaa9l\xc6&\x95[\xb0F\xac{\xb0+M\x8d\xdc\x1ec\a\xf7\u0091\xde'\xdbL\xe2[?x\f\x12\xf6\xb0n\x035\x89\x19\x80\x8d\x99\xc0\x05\xc3\x1av\xea<\x86\xbc\r\x88\xd5p\xfa\x05`\\\x00\xba\x88wA\x98\x01T9a\xab$\xab\x94\xec*z\xee(ڙe" +
 			"/\xe4\xae\xffK\xed\"9\r\x10\x1a\x84\x1b\xfa\xdcH\xa8\xfc\x10?l\xd1\x0ew\xb3\x90CB\xce)5\"t|\x1eX\r\xf1\xb4&y\x87\xe6\x01Q\x9f\xf9_\xd1\n;W\x06n\xcf;q\a\xbd?x\xb0\\ԙ\xbcӴ\x89W\xab\xc3w\xa2\xb47\xb6{\xb2\a^A\a\xa3\x96q\xd2\x16\xaf\x03\x8d\xf9\xbf\xad\xe1n\xcbR{\xd3" +
 			"\xb6\xa7\x19\uf5be?o\xd1W\x9d\xbf\xaf@\xc5\xe6^~\x83W\xad\xa9\x88$\x1f\xf3\xcbѶ惫\xc1x\x81\u007f\xdap2\xad\x00X̂\x9d>~\xe7\xaf/p\x02\xef\xcf/\xdc\xeb\x1a\xf4\xf4&\x8c!4\xec\xb7s\xcc2\x1b\xed\x03\x0f\xeen\x1a\xbf\xd8.ȗsV\x8e\xa7Tܠ\aq\xda\xf0F\xdeY*\x18\x98\xbd\xc6" +
-			"\xb6\x05{˛\xe6Cm\u007f۶i\x11\xf66\xfbx\xea\x96G8\x1fo\x81\xa5\xacf\xe0>~<j\xf5\xb7I\xbd\xed@\x1bN\xacm\r\xe7\xf0d\xe4\xcc\xf9O^J\x89\xf6s\xf3#2\x8b\x93\xad7\xfaFjO\x9eyԡ\xb6\\\xfb\xce\xf1?\x8c\x947a\xfb\xf1Z\x1fc\xfd:1\xa3\xe6\x8b4\r\xbd\x86\xe7G\x9c\xac\xcd" +
-			"c\x0e\x95\xc5\xd5ݸ\xb2@Ͻ\xb4j?{vι\xb9\x8dt/5\x0e.\xc60\x98\xf5\xe0\x9f\xe1\x840W\xa9^\x95\xef\xd4*\xe5\xcd\x02]ܡ[\b\xf6\xc3\xf9\xcf?\x85:\x94\x92\xf9\x9df\x05\x98 Ft:\xe0\x802\x16\xb8bv\xf9\xc4H\x00\xb9܋]i\xfc7\xfdj>șT\xa0Y'G5`\xf5\xbf\a" +
-			"\x00\x00\xff\xffT\xea\xecvo)\x00\x00",
+			"\xb6\x05{˛\xe6Cm\u007f۶i\x11\xf66\xfbx\xea\x96G8\x1fo\x81\xa5\xacf\xe0>~<j\xf5\xb7I\xbd\xed@\x1bN\xacm\r\xe7\xf0d\xe4\xcc\xf9O^J\x89\xf6s\xf3#2\x8b\x93\xad7\xfaFjO\x9eyԡ\xb6\\\xfb\xce\xf1?\x8c\x947a\xfb\xf1Z\x1fc\xfd:1\xa3\xe6\x8b4\xfe\xd9J\b \xacT\xaf" +
+			"\xcawj\x95\xea\x13\xfb\x1a\x06\x1fs\xd66\x8f9f\x16iw#\xcdB?\xf7\x1a\xab\xfd\x10\xda9\xf9\xe6~ҽ\xe68\xb8<\xc3\xf0\xb8\x15ZxDM\x05\xfb\xe1\xfc\xe7\x9fB\x1d\\\xc9\xfcN\xb3\x02p\x10#:/pd\x19\v\\1\xbb|b$\xc8\\\xeeE\xb34\xfe\x9b~5\x9f\xe8LrЬ\x93\xa3\x1a\xd0\xfb\xdf\x03\x00" +
+			"\x00\xff\xff\xe3\xed\xb0\xa0\x81)\x00\x00",
 	},
 
 	"/js/d3.d.ts": {
diff --git a/cmd/bosun/web/static/js/bosun.js b/cmd/bosun/web/static/js/bosun.js
index 7f06ddb..43bcfd2 100644
--- a/cmd/bosun/web/static/js/bosun.js
+++ b/cmd/bosun/web/static/js/bosun.js
@@ -649,7 +649,7 @@ bosunControllers.controller('ConfigCtrl', ['$scope', '$http', '$location', '$rou
             $http.post(url, $scope.config_text)
                 .success(function (data) {
                 v.subject = data.Subject;
-                v.body = data.Body;
+                v.body = $sce.trustAsHtml(data.Body);
             })
                 .error(function (error) {
                 v.error = error;
diff --git a/cmd/bosun/web/static/js/config.ts b/cmd/bosun/web/static/js/config.ts
index 9750ead..92b52b8 100644
--- a/cmd/bosun/web/static/js/config.ts
+++ b/cmd/bosun/web/static/js/config.ts
@@ -360,7 +360,7 @@ bosunControllers.controller('ConfigCtrl', ['$scope', '$http', '$location', '$rou
 		$http.post(url, $scope.config_text)
 			.success((data) => {
 				v.subject = data.Subject;
-				v.body = data.Body;
+				v.body = $sce.trustAsHtml(data.Body);
 			})
 			.error((error) => {
 				v.error = error;
diff --git a/cmd/bosun/web/web.go b/cmd/bosun/web/web.go
index 5ccd9df..8095b51 100644
--- a/cmd/bosun/web/web.go
+++ b/cmd/bosun/web/web.go
@@ -9,7 +9,6 @@ import (
 	"io"
 	"io/ioutil"
 	"log"
-	"net"
 	"net/http"
 	"net/http/httputil"
 	"net/url"
@@ -146,9 +145,6 @@ func (rw *relayWriter) WriteHeader(code int) {
 }
 
 func (rp *relayProxy) ServeHTTP(responseWriter http.ResponseWriter, r *http.Request) {
-	if !IPAuthorized(responseWriter, r) {
-		return
-	}
 	clean := func(s string) string {
 		return opentsdb.MustReplace(s, "_")
 	}
@@ -194,9 +190,6 @@ func indexTSDB(r *http.Request, body []byte) {
 }
 
 func IndexTSDB(w http.ResponseWriter, r *http.Request) {
-	if !IPAuthorized(w, r) {
-		return
-	}
 	body, err := ioutil.ReadAll(r.Body)
 	if err != nil {
 		log.Println(err)
@@ -302,24 +295,7 @@ func HealthCheck(t miniprofiler.Timer, w http.ResponseWriter, r *http.Request) (
 	return h, nil
 }
 
-func IPAuthorized(w http.ResponseWriter, r *http.Request) bool {
-	ra := strings.Split(r.RemoteAddr, ":")[0]
-	ip := net.ParseIP(ra)
-	if ip == nil {
-		http.Error(w, fmt.Sprintf("Could not parse client IP %v", ra), 500)
-		return false
-	}
-	if !schedule.Conf.PutAuthorized(ip) {
-		http.Error(w, fmt.Sprintf("IP %v not authorized", ip), 403)
-		return false
-	}
-	return true
-}
-
 func PutMetadata(t miniprofiler.Timer, w http.ResponseWriter, r *http.Request) (interface{}, error) {
-	if !IPAuthorized(w, r) {
-		return nil, nil
-	}
 	d := json.NewDecoder(r.Body)
 	var ms []metadata.Metasend
 	if err := d.Decode(&ms); err != nil {
diff --git a/cmd/scollector/collectors/cassandra_unix.go b/cmd/scollector/collectors/cassandra_unix.go
deleted file mode 100644
index fc873ec..0000000
--- a/cmd/scollector/collectors/cassandra_unix.go
+++ /dev/null
@@ -1,52 +0,0 @@
-// +build darwin linux
-
-package collectors
-
-import (
-	"strings"
-
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-	"bosun.org/util"
-)
-
-func init() {
-	collectors = append(collectors, &IntervalCollector{F: c_nodestats_cfstats_linux})
-}
-
-func c_nodestats_cfstats_linux() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	var keyspace, table string
-	util.ReadCommand(func(line string) error {
-		fields := strings.Split(strings.TrimSpace(line), ": ")
-		if len(fields) != 2 {
-			return nil
-		}
-		if fields[0] == "Keyspace" {
-			keyspace = fields[1]
-			table = ""
-			return nil
-		}
-		if fields[0] == "Table" {
-			table = fields[1]
-			return nil
-		}
-		metric := strings.Replace(fields[0], " ", "_", -1)
-		metric = strings.Replace(metric, "(", "", -1)
-		metric = strings.Replace(metric, ")", "", -1)
-		metric = strings.Replace(metric, ",", "", -1)
-		metric = strings.ToLower(metric)
-		values := strings.Fields(fields[1])
-		if values[0] == "NaN" {
-			return nil
-		}
-		value := values[0]
-		if table == "" {
-			Add(&md, "cassandra.tables."+metric, value, opentsdb.TagSet{"keyspace": keyspace}, metadata.Unknown, metadata.None, "")
-		} else {
-			Add(&md, "cassandra.tables."+metric, value, opentsdb.TagSet{"keyspace": keyspace, "table": table}, metadata.Unknown, metadata.None, "")
-		}
-		return nil
-	}, "nodetool", "cfstats")
-	return md, nil
-}
diff --git a/cmd/scollector/collectors/collectors.go b/cmd/scollector/collectors/collectors.go
index be4f72f..22cdfd2 100644
--- a/cmd/scollector/collectors/collectors.go
+++ b/cmd/scollector/collectors/collectors.go
@@ -48,6 +48,7 @@ const (
 	osNetErrors        = "os.net.errs"
 	osNetMulticast     = "os.net.packets_multicast"
 	osNetPackets       = "os.net.packets"
+	osNetPauseFrames   = "os.net.pause_frames"
 	osNetUnicast       = "os.net.packets_unicast"
 	osSystemUptime     = "os.system.uptime"
 )
diff --git a/cmd/scollector/collectors/cpu_windows.go b/cmd/scollector/collectors/cpu_windows.go
deleted file mode 100644
index 43d429a..0000000
--- a/cmd/scollector/collectors/cpu_windows.go
+++ /dev/null
@@ -1,133 +0,0 @@
-package collectors
-
-import (
-	"strings"
-
-	"bosun.org/_third_party/github.com/StackExchange/wmi"
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-)
-
-func init() {
-	collectors = append(collectors, &IntervalCollector{F: c_cpu_windows})
-	collectors = append(collectors, &IntervalCollector{F: c_cpu_info_windows})
-}
-
-func c_cpu_windows() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_PerfRawData_PerfOS_Processor
-	var q = wmi.CreateQuery(&dst, "")
-	err := queryWmi(q, &dst)
-	if err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	var used, num uint64
-	var winCPUTotalPerfOS *Win32_PerfRawData_PerfOS_Processor
-	for _, v := range dst {
-		if v.Name == "_Total" {
-			winCPUTotalPerfOS = &v
-			continue
-		}
-		ts := TSys100NStoEpoch(v.Timestamp_Sys100NS)
-		tags := opentsdb.TagSet{"cpu": v.Name}
-		num++
-		//Divide by 1e5 because: 1 seconds / 100 Nanoseconds = 1e7. This is the percent time as a decimal, so divide by two less zeros to make it the same as the result * 100.
-		used += (v.PercentUserTime + v.PercentPrivilegedTime + v.PercentInterruptTime) / 1e5
-		AddTS(&md, winCPU, ts, v.PercentPrivilegedTime/1e5, opentsdb.TagSet{"type": "privileged"}.Merge(tags), metadata.Counter, metadata.Pct, descWinCPUPrivileged)
-		AddTS(&md, winCPU, ts, v.PercentInterruptTime/1e5, opentsdb.TagSet{"type": "interrupt"}.Merge(tags), metadata.Counter, metadata.Pct, descWinCPUInterrupt)
-		AddTS(&md, winCPU, ts, v.PercentUserTime/1e5, opentsdb.TagSet{"type": "user"}.Merge(tags), metadata.Counter, metadata.Pct, descWinCPUUser)
-		AddTS(&md, winCPU, ts, v.PercentIdleTime/1e5, opentsdb.TagSet{"type": "idle"}.Merge(tags), metadata.Counter, metadata.Pct, descWinCPUIdle)
-		AddTS(&md, "win.cpu.interrupts", ts, v.InterruptsPersec, tags, metadata.Counter, metadata.Event, descWinCPUInterrupts)
-		Add(&md, "win.cpu.dpcs", v.DPCRate, tags, metadata.Gauge, metadata.Event, descWinCPUDPC)
-	}
-	if num > 0 {
-		cpu := used / num
-		Add(&md, osCPU, cpu, nil, metadata.Counter, metadata.Pct, "")
-	}
-	if winCPUTotalPerfOS != nil {
-		v := winCPUTotalPerfOS
-		ts := TSys100NStoEpoch(v.Timestamp_Sys100NS)
-		AddTS(&md, winCPUTotal, ts, v.PercentPrivilegedTime/1e5, opentsdb.TagSet{"type": "privileged"}, metadata.Counter, metadata.Pct, descWinCPUPrivileged)
-		AddTS(&md, winCPUTotal, ts, v.PercentInterruptTime/1e5, opentsdb.TagSet{"type": "interrupt"}, metadata.Counter, metadata.Pct, descWinCPUInterrupt)
-		AddTS(&md, winCPUTotal, ts, v.PercentUserTime/1e5, opentsdb.TagSet{"type": "user"}, metadata.Counter, metadata.Pct, descWinCPUUser)
-		AddTS(&md, winCPUTotal, ts, v.PercentIdleTime/1e5, opentsdb.TagSet{"type": "idle"}, metadata.Counter, metadata.Pct, descWinCPUIdle)
-		AddTS(&md, "win.cpu_total.interrupts", ts, v.InterruptsPersec, nil, metadata.Counter, metadata.Event, descWinCPUInterrupts)
-		Add(&md, "win.cpu_total.dpcs", v.DPCRate, nil, metadata.Gauge, metadata.Event, descWinCPUDPC)
-		AddTS(&md, winCPUCStates, ts, v.PercentC1Time/1e5, opentsdb.TagSet{"cpu": "total", "type": "c1"}, metadata.Counter, metadata.Pct, descWinCPUC1)
-		AddTS(&md, winCPUCStates, ts, v.PercentC2Time/1e5, opentsdb.TagSet{"cpu": "total", "type": "c2"}, metadata.Counter, metadata.Pct, descWinCPUC2)
-		AddTS(&md, winCPUCStates, ts, v.PercentC3Time/1e5, opentsdb.TagSet{"cpu": "total", "type": "c3"}, metadata.Counter, metadata.Pct, descWinCPUC3)
-	}
-	return md, nil
-}
-
-const (
-	winCPU               = "win.cpu"
-	winCPUTotal          = "win.cpu_total"
-	winCPUCStates        = "win.cpu.time_cstate"
-	descWinCPUPrivileged = "Percentage of non-idle processor time spent in privileged mode."
-	descWinCPUInterrupt  = "Percentage of time that the processor spent receiving and servicing hardware interrupts during the sample interval."
-	descWinCPUUser       = "Percentage of non-idle processor time spent in user mode."
-	descWinCPUIdle       = "Percentage of time during the sample interval that the processor was idle."
-	descWinCPUInterrupts = "Average number of hardware interrupts that the processor is receiving and servicing in each second."
-	descWinCPUDPC        = "Rate at which deferred procedure calls (DPCs) are added to the processor DPC queue between the timer tics of the processor clock."
-	descWinCPUC1         = "Percentage of time that the processor spends in the C1 low-power idle state, which is a subset of the total processor idle time."
-	descWinCPUC2         = "Percentage of time that the processor spends in the C-2 low-power idle state, which is a subset of the total processor idle time."
-	descWinCPUC3         = "Percentage of time that the processor spends in the C3 low-power idle state, which is a subset of the total processor idle time."
-)
-
-type Win32_PerfRawData_PerfOS_Processor struct {
-	DPCRate               uint32
-	InterruptsPersec      uint32
-	Name                  string
-	PercentC1Time         uint64
-	Timestamp_Sys100NS    uint64
-	PercentC2Time         uint64
-	PercentC3Time         uint64
-	PercentIdleTime       uint64
-	PercentInterruptTime  uint64
-	PercentPrivilegedTime uint64
-	PercentProcessorTime  uint64
-	PercentUserTime       uint64
-}
-
-func c_cpu_info_windows() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_Processor
-	var q = wmi.CreateQuery(&dst, `WHERE Name <> '_Total'`)
-	err := queryWmi(q, &dst)
-	if err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		tags := opentsdb.TagSet{"cpu": strings.Replace(v.DeviceID, "CPU", "", 1)}
-		Add(&md, osCPUClock, v.CurrentClockSpeed, tags, metadata.Gauge, metadata.MHz, osCPUClockDesc)
-		Add(&md, "win.cpu.clock", v.CurrentClockSpeed, tags, metadata.Gauge, metadata.MHz, descWinCPUClock)
-		Add(&md, "win.cpu.clock_max", v.MaxClockSpeed, tags, metadata.Gauge, metadata.MHz, descWinCPUClockMax)
-		Add(&md, "win.cpu.voltage", v.CurrentVoltage, tags, metadata.Gauge, metadata.V10, descWinCPUVoltage)
-		Add(&md, "win.cpu.cores_physical", v.NumberOfCores, tags, metadata.Gauge, metadata.Count, descWinCPUCores)
-		Add(&md, "win.cpu.cores_logical", v.NumberOfLogicalProcessors, tags, metadata.Gauge, metadata.Count, descWinCPUCoresLogical)
-		if v.LoadPercentage != nil {
-			Add(&md, "win.cpu.load", *v.LoadPercentage, tags, metadata.Gauge, metadata.Pct, descWinCPULoad)
-		}
-	}
-	return md, nil
-}
-
-const (
-	descWinCPUClock        = "Current speed of the processor, in MHz."
-	descWinCPUClockMax     = "Maximum speed of the processor, in MHz."
-	descWinCPUVoltage      = "Voltage of the processor."
-	descWinCPUCores        = "Number of cores for the current instance of the processor."
-	descWinCPUCoresLogical = "Number of logical processors for the current instance of the processor."
-	descWinCPULoad         = "Load capacity of each processor, averaged to the last second."
-)
-
-type Win32_Processor struct {
-	CurrentClockSpeed         uint32
-	CurrentVoltage            *uint16
-	LoadPercentage            *uint16
-	MaxClockSpeed             uint32
-	DeviceID                  string
-	NumberOfCores             uint32
-	NumberOfLogicalProcessors uint32
-}
diff --git a/cmd/scollector/collectors/dell_hw.go b/cmd/scollector/collectors/dell_hw.go
deleted file mode 100644
index a78a741..0000000
--- a/cmd/scollector/collectors/dell_hw.go
+++ /dev/null
@@ -1,307 +0,0 @@
-package collectors
-
-import (
-	"fmt"
-	"strconv"
-	"strings"
-	"time"
-
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-	"bosun.org/util"
-)
-
-func init() {
-	const interval = time.Minute * 5
-	collectors = append(collectors,
-		&IntervalCollector{F: c_omreport_chassis, Interval: interval},
-		&IntervalCollector{F: c_omreport_fans, Interval: interval},
-		&IntervalCollector{F: c_omreport_memory, Interval: interval},
-		&IntervalCollector{F: c_omreport_processors, Interval: interval},
-		&IntervalCollector{F: c_omreport_ps, Interval: interval},
-		&IntervalCollector{F: c_omreport_ps_amps, Interval: interval},
-		&IntervalCollector{F: c_omreport_storage_battery, Interval: interval},
-		&IntervalCollector{F: c_omreport_storage_controller, Interval: interval},
-		&IntervalCollector{F: c_omreport_storage_enclosure, Interval: interval},
-		&IntervalCollector{F: c_omreport_storage_vdisk, Interval: interval},
-		&IntervalCollector{F: c_omreport_system, Interval: interval},
-		&IntervalCollector{F: c_omreport_temps, Interval: interval},
-		&IntervalCollector{F: c_omreport_volts, Interval: interval},
-	)
-}
-
-func c_omreport_chassis() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	readOmreport(func(fields []string) {
-		if len(fields) != 2 || fields[0] == "SEVERITY" {
-			return
-		}
-		component := strings.Replace(fields[1], " ", "_", -1)
-		Add(&md, "hw.chassis", severity(fields[0]), opentsdb.TagSet{"component": component}, metadata.Gauge, metadata.Ok, descDellHWChassis)
-	}, "chassis")
-	return md, nil
-}
-
-func c_omreport_system() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	readOmreport(func(fields []string) {
-		if len(fields) != 2 || fields[0] == "SEVERITY" {
-			return
-		}
-		component := strings.Replace(fields[1], " ", "_", -1)
-		Add(&md, "hw.system", severity(fields[0]), opentsdb.TagSet{"component": component}, metadata.Gauge, metadata.Ok, descDellHWSystem)
-	}, "system")
-	return md, nil
-}
-
-func c_omreport_storage_enclosure() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	readOmreport(func(fields []string) {
-		if len(fields) < 3 || fields[0] == "ID" {
-			return
-		}
-		id := strings.Replace(fields[0], ":", "_", -1)
-		Add(&md, "hw.storage.enclosure", severity(fields[1]), opentsdb.TagSet{"id": id}, metadata.Gauge, metadata.Ok, descDellHWStorageEnc)
-	}, "storage", "enclosure")
-	return md, nil
-}
-
-func c_omreport_storage_vdisk() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	readOmreport(func(fields []string) {
-		if len(fields) < 3 || fields[0] == "ID" {
-			return
-		}
-		id := strings.Replace(fields[0], ":", "_", -1)
-		Add(&md, "hw.storage.vdisk", severity(fields[1]), opentsdb.TagSet{"id": id}, metadata.Gauge, metadata.Ok, descDellHWVDisk)
-	}, "storage", "vdisk")
-	return md, nil
-}
-
-func c_omreport_ps() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	readOmreport(func(fields []string) {
-		if len(fields) < 3 || fields[0] == "Index" {
-			return
-		}
-		id := strings.Replace(fields[0], ":", "_", -1)
-		Add(&md, "hw.ps", severity(fields[1]), opentsdb.TagSet{"id": id}, metadata.Gauge, metadata.Ok, descDellHWPS)
-	}, "chassis", "pwrsupplies")
-	return md, nil
-}
-
-func c_omreport_ps_amps() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	readOmreport(func(fields []string) {
-		if len(fields) == 2 && strings.Contains(fields[0], "Current") {
-			i_fields := strings.Split(fields[0], "Current")
-			v_fields := strings.Fields(fields[1])
-			if len(i_fields) < 2 && len(v_fields) < 2 {
-				return
-			}
-			id := strings.Replace(i_fields[0], " ", "", -1)
-			Add(&md, "hw.chassis.current.reading", v_fields[0], opentsdb.TagSet{"id": id}, metadata.Gauge, metadata.A, descDellHWCurrent)
-		} else if len(fields) == 6 && (fields[2] == "System Board Pwr Consumption" || fields[2] == "System Board System Level") {
-			v_fields := strings.Fields(fields[3])
-			if len(v_fields) < 2 {
-				return
-			}
-			Add(&md, "hw.chassis.power.reading", v_fields[0], nil, metadata.Gauge, metadata.Watt, descDellHWPower)
-		}
-	}, "chassis", "pwrmonitoring")
-	return md, nil
-}
-
-func c_omreport_storage_battery() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	readOmreport(func(fields []string) {
-		if len(fields) < 3 || fields[0] == "ID" {
-			return
-		}
-		id := strings.Replace(fields[0], ":", "_", -1)
-		Add(&md, "hw.storage.battery", severity(fields[1]), opentsdb.TagSet{"id": id}, metadata.Gauge, metadata.Ok, descDellHWStorageBattery)
-	}, "storage", "battery")
-	return md, nil
-}
-
-func c_omreport_storage_controller() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	readOmreport(func(fields []string) {
-		if len(fields) < 3 || fields[0] == "ID" {
-			return
-		}
-		c_omreport_storage_pdisk(fields[0], &md)
-		id := strings.Replace(fields[0], ":", "_", -1)
-		Add(&md, "hw.storage.controller", severity(fields[1]), opentsdb.TagSet{"id": id}, metadata.Gauge, metadata.Ok, descDellHWStorageCtl)
-	}, "storage", "controller")
-	return md, nil
-}
-
-// c_omreport_storage_pdisk is called from the controller func, since it needs the encapsulating id.
-func c_omreport_storage_pdisk(id string, md *opentsdb.MultiDataPoint) {
-	readOmreport(func(fields []string) {
-		if len(fields) < 3 || fields[0] == "ID" {
-			return
-		}
-		//Need to find out what the various ID formats might be
-		id := strings.Replace(fields[0], ":", "_", -1)
-		Add(md, "hw.storage.pdisk", severity(fields[1]), opentsdb.TagSet{"id": id}, metadata.Gauge, metadata.Ok, descDellHWPDisk)
-	}, "storage", "pdisk", "controller="+id)
-}
-
-func c_omreport_processors() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	readOmreport(func(fields []string) {
-		if len(fields) != 8 {
-			return
-		}
-		if _, err := strconv.Atoi(fields[0]); err != nil {
-			return
-		}
-		ts := opentsdb.TagSet{"name": replace(fields[2])}
-		Add(&md, "hw.chassis.processor", severity(fields[1]), ts, metadata.Gauge, metadata.Ok, descDellHWCPU)
-		metadata.AddMeta("", ts, "processor", clean(fields[3], fields[4]), true)
-	}, "chassis", "processors")
-	return md, nil
-}
-
-func c_omreport_fans() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	readOmreport(func(fields []string) {
-		if len(fields) != 8 {
-			return
-		}
-		if _, err := strconv.Atoi(fields[0]); err != nil {
-			return
-		}
-		ts := opentsdb.TagSet{"name": replace(fields[2])}
-		Add(&md, "hw.chassis.fan", severity(fields[1]), ts, metadata.Gauge, metadata.Ok, descDellHWFan)
-		fs := strings.Fields(fields[3])
-		if len(fs) == 2 && fs[1] == "RPM" {
-			i, err := strconv.Atoi(fs[0])
-			if err == nil {
-				Add(&md, "hw.chassis.fan.reading", i, ts, metadata.Gauge, metadata.RPM, descDellHWFanSpeed)
-			}
-		}
-	}, "chassis", "fans")
-	return md, nil
-}
-
-func c_omreport_memory() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	readOmreport(func(fields []string) {
-		if len(fields) != 5 {
-			return
-		}
-		if _, err := strconv.Atoi(fields[0]); err != nil {
-			return
-		}
-		ts := opentsdb.TagSet{"name": replace(fields[2])}
-		Add(&md, "hw.chassis.memory", severity(fields[1]), ts, metadata.Gauge, metadata.Ok, descDellHWMemory)
-		metadata.AddMeta("", ts, "memory", clean(fields[4]), true)
-	}, "chassis", "memory")
-	return md, nil
-}
-
-func c_omreport_temps() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	readOmreport(func(fields []string) {
-		if len(fields) != 8 {
-			return
-		}
-		if _, err := strconv.Atoi(fields[0]); err != nil {
-			return
-		}
-		ts := opentsdb.TagSet{"name": replace(fields[2])}
-		Add(&md, "hw.chassis.temps", severity(fields[1]), ts, metadata.Gauge, metadata.Ok, descDellHWTemp)
-		fs := strings.Fields(fields[3])
-		if len(fs) == 2 && fs[1] == "C" {
-			i, err := strconv.ParseFloat(fs[0], 64)
-			if err == nil {
-				Add(&md, "hw.chassis.temps.reading", i, ts, metadata.Gauge, metadata.C, descDellHWTempReadings)
-			}
-		}
-	}, "chassis", "temps")
-	return md, nil
-}
-
-func c_omreport_volts() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	readOmreport(func(fields []string) {
-		if len(fields) != 8 {
-			return
-		}
-		if _, err := strconv.Atoi(fields[0]); err != nil {
-			return
-		}
-		ts := opentsdb.TagSet{"name": replace(fields[2])}
-		Add(&md, "hw.chassis.volts", severity(fields[1]), ts, metadata.Gauge, metadata.Ok, descDellHWVolt)
-		if i, err := extract(fields[3], "V"); err == nil {
-			Add(&md, "hw.chassis.volts.reading", i, ts, metadata.Gauge, metadata.V, descDellHWVoltReadings)
-		}
-	}, "chassis", "volts")
-	return md, nil
-}
-
-// extract tries to return a parsed number from s with given suffix. A space may
-// be present between number ond suffix.
-func extract(s, suffix string) (float64, error) {
-	if !strings.HasSuffix(s, suffix) {
-		return 0, fmt.Errorf("extract: suffix not found")
-	}
-	s = s[:len(s)-len(suffix)]
-	return strconv.ParseFloat(strings.TrimSpace(s), 64)
-}
-
-// severity returns 0 if s is not "Ok" or "Non-Critical", else 1.
-func severity(s string) int {
-	if s != "Ok" && s != "Non-Critical" {
-		return 1
-	}
-	return 0
-}
-
-func readOmreport(f func([]string), args ...string) {
-	args = append(args, "-fmt", "ssv")
-	_ = util.ReadCommand(func(line string) error {
-		sp := strings.Split(line, ";")
-		for i, s := range sp {
-			sp[i] = clean(s)
-		}
-		f(sp)
-		return nil
-	}, "omreport", args...)
-}
-
-// clean concatenates arguments with a space and removes extra whitespace.
-func clean(ss ...string) string {
-	v := strings.Join(ss, " ")
-	fs := strings.Fields(v)
-	return strings.Join(fs, " ")
-}
-
-func replace(name string) string {
-	r, _ := opentsdb.Replace(name, "_")
-	return r
-}
-
-const (
-	descDellHWChassis        = "Overall status of chassis components."
-	descDellHWSystem         = "Overall status of system components."
-	descDellHWStorageEnc     = "Overall status of storage enclosures."
-	descDellHWVDisk          = "Overall status of virtual disks."
-	descDellHWPS             = "Overall status of power supplies."
-	descDellHWCurrent        = "Amps used per power supply."
-	descDellHWPower          = "Overall system power usage."
-	descDellHWStorageBattery = "Status of storage controller backup batteries."
-	descDellHWStorageCtl     = "Overall status of storage controllers."
-	descDellHWPDisk          = "Overall status of physical disks."
-	descDellHWCPU            = "Overall status of CPUs."
-	descDellHWFan            = "Overall status of system fans."
-	descDellHWFanSpeed       = "System fan speed."
-	descDellHWMemory         = "System RAM DIMM status."
-	descDellHWTemp           = "Overall status of system temperature readings."
-	descDellHWTempReadings   = "System temperature readings."
-	descDellHWVolt           = "Overall status of power supply volt readings."
-	descDellHWVoltReadings   = "Volts used per power supply."
-)
diff --git a/cmd/scollector/collectors/dfstat_darwin.go b/cmd/scollector/collectors/dfstat_darwin.go
deleted file mode 100644
index 4eace73..0000000
--- a/cmd/scollector/collectors/dfstat_darwin.go
+++ /dev/null
@@ -1,39 +0,0 @@
-package collectors
-
-import (
-	"strconv"
-	"strings"
-
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-	"bosun.org/util"
-)
-
-func init() {
-	collectors = append(collectors, &IntervalCollector{F: c_dfstat_darwin})
-}
-
-func c_dfstat_darwin() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	util.ReadCommand(func(line string) error {
-		fields := strings.Fields(line)
-		if line == "" || len(fields) < 9 || !IsDigit(fields[2]) {
-			return nil
-		}
-		mount := fields[8]
-		if strings.HasPrefix(mount, "/Volumes/Time Machine Backups") {
-			return nil
-		}
-		f5, _ := strconv.Atoi(fields[5])
-		f6, _ := strconv.Atoi(fields[6])
-		tags := opentsdb.TagSet{"mount": mount}
-		Add(&md, "darwin.disk.fs.total", fields[1], tags, metadata.Unknown, metadata.None, "")
-		Add(&md, "darwin.disk.fs.used", fields[2], tags, metadata.Unknown, metadata.None, "")
-		Add(&md, "darwin.disk.fs.free", fields[3], tags, metadata.Unknown, metadata.None, "")
-		Add(&md, "darwin.disk.fs.inodes.total", f5+f6, tags, metadata.Unknown, metadata.None, "")
-		Add(&md, "darwin.disk.fs.inodes.used", fields[5], tags, metadata.Unknown, metadata.None, "")
-		Add(&md, "darwin.disk.fs.inodes.free", fields[6], tags, metadata.Unknown, metadata.None, "")
-		return nil
-	}, "df", "-lki")
-	return md, nil
-}
diff --git a/cmd/scollector/collectors/disk_linux.go b/cmd/scollector/collectors/disk_linux.go
index cfc4b38..6ed64d0 100644
--- a/cmd/scollector/collectors/disk_linux.go
+++ b/cmd/scollector/collectors/disk_linux.go
@@ -9,13 +9,13 @@ import (
 
 	"bosun.org/metadata"
 	"bosun.org/opentsdb"
-	"bosun.org/util"
+//	"bosun.org/util"
 )
 
 func init() {
 	collectors = append(collectors, &IntervalCollector{F: c_iostat_linux})
-	collectors = append(collectors, &IntervalCollector{F: c_dfstat_blocks_linux})
-	collectors = append(collectors, &IntervalCollector{F: c_dfstat_inodes_linux})
+//	collectors = append(collectors, &IntervalCollector{F: c_dfstat_blocks_linux})
+//	collectors = append(collectors, &IntervalCollector{F: c_dfstat_inodes_linux})
 }
 
 var diskLinuxFields = []struct {
@@ -58,7 +58,7 @@ func removable(major, minor string) bool {
 	return strings.Trim(string(b), "\n") == "1"
 }
 
-var sdiskRE = regexp.MustCompile(`/dev/(sd[a-z])[0-9]?`)
+var sdiskRE = regexp.MustCompile(`/dev/(mmcblk)[0-9]?`)
 
 func removable_fs(name string) bool {
 	s := sdiskRE.FindStringSubmatch(name)
@@ -141,59 +141,59 @@ func c_iostat_linux() (opentsdb.MultiDataPoint, error) {
 	return md, err
 }
 
-func c_dfstat_blocks_linux() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	err := util.ReadCommand(func(line string) error {
-		fields := strings.Fields(line)
-		// TODO: support mount points with spaces in them. They mess up the field order
-		// currently due to df's columnar output.
-		if len(fields) != 6 || !IsDigit(fields[2]) {
-			return nil
-		}
-		fs := fields[0]
-		mount := fields[5]
-		tags := opentsdb.TagSet{"mount": mount}
-		os_tags := opentsdb.TagSet{"disk": mount}
-		metric := "linux.disk.fs."
-		ometric := "os.disk.fs."
-		if removable_fs(fs) {
-			metric += "rem."
-			ometric += "rem."
-		}
-		Add(&md, metric+"space_total", fields[1], tags, metadata.Gauge, metadata.Bytes, osDiskTotalDesc)
-		Add(&md, metric+"space_used", fields[2], tags, metadata.Gauge, metadata.Bytes, osDiskUsedDesc)
-		Add(&md, metric+"space_free", fields[3], tags, metadata.Gauge, metadata.Bytes, osDiskFreeDesc)
-		Add(&md, ometric+"space_total", fields[1], os_tags, metadata.Gauge, metadata.Bytes, osDiskTotalDesc)
-		Add(&md, ometric+"space_used", fields[2], os_tags, metadata.Gauge, metadata.Bytes, osDiskUsedDesc)
-		Add(&md, ometric+"space_free", fields[3], os_tags, metadata.Gauge, metadata.Bytes, osDiskFreeDesc)
-		st, _ := strconv.ParseFloat(fields[1], 64)
-		sf, _ := strconv.ParseFloat(fields[3], 64)
-		if st != 0 {
-			Add(&md, osDiskPctFree, sf/st*100, os_tags, metadata.Gauge, metadata.Pct, osDiskPctFreeDesc)
-		}
-		return nil
-	}, "df", "-lP", "--block-size", "1")
-	return md, err
-}
-
-func c_dfstat_inodes_linux() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	err := util.ReadCommand(func(line string) error {
-		fields := strings.Fields(line)
-		if len(fields) != 6 || !IsDigit(fields[2]) {
-			return nil
-		}
-		mount := fields[5]
-		fs := fields[0]
-		tags := opentsdb.TagSet{"mount": mount}
-		metric := "linux.disk.fs."
-		if removable_fs(fs) {
-			metric += "rem."
-		}
-		Add(&md, metric+"inodes_total", fields[1], tags, metadata.Gauge, metadata.Count, "")
-		Add(&md, metric+"inodes_used", fields[2], tags, metadata.Gauge, metadata.Count, "")
-		Add(&md, metric+"inodes_free", fields[3], tags, metadata.Gauge, metadata.Count, "")
-		return nil
-	}, "df", "-liP")
-	return md, err
-}
+//func c_dfstat_blocks_linux() (opentsdb.MultiDataPoint, error) {
+//	var md opentsdb.MultiDataPoint
+//	err := util.ReadCommand(func(line string) error {
+//		fields := strings.Fields(line)
+//		// TODO: support mount points with spaces in them. They mess up the field order
+//		// currently due to df's columnar output.
+//		if len(fields) != 6 || !IsDigit(fields[2]) {
+//			return nil
+//		}
+//		fs := fields[0]
+//		mount := fields[5]
+//		tags := opentsdb.TagSet{"mount": mount}
+//		os_tags := opentsdb.TagSet{"disk": mount}
+//		metric := "linux.disk.fs."
+//		ometric := "os.disk.fs."
+//		if removable_fs(fs) {
+//			metric += "rem."
+//			ometric += "rem."
+//		}
+//		Add(&md, metric+"space_total", fields[1], tags, metadata.Gauge, metadata.Bytes, osDiskTotalDesc)
+//		Add(&md, metric+"space_used", fields[2], tags, metadata.Gauge, metadata.Bytes, osDiskUsedDesc)
+//		Add(&md, metric+"space_free", fields[3], tags, metadata.Gauge, metadata.Bytes, osDiskFreeDesc)
+//		Add(&md, ometric+"space_total", fields[1], os_tags, metadata.Gauge, metadata.Bytes, osDiskTotalDesc)
+//		Add(&md, ometric+"space_used", fields[2], os_tags, metadata.Gauge, metadata.Bytes, osDiskUsedDesc)
+//		Add(&md, ometric+"space_free", fields[3], os_tags, metadata.Gauge, metadata.Bytes, osDiskFreeDesc)
+//		st, _ := strconv.ParseFloat(fields[1], 64)
+//		sf, _ := strconv.ParseFloat(fields[3], 64)
+//		if st != 0 {
+//			Add(&md, osDiskPctFree, sf/st*100, os_tags, metadata.Gauge, metadata.Pct, osDiskPctFreeDesc)
+//		}
+//		return nil
+//	}, "df", "-lP", "--block-size", "1")
+//	return md, err
+//}
+//
+//func c_dfstat_inodes_linux() (opentsdb.MultiDataPoint, error) {
+//	var md opentsdb.MultiDataPoint
+//	err := util.ReadCommand(func(line string) error {
+//		fields := strings.Fields(line)
+//		if len(fields) != 6 || !IsDigit(fields[2]) {
+//			return nil
+//		}
+//		mount := fields[5]
+//		fs := fields[0]
+//		tags := opentsdb.TagSet{"mount": mount}
+//		metric := "linux.disk.fs."
+//		if removable_fs(fs) {
+//			metric += "rem."
+//		}
+//		Add(&md, metric+"inodes_total", fields[1], tags, metadata.Gauge, metadata.Count, "")
+//		Add(&md, metric+"inodes_used", fields[2], tags, metadata.Gauge, metadata.Count, "")
+//		Add(&md, metric+"inodes_free", fields[3], tags, metadata.Gauge, metadata.Count, "")
+//		return nil
+//	}, "df", "-liP")
+//	return md, err
+//}
diff --git a/cmd/scollector/collectors/disk_windows.go b/cmd/scollector/collectors/disk_windows.go
deleted file mode 100644
index 200dd51..0000000
--- a/cmd/scollector/collectors/disk_windows.go
+++ /dev/null
@@ -1,95 +0,0 @@
-package collectors
-
-import (
-	"bosun.org/_third_party/github.com/StackExchange/wmi"
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-)
-
-func init() {
-	collectors = append(collectors, &IntervalCollector{F: c_physical_disk_windows})
-	collectors = append(collectors, &IntervalCollector{F: c_diskspace_windows})
-}
-
-const (
-	//Converts 100nS samples to 1S samples
-	winDisk100nS_1S = 10000000
-
-	//Converts 100nS samples to 1mS samples
-	winDisk100nS_1mS = 1000000
-
-	//Converts 100nS samples to 0-100 Percent samples
-	winDisk100nS_Pct = 100000
-)
-
-func c_diskspace_windows() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_LogicalDisk
-	var q = wmi.CreateQuery(&dst, "WHERE DriveType = 3 AND FreeSpace <> null")
-	err := queryWmi(q, &dst)
-	if err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		tags := opentsdb.TagSet{"disk": v.Name}
-		space_used := v.Size - v.FreeSpace
-		Add(&md, "win.disk.fs.space_free", v.FreeSpace, tags, metadata.Gauge, metadata.Bytes, osDiskFreeDesc)
-		Add(&md, "win.disk.fs.space_total", v.Size, tags, metadata.Gauge, metadata.Bytes, osDiskTotalDesc)
-		Add(&md, "win.disk.fs.space_used", space_used, tags, metadata.Gauge, metadata.Bytes, osDiskUsedDesc)
-		Add(&md, osDiskFree, v.FreeSpace, tags, metadata.Gauge, metadata.Bytes, osDiskFreeDesc)
-		Add(&md, osDiskTotal, v.Size, tags, metadata.Gauge, metadata.Bytes, osDiskTotalDesc)
-		Add(&md, osDiskUsed, space_used, tags, metadata.Gauge, metadata.Bytes, osDiskUsedDesc)
-		if v.Size != 0 {
-			percent_free := float64(v.FreeSpace) / float64(v.Size) * 100
-			Add(&md, "win.disk.fs.percent_free", percent_free, tags, metadata.Gauge, metadata.Pct, osDiskPctFreeDesc)
-			Add(&md, osDiskPctFree, percent_free, tags, metadata.Gauge, metadata.Pct, osDiskPctFreeDesc)
-		}
-	}
-	return md, nil
-}
-
-type Win32_LogicalDisk struct {
-	FreeSpace uint64
-	Name      string
-	Size      uint64
-}
-
-func c_physical_disk_windows() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_PerfRawData_PerfDisk_PhysicalDisk
-	var q = wmi.CreateQuery(&dst, `WHERE Name <> '_Total'`)
-	err := queryWmi(q, &dst)
-	if err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		Add(&md, "win.disk.duration", v.AvgDiskSecPerRead/winDisk100nS_1mS, opentsdb.TagSet{"disk": v.Name, "type": "read"}, metadata.Counter, metadata.MilliSecond, "Time, in milliseconds, of a read from the disk.")
-		Add(&md, "win.disk.duration", v.AvgDiskSecPerWrite/winDisk100nS_1mS, opentsdb.TagSet{"disk": v.Name, "type": "write"}, metadata.Counter, metadata.MilliSecond, "Time, in milliseconds, of a write to the disk.")
-		Add(&md, "win.disk.queue", v.AvgDiskReadQueueLength/winDisk100nS_1S, opentsdb.TagSet{"disk": v.Name, "type": "read"}, metadata.Counter, metadata.Operation, "Number of read requests that were queued for the disk.")
-		Add(&md, "win.disk.queue", v.AvgDiskWriteQueueLength/winDisk100nS_1S, opentsdb.TagSet{"disk": v.Name, "type": "write"}, metadata.Counter, metadata.Operation, "Number of write requests that were queued for the disk.")
-		Add(&md, "win.disk.ops", v.DiskReadsPerSec, opentsdb.TagSet{"disk": v.Name, "type": "read"}, metadata.Counter, metadata.PerSecond, "Number of read operations on the disk.")
-		Add(&md, "win.disk.ops", v.DiskWritesPerSec, opentsdb.TagSet{"disk": v.Name, "type": "write"}, metadata.Counter, metadata.PerSecond, "Number of write operations on the disk.")
-		Add(&md, "win.disk.bytes", v.DiskReadBytesPerSec, opentsdb.TagSet{"disk": v.Name, "type": "read"}, metadata.Counter, metadata.BytesPerSecond, "Number of bytes read from the disk.")
-		Add(&md, "win.disk.bytes", v.DiskWriteBytesPerSec, opentsdb.TagSet{"disk": v.Name, "type": "write"}, metadata.Counter, metadata.BytesPerSecond, "Number of bytes written to the disk.")
-		Add(&md, "win.disk.percent_time", v.PercentDiskReadTime/winDisk100nS_Pct, opentsdb.TagSet{"disk": v.Name, "type": "read"}, metadata.Counter, metadata.Pct, "Percentage of time that the disk was busy servicing read requests.")
-		Add(&md, "win.disk.percent_time", v.PercentDiskWriteTime/winDisk100nS_Pct, opentsdb.TagSet{"disk": v.Name, "type": "write"}, metadata.Counter, metadata.Pct, "Percentage of time that the disk was busy servicing write requests.")
-		Add(&md, "win.disk.spltio", v.SplitIOPerSec, opentsdb.TagSet{"disk": v.Name}, metadata.Counter, metadata.PerSecond, "Number of requests to the disk that were split into multiple requests due to size or fragmentation.")
-	}
-	return md, nil
-}
-
-//See msdn for counter types http://msdn.microsoft.com/en-us/library/ms804035.aspx
-type Win32_PerfRawData_PerfDisk_PhysicalDisk struct {
-	AvgDiskReadQueueLength  uint64
-	AvgDiskSecPerRead       uint32
-	AvgDiskSecPerWrite      uint32
-	AvgDiskWriteQueueLength uint64
-	DiskReadBytesPerSec     uint64
-	DiskReadsPerSec         uint32
-	DiskWriteBytesPerSec    uint64
-	DiskWritesPerSec        uint32
-	Name                    string
-	PercentDiskReadTime     uint64
-	PercentDiskWriteTime    uint64
-	SplitIOPerSec           uint32
-}
diff --git a/cmd/scollector/collectors/dotnet_windows.go b/cmd/scollector/collectors/dotnet_windows.go
deleted file mode 100644
index 08eb9fe..0000000
--- a/cmd/scollector/collectors/dotnet_windows.go
+++ /dev/null
@@ -1,241 +0,0 @@
-package collectors
-
-import (
-	"regexp"
-	"strings"
-
-	"bosun.org/_third_party/github.com/StackExchange/wmi"
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-)
-
-var regexesDotNet = []*regexp.Regexp{}
-
-func init() {
-	AddProcessDotNetConfig = func(line string) error {
-		reg, err := regexp.Compile(line)
-		if err != nil {
-			return err
-		}
-		regexesDotNet = append(regexesDotNet, reg)
-		return nil
-	}
-	WatchProcessesDotNet = func() {
-		if len(regexesDotNet) == 0 {
-			// If no process_dotnet settings configured in config file, use this set instead.
-			regexesDotNet = append(regexesDotNet, regexp.MustCompile("^w3wp"))
-		}
-		c := &IntervalCollector{
-			F: c_dotnet_loading,
-		}
-		c.init = wmiInit(c, func() interface{} {
-			return &[]Win32_PerfRawData_NETFramework_NETCLRLoading{}
-		}, "", &dotnetLoadingQuery)
-		collectors = append(collectors, c)
-		c = &IntervalCollector{
-			F: c_dotnet_memory,
-		}
-		c.init = wmiInit(c, func() interface{} {
-			return &[]Win32_PerfRawData_NETFramework_NETCLRMemory{}
-		}, `WHERE ProcessID <> 0`, &dotnetMemoryQuery)
-		collectors = append(collectors, c)
-	}
-}
-
-var (
-	dotnetLoadingQuery string
-	dotnetMemoryQuery  string
-)
-
-func c_dotnet_loading() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_PerfRawData_NETFramework_NETCLRLoading
-	err := queryWmi(dotnetLoadingQuery, &dst)
-	if err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		if !nameMatches(v.Name, regexesDotNet) {
-			continue
-		}
-		id := "0"
-		raw_name := strings.Split(v.Name, "#")
-		name := raw_name[0]
-		if len(raw_name) == 2 {
-			id = raw_name[1]
-		}
-		// If you have a hash sign in your process name you don't deserve monitoring ;-)
-		if len(raw_name) > 2 {
-			continue
-		}
-		tags := opentsdb.TagSet{"name": name, "id": id}
-		Add(&md, "dotnet.current.appdomains", v.Currentappdomains, tags, metadata.Gauge, metadata.Count, descWinDotNetLoadingCurrentappdomains)
-		Add(&md, "dotnet.current.assemblies", v.CurrentAssemblies, tags, metadata.Gauge, metadata.Count, descWinDotNetLoadingCurrentAssemblies)
-		Add(&md, "dotnet.current.classes", v.CurrentClassesLoaded, tags, metadata.Gauge, metadata.Count, descWinDotNetLoadingCurrentClassesLoaded)
-		Add(&md, "dotnet.total.appdomains", v.TotalAppdomains, tags, metadata.Gauge, metadata.Count, descWinDotNetLoadingTotalAppdomains)
-		Add(&md, "dotnet.total.appdomains_unloaded", v.Totalappdomainsunloaded, tags, metadata.Gauge, metadata.Count, descWinDotNetLoadingTotalappdomainsunloaded)
-		Add(&md, "dotnet.total.assemblies", v.TotalAssemblies, tags, metadata.Gauge, metadata.Count, descWinDotNetLoadingTotalAssemblies)
-		Add(&md, "dotnet.total.classes", v.TotalClassesLoaded, tags, metadata.Gauge, metadata.Count, descWinDotNetLoadingTotalClassesLoaded)
-		Add(&md, "dotnet.total.load_failures", v.TotalNumberofLoadFailures, tags, metadata.Gauge, metadata.Count, descWinDotNetLoadingTotalNumberofLoadFailures)
-	}
-	return md, nil
-}
-
-const (
-	descWinDotNetLoadingCurrentappdomains         = "This counter displays the current number of AppDomains loaded in this application. AppDomains (application domains) provide a secure and versatile unit of processing that the CLR can use to provide isolation between applications running in the same process."
-	descWinDotNetLoadingCurrentAssemblies         = "This counter displays the current number of Assemblies loaded across all AppDomains in this application. If the Assembly is loaded as domain-neutral from multiple AppDomains then this counter is incremented once only. Assemblies can be loaded as domain-neutral when their code can be shared by all AppDomains or they can be loaded as domain-specific when their code is private to the AppDomain."
-	descWinDotNetLoadingCurrentClassesLoaded      = "This counter displays the current number of classes loaded in all Assemblies."
-	descWinDotNetLoadingTotalAppdomains           = "This counter displays the peak number of AppDomains loaded since the start of this application."
-	descWinDotNetLoadingTotalappdomainsunloaded   = "This counter displays the total number of AppDomains unloaded since the start of the application. If an AppDomain is loaded and unloaded multiple times this counter would count each of those unloads as separate."
-	descWinDotNetLoadingTotalAssemblies           = "This counter displays the total number of Assemblies loaded since the start of this application. If the Assembly is loaded as domain-neutral from multiple AppDomains then this counter is incremented once only."
-	descWinDotNetLoadingTotalClassesLoaded        = "This counter displays the cumulative number of classes loaded in all Assemblies since the start of this application."
-	descWinDotNetLoadingTotalNumberofLoadFailures = "This counter displays the peak number of classes that have failed to load since the start of the application. These load failures could be due to many reasons like inadequate security or illegal format."
-)
-
-type Win32_PerfRawData_NETFramework_NETCLRLoading struct {
-	Currentappdomains         uint32
-	CurrentAssemblies         uint32
-	CurrentClassesLoaded      uint32
-	Name                      string
-	TotalAppdomains           uint32
-	Totalappdomainsunloaded   uint32
-	TotalAssemblies           uint32
-	TotalClassesLoaded        uint32
-	TotalNumberofLoadFailures uint32
-}
-
-func c_dotnet_memory() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_PerfRawData_NETFramework_NETCLRMemory
-	err := queryWmi(dotnetMemoryQuery, &dst)
-	if err != nil {
-		return nil, err
-	}
-	var svc_dst []Win32_Service
-	var svc_q = wmi.CreateQuery(&svc_dst, `WHERE Started=true`)
-	err = queryWmi(svc_q, &svc_dst)
-	if err != nil {
-		return nil, err
-	}
-	var iis_dst []WorkerProcess
-	iis_q := wmi.CreateQuery(&iis_dst, "")
-	err = queryWmiNamespace(iis_q, &iis_dst, "root\\WebAdministration")
-	if err != nil {
-		iis_dst = nil
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		var name string
-		service_match := false
-		iis_match := false
-		process_match := nameMatches(v.Name, regexesDotNet)
-		id := "0"
-		if process_match {
-			raw_name := strings.Split(v.Name, "#")
-			name = raw_name[0]
-			if len(raw_name) == 2 {
-				id = raw_name[1]
-			}
-			// If you have a hash sign in your process name you don't deserve monitoring ;-)
-			if len(raw_name) > 2 {
-				continue
-			}
-		}
-		// A Service match could "overwrite" a process match, but that is probably what we would want.
-		for _, svc := range svc_dst {
-			if nameMatches(svc.Name, regexesDotNet) {
-				// It is possible the pid has gone and been reused, but I think this unlikely
-				// and I'm not aware of an atomic join we could do anyways.
-				if svc.ProcessId != 0 && svc.ProcessId == v.ProcessID {
-					id = "0"
-					service_match = true
-					name = svc.Name
-					break
-				}
-			}
-		}
-		for _, a_pool := range iis_dst {
-			if a_pool.ProcessId == v.ProcessID {
-				id = "0"
-				iis_match = true
-				name = strings.Join([]string{"iis", a_pool.AppPoolName}, "_")
-				break
-			}
-		}
-		if !(service_match || process_match || iis_match) {
-			continue
-		}
-		tags := opentsdb.TagSet{"name": name, "id": id}
-		Add(&md, "dotnet.memory.finalization_survivors", v.FinalizationSurvivors, tags, metadata.Gauge, metadata.Count, descWinDotNetMemoryFinalizationSurvivors)
-		Add(&md, "dotnet.memory.gen0_promoted", v.Gen0PromotedBytesPerSec, tags, metadata.Counter, metadata.BytesPerSecond, descWinDotNetMemoryGen0PromotedBytesPerSec)
-		Add(&md, "dotnet.memory.gen0_promoted_finalized", v.PromotedFinalizationMemoryfromGen0, tags, metadata.Gauge, metadata.PerSecond, descWinDotNetMemoryPromotedFinalizationMemoryfromGen0)
-		Add(&md, "dotnet.memory.gen1_promoted", v.Gen1PromotedBytesPerSec, tags, metadata.Counter, metadata.BytesPerSecond, descWinDotNetMemoryGen1PromotedBytesPerSec)
-		Add(&md, "dotnet.memory.heap_allocations", v.AllocatedBytesPersec, tags, metadata.Counter, metadata.BytesPerSecond, descWinDotNetMemoryAllocatedBytesPersec)
-		Add(&md, "dotnet.memory.heap_size_gen0_max", v.Gen0heapsize, tags, metadata.Gauge, metadata.Bytes, descWinDotNetMemoryGen0heapsize)
-		Add(&md, "dotnet.memory.heap_size", v.Gen1heapsize, opentsdb.TagSet{"type": "gen1"}.Merge(tags), metadata.Gauge, metadata.Bytes, descWinDotNetMemoryGen1heapsize)
-		Add(&md, "dotnet.memory.heap_size", v.Gen2heapsize, opentsdb.TagSet{"type": "gen2"}.Merge(tags), metadata.Gauge, metadata.Bytes, descWinDotNetMemoryGen2heapsize)
-		Add(&md, "dotnet.memory.heap_size", v.LargeObjectHeapsize, opentsdb.TagSet{"type": "large_object"}.Merge(tags), metadata.Gauge, metadata.Bytes, descWinDotNetMemoryLargeObjectHeapsize)
-		Add(&md, "dotnet.memory.heap_size", v.NumberBytesinallHeaps, opentsdb.TagSet{"type": "total"}.Merge(tags), metadata.Gauge, metadata.Bytes, descWinDotNetMemoryNumberBytesinallHeaps)
-		Add(&md, "dotnet.memory.gc_handles", v.NumberGCHandles, tags, metadata.Gauge, metadata.Count, descWinDotNetMemoryNumberGCHandles)
-		Add(&md, "dotnet.memory.gc_collections", v.NumberGen0Collections, opentsdb.TagSet{"type": "gen0"}.Merge(tags), metadata.Counter, metadata.Count, descWinDotNetMemoryNumberGen0Collections)
-		Add(&md, "dotnet.memory.gc_collections", v.NumberGen1Collections, opentsdb.TagSet{"type": "gen1"}.Merge(tags), metadata.Counter, metadata.Count, descWinDotNetMemoryNumberGen1Collections)
-		Add(&md, "dotnet.memory.gc_collections", v.NumberGen2Collections, opentsdb.TagSet{"type": "gen2"}.Merge(tags), metadata.Counter, metadata.Count, descWinDotNetMemoryNumberGen2Collections)
-		Add(&md, "dotnet.memory.gc_collections", v.NumberInducedGC, opentsdb.TagSet{"type": "induced"}.Merge(tags), metadata.Counter, metadata.Count, descWinDotNetMemoryNumberInducedGC)
-		Add(&md, "dotnet.memory.pinned_objects", v.NumberofPinnedObjects, tags, metadata.Gauge, metadata.Count, descWinDotNetMemoryNumberofPinnedObjects)
-		Add(&md, "dotnet.memory.sink_blocks", v.NumberofSinkBlocksinuse, tags, metadata.Gauge, metadata.Count, descWinDotNetMemoryNumberofSinkBlocksinuse)
-		Add(&md, "dotnet.memory.virtual_committed", v.NumberTotalcommittedBytes, tags, metadata.Gauge, metadata.Bytes, descWinDotNetMemoryNumberTotalcommittedBytes)
-		Add(&md, "dotnet.memory.virtual_reserved", v.NumberTotalreservedBytes, tags, metadata.Gauge, metadata.Bytes, descWinDotNetMemoryNumberTotalreservedBytes)
-		if v.PercentTimeinGC_Base != 0 {
-			Add(&md, "dotnet.memory.gc_time", float64(v.PercentTimeinGC)/float64(v.PercentTimeinGC_Base)*100, tags, metadata.Gauge, metadata.Pct, descWinDotNetMemoryPercentTimeinGC)
-		}
-	}
-	return md, nil
-}
-
-const (
-	descWinDotNetMemoryAllocatedBytesPersec               = "This counter displays the rate of bytes per second allocated on the GC Heap. This counter is updated at the end of every GC; not at each allocation."
-	descWinDotNetMemoryFinalizationSurvivors              = "This counter displays the number of garbage collected objects that survive a collection because they are waiting to be finalized. If these objects hold references to other objects then those objects also survive but are not counted by this counter; This counter is not a cumulative counter; its updated at the end of every GC with count of the survivors during that particular GC only. This counter was designed to indicate the extra overhead that the application might incur because of finalization."
-	descWinDotNetMemoryGen0heapsize                       = "This counter displays the maximum bytes that can be allocated in generation 0 (Gen 0); its does not indicate the current number of bytes allocated in Gen 0. A Gen 0 GC is triggered when the allocations since the last GC exceed this size. The Gen 0 size is tuned by the Garbage Collector and can change during the execution of the application. At the end of a Gen 0 collection the size of the Gen 0 heap is infact 0 bytes; this counter displays the size (in bytes) of allocations that would trigger the next Gen 0 GC. This counter is updated at the end of a GC; its not updated on every allocation."
-	descWinDotNetMemoryGen0PromotedBytesPerSec            = "This counter displays the bytes per second that are promoted from generation 0 (youngest) to generation 1; objects that are promoted just because they are waiting to be finalized are not included in this counter. Memory is promoted when it survives a garbage collection. This counter was designed as an indicator of relatively long-lived objects being created per sec."
-	descWinDotNetMemoryGen1heapsize                       = "This counter displays the current number of bytes in generation 1 (Gen 1); this counter does not display the maximum size of Gen 1. Objects are not directly allocated in this generation; they are promoted from previous Gen 0 GCs. This counter is updated at the end of a GC; its not updated on every allocation."
-	descWinDotNetMemoryGen1PromotedBytesPerSec            = "This counter displays the bytes per second that are promoted from generation 1 to generation 2 (oldest); objects that are promoted just because they are waiting to be finalized are not included in this counter. Memory is promoted when it survives a garbage collection. Nothing is promoted from generation 2 since it is the oldest."
-	descWinDotNetMemoryGen2heapsize                       = "This counter displays the current number of bytes in generation 2 (Gen 2)."
-	descWinDotNetMemoryLargeObjectHeapsize                = "This counter displays the current size of the Large Object Heap in bytes. Objects greater than a threshold are treated as large objects by the Garbage Collector and are directly allocated in a special heap; they are not promoted through the generations. In CLR v1.1 and above this threshold is equal to 85000 bytes."
-	descWinDotNetMemoryNumberBytesinallHeaps              = "This counter is the sum of four other counters; Gen 0 Heap Size; Gen 1 Heap Size; Gen 2 Heap Size and the Large Object Heap Size. This counter indicates the current memory allocated in bytes on the GC Heaps."
-	descWinDotNetMemoryNumberGCHandles                    = "This counter displays the current number of GC Handles in use. GCHandles are handles to resources external to the CLR and the managed environment. Handles occupy small amounts of memory in the GCHeap but potentially expensive unmanaged resources."
-	descWinDotNetMemoryNumberGen0Collections              = "This counter displays the number of times the generation 0 objects (youngest; most recently allocated) are garbage collected (Gen 0 GC) since the start of the application. Gen 0 GC occurs when the available memory in generation 0 is not sufficient to satisfy an allocation request. This counter is incremented at the end of a Gen 0 GC. Higher generation GCs include all lower generation GCs. This counter is explicitly incremented when a higher generation (Gen 1 or Gen 2) GC occurs. _Global_ counter value is not accurate and should be ignored."
-	descWinDotNetMemoryNumberGen1Collections              = "This counter displays the number of times the generation 1 objects are garbage collected since the start of the application. The counter is incremented at the end of a Gen 1 GC. Higher generation GCs include all lower generation GCs. This counter is explicitly incremented when a higher generation (Gen 2) GC occurs. _Global_ counter value is not accurate and should be ignored."
-	descWinDotNetMemoryNumberGen2Collections              = "This counter displays the number of times the generation 2 objects (older) are garbage collected since the start of the application. The counter is incremented at the end of a Gen 2 GC (also called full GC). _Global_ counter value is not accurate and should be ignored."
-	descWinDotNetMemoryNumberInducedGC                    = "This counter displays the peak number of times a garbage collection was performed because of an explicit call to GC.Collect. Its a good practice to let the GC tune the frequency of its collections."
-	descWinDotNetMemoryNumberofPinnedObjects              = "This counter displays the number of pinned objects encountered in the last GC. This counter tracks the pinned objects only in the heaps that were garbage collected e.g. a Gen 0 GC would cause enumeration of pinned objects in the generation 0 heap only. A pinned object is one that the Garbage Collector cannot move in memory."
-	descWinDotNetMemoryNumberofSinkBlocksinuse            = "This counter displays the current number of sync blocks in use. Sync blocks are per-object data structures allocated for storing synchronization information. Sync blocks hold weak references to managed objects and need to be scanned by the Garbage Collector. Sync blocks are not limited to storing synchronization information and can also store COM interop metadata. This counter was designed to indicate performance problems with heavy use of synchronization primitives."
-	descWinDotNetMemoryNumberTotalcommittedBytes          = "This counter displays the amount of virtual memory (in bytes) currently committed by the Garbage Collector. Committed memory is the physical memory for which space has been reserved on the disk paging file."
-	descWinDotNetMemoryNumberTotalreservedBytes           = "This counter displays the amount of virtual memory (in bytes) currently reserved by the Garbage Collector. Reserved memory is the virtual memory space reserved for the application but no disk or main memory pages have been used."
-	descWinDotNetMemoryPercentTimeinGC                    = "Percent Time in GC is the percentage of elapsed time that was spent in performing a garbage collection (GC) since the last GC cycle. This counter is usually an indicator of the work done by the Garbage Collector on behalf of the application to collect and compact memory. This counter is updated only at the end of every GC and the counter value reflects the last observed value; its not an average."
-	descWinDotNetMemoryPromotedFinalizationMemoryfromGen0 = "This counter displays the bytes of memory that are promoted from generation 0 to generation 1 just because they are waiting to be finalized. This counter displays the value observed at the end of the last GC; its not a cumulative counter."
-)
-
-type Win32_PerfRawData_NETFramework_NETCLRMemory struct {
-	AllocatedBytesPersec               uint32
-	FinalizationSurvivors              uint32
-	Gen0heapsize                       uint32
-	Gen0PromotedBytesPerSec            uint32
-	Gen1heapsize                       uint32
-	Gen1PromotedBytesPerSec            uint32
-	Gen2heapsize                       uint32
-	LargeObjectHeapsize                uint32
-	Name                               string
-	NumberBytesinallHeaps              uint32
-	NumberGCHandles                    uint32
-	NumberGen0Collections              uint32
-	NumberGen1Collections              uint32
-	NumberGen2Collections              uint32
-	NumberInducedGC                    uint32
-	NumberofPinnedObjects              uint32
-	NumberofSinkBlocksinuse            uint32
-	NumberTotalcommittedBytes          uint32
-	NumberTotalreservedBytes           uint32
-	PercentTimeinGC                    uint32
-	PercentTimeinGC_Base               uint32
-	ProcessID                          uint32
-	PromotedFinalizationMemoryfromGen0 uint32
-}
diff --git a/cmd/scollector/collectors/dsc_windows.go b/cmd/scollector/collectors/dsc_windows.go
deleted file mode 100644
index 7eac2c8..0000000
--- a/cmd/scollector/collectors/dsc_windows.go
+++ /dev/null
@@ -1,62 +0,0 @@
-package collectors
-
-import (
-	"os"
-	"time"
-
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-)
-
-func init() {
-	collectors = append(collectors, &IntervalCollector{F: c_dsc_mof, Interval: time.Minute * 5})
-}
-
-const (
-	dscLCM = "dsc.lcm."
-	dscMof = "dsc.mof."
-)
-
-var (
-	dscpath     = os.ExpandEnv(`${SYSTEMROOT}\system32\Configuration\`)
-	mapMofFiles = map[string]string{
-		"MetaConfig.mof":       "Meta_Config",
-		"Current.mof":          "Current_Config",
-		"backup.mof":           "Backup_Config",
-		"pending.mof":          "Pending_Config",
-		"DSCStatusHistory.mof": "DSC_History",
-		"DSCEngineCache.mof":   "DSC_Cache",
-	}
-)
-
-// c_dsc_mof monitors the size and last modified time of each mof file.
-// These out of band metrics can be used to verify the DSC WMI Status metrics.
-func c_dsc_mof() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	c := 0
-	if _, err := os.Stat(dscpath + "MetaConfig.mof"); os.IsNotExist(err) {
-		c = 1
-	}
-	Add(&md, dscLCM+"configured", c, nil, metadata.Gauge, metadata.StatusCode, descDSCLCMConfigured)
-	if c == 1 {
-		return md, nil
-	}
-	for filename, filetype := range mapMofFiles {
-		tags := opentsdb.TagSet{"type": filetype}
-		s := int64(-1)
-		l := int64(-1)
-		if fi, fierr := os.Stat(dscpath + filename); fierr == nil {
-			s = fi.Size()
-			l = time.Now().Unix() - fi.ModTime().Unix()
-		}
-		Add(&md, dscMof+"size", s, tags, metadata.Gauge, metadata.Bytes, descDSCMofSize)
-		Add(&md, dscMof+"last_modified", l, tags, metadata.Gauge, metadata.Second, descDSCMofModified)
-	}
-	return md, nil
-}
-
-const (
-	descDSCLCMConfigured = "Indicates if DSC Local Configuration Manager is configured: 0=configured, 1=not configured. If the LCM is not configured then the rest of the dsc.* metrics will be skipped on that server."
-	descDSCMofSize       = "Size of the mof file in bytes or -1 if file does not exist."
-	descDSCMofModified   = "Number of seconds since the mof file was last modified or -1 if file does not exist."
-)
diff --git a/cmd/scollector/collectors/elasticsearch.go b/cmd/scollector/collectors/elasticsearch.go
deleted file mode 100644
index ff20c2d..0000000
--- a/cmd/scollector/collectors/elasticsearch.go
+++ /dev/null
@@ -1,566 +0,0 @@
-package collectors
-
-import (
-	"encoding/json"
-	"errors"
-	"math"
-	"net/http"
-	"net/url"
-	"regexp"
-	"time"
-
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-)
-
-func init() {
-	collectors = append(collectors, &IntervalCollector{F: c_elasticsearch, Enable: enableURL(esURL)})
-	collectors = append(collectors, &IntervalCollector{F: c_elasticsearch_indices, Interval: time.Minute * 2, Enable: enableURL(esURL)})
-}
-
-const esURL = "http://localhost:9200/"
-
-var (
-	esPreV1     = regexp.MustCompile(`^0\.`)
-	esStatusMap = map[string]int{
-		"green":  0,
-		"yellow": 1,
-		"red":    2,
-	}
-)
-
-func c_elasticsearch() (opentsdb.MultiDataPoint, error) {
-	var status esStatus
-	if err := esReq("/", "", &status); err != nil {
-		return nil, err
-	}
-	var stats esStats
-	if err := esReq(esStatsURL(status.Version.Number), "", &stats); err != nil {
-		return nil, err
-	}
-	var clusterState esClusterState
-	if err := esReq("/_cluster/state", "?filter_routing_table=true&filter_metadata=true&filter_blocks=true", &clusterState); err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	add := func(name string, val interface{}, ts opentsdb.TagSet) {
-		tags := opentsdb.TagSet{"cluster": stats.ClusterName}
-		for k, v := range ts {
-			tags[k] = v
-		}
-		Add(&md, "elastic."+name, val, tags, metadata.Unknown, metadata.None, "")
-	}
-	for nodeid, nstats := range stats.Nodes {
-		isMaster := nodeid == clusterState.MasterNode
-		if isMaster {
-			cstats := make(map[string]interface{})
-			if err := esReq("/_cluster/health", "", &cstats); err != nil {
-				return nil, err
-			}
-			for k, v := range cstats {
-				switch t := v.(type) {
-				case string:
-					if k != "status" {
-						continue
-					}
-					var present bool
-					if v, present = esStatusMap[t]; !present {
-						v = -1
-					}
-				case float64:
-					// break
-				default:
-					continue
-				}
-				add("cluster."+k, v, nil)
-			}
-		}
-		for k, v := range nstats.Indices {
-			switch k {
-			case "docs":
-				add("num_docs", v["count"], nil)
-			case "store":
-				add("indices.size", v["size_in_bytes"], nil)
-			case "indexing":
-				add("indexing.index_total", v["index_total"], nil)
-				add("indexing.index_time", v["index_time_in_millis"], nil)
-				if f, err := divInterfaceFlt(v["index_time_in_millis"], v["index_total"]); err == nil {
-					add("indexing.time_per_index", f, nil)
-				}
-				add("indexing.index_current", v["index_current"], nil)
-				add("indexing.delete_total", v["delete_total"], nil)
-				add("indexing.delete_time", v["delete_time_in_millis"], nil)
-				add("indexing.delete_current", v["delete_current"], nil)
-				if f, err := divInterfaceFlt(v["delete_time_in_millis"], v["delete_total"]); err == nil {
-					add("indexing.time_per_delete", f, nil)
-				}
-			case "get":
-				add("get.total", v["total"], nil)
-				add("get.time", v["time_in_millis"], nil)
-				if f, err := divInterfaceFlt(v["time_in_millis"], v["total"]); err == nil {
-					add("get.time_per_get", f, nil)
-				}
-				add("get.exists_total", v["exists_total"], nil)
-				add("get.exists_time", v["exists_time_in_millis"], nil)
-				if f, err := divInterfaceFlt(v["exists_time_in_millis"], v["exists_total"]); err == nil {
-					add("get.time_per_get_exists", f, nil)
-				}
-				add("get.missing_total", v["missing_total"], nil)
-				add("get.missing_time", v["missing_time_in_millis"], nil)
-				if f, err := divInterfaceFlt(v["missing_time_in_millis"], v["missing_total"]); err == nil {
-					add("get.time_per_get_missing", f, nil)
-				}
-			case "search":
-				add("search.query_total", v["query_total"], nil)
-				add("search.query_time", v["query_time_in_millis"], nil)
-				if f, err := divInterfaceFlt(v["query_time_in_millis"], v["query_total"]); err == nil {
-					add("search.time_per_query", f, nil)
-				}
-				add("search.query_current", v["query_current"], nil)
-				add("search.fetch_total", v["fetch_total"], nil)
-				add("search.fetch_time", v["fetch_time_in_millis"], nil)
-				if f, err := divInterfaceFlt(v["fetch_time_in_millis"], v["fetch_total"]); err == nil {
-					add("search.time_per_fetch", f, nil)
-				}
-				add("search.fetch_current", v["fetch_current"], nil)
-			case "cache":
-				add("cache.field.evictions", v["field_evictions"], nil)
-				add("cache.field.size", v["field_size_in_bytes"], nil)
-				add("cache.filter.count", v["filter_count"], nil)
-				add("cache.filter.evictions", v["filter_evictions"], nil)
-				add("cache.filter.size", v["filter_size_in_bytes"], nil)
-			case "merges":
-				add("merges.current", v["current"], nil)
-				add("merges.total", v["total"], nil)
-				add("merges.total_time", v["total_time_in_millis"], nil)
-				if f, err := divInterfaceFlt(v["total_time_in_millis"], v["total"]); err == nil {
-					add("merges.time_per_merge", f, nil)
-				}
-			}
-		}
-		for k, v := range nstats.Process {
-			switch k {
-			case "open_file_descriptors": // ES 0.17
-				add("process.open_file_descriptors", v, nil)
-			case "fd": // ES 0.16
-				if t, present := nstats.Process["total"]; present {
-					add("process.open_file_descriptors", t, nil)
-				}
-			case "cpu":
-				v := v.(map[string]interface{})
-				add("process.cpu.percent", v["percent"], nil)
-				add("process.cpu.sys", v["sys_in_millis"].(float64)/1000., nil)
-				add("process.cpu.user", v["user_in_millis"].(float64)/1000., nil)
-			case "mem":
-				v := v.(map[string]interface{})
-				add("process.mem.resident", v["resident_in_bytes"], nil)
-				add("process.mem.shared", v["share_in_bytes"], nil)
-				add("process.mem.total_virtual", v["total_virtual_in_bytes"], nil)
-			}
-		}
-		for k, v := range nstats.JVM {
-			switch k {
-			case "mem":
-				v := v.(map[string]interface{})
-				add("jvm.mem.heap_used", v["heap_used_in_bytes"], nil)
-				add("jvm.mem.heap_committed", v["heap_committed_in_bytes"], nil)
-				add("jvm.mem.non_heap_used", v["non_heap_used_in_bytes"], nil)
-				add("jvm.mem.non_heap_committed", v["non_heap_committed_in_bytes"], nil)
-			case "threads":
-				v := v.(map[string]interface{})
-				add("jvm.threads.count", v["count"], nil)
-				add("jvm.threads.peak_count", v["peak_count"], nil)
-			case "gc":
-				v := v.(map[string]interface{})
-				c := v["collectors"].(map[string]interface{})
-				for k, v := range c {
-					v := v.(map[string]interface{})
-					ts := opentsdb.TagSet{"gc": k}
-					add("jvm.gc.collection_count", v["collection_count"], ts)
-					add("jvm.gc.collection_time", v["collection_time_in_millis"].(float64)/1000, ts)
-				}
-			}
-		}
-		for k, v := range nstats.Network {
-			switch k {
-			case "tcp":
-				for k, v := range v.(map[string]interface{}) {
-					switch v.(type) {
-					case float64:
-						add("network.tcp."+k, v, nil)
-					}
-				}
-			}
-		}
-		for k, v := range nstats.Transport {
-			switch v.(type) {
-			case float64:
-				add("transport."+k, v, nil)
-			}
-		}
-		for k, v := range nstats.HTTP {
-			switch v.(type) {
-			case float64:
-				add("http."+k, v, nil)
-			}
-		}
-	}
-	return md, nil
-}
-
-type ElasticIndexStats struct {
-	All    ElasticIndex `json:"_all"`
-	Shards struct {
-		Failed     float64 `json:"failed"`
-		Successful float64 `json:"successful"`
-		Total      float64 `json:"total"`
-	} `json:"_shards"`
-	Indices map[string]ElasticIndex `json:"indices"`
-}
-
-type ElasticIndex struct {
-	Primaries ElasticIndexDetails `json:"primaries"`
-	Total     ElasticIndexDetails `json:"total"`
-}
-
-type ElasticIndexDetails struct {
-	Completion struct {
-		SizeInBytes float64 `json:"size_in_bytes"`
-	} `json:"completion"`
-	Docs struct {
-		Count   float64 `json:"count"`
-		Deleted float64 `json:"deleted"`
-	} `json:"docs"`
-	Fielddata struct {
-		Evictions         float64 `json:"evictions"`
-		MemorySizeInBytes float64 `json:"memory_size_in_bytes"`
-	} `json:"fielddata"`
-	FilterCache struct {
-		Evictions         float64 `json:"evictions"`
-		MemorySizeInBytes float64 `json:"memory_size_in_bytes"`
-	} `json:"filter_cache"`
-	Flush struct {
-		Total             float64 `json:"total"`
-		TotalTimeInMillis float64 `json:"total_time_in_millis"`
-	} `json:"flush"`
-	Get struct {
-		Current             float64 `json:"current"`
-		ExistsTimeInMillis  float64 `json:"exists_time_in_millis"`
-		ExistsTotal         float64 `json:"exists_total"`
-		MissingTimeInMillis float64 `json:"missing_time_in_millis"`
-		MissingTotal        float64 `json:"missing_total"`
-		TimeInMillis        float64 `json:"time_in_millis"`
-		Total               float64 `json:"total"`
-	} `json:"get"`
-	IDCache struct {
-		MemorySizeInBytes float64 `json:"memory_size_in_bytes"`
-	} `json:"id_cache"`
-	Indexing struct {
-		DeleteCurrent      float64 `json:"delete_current"`
-		DeleteTimeInMillis float64 `json:"delete_time_in_millis"`
-		DeleteTotal        float64 `json:"delete_total"`
-		IndexCurrent       float64 `json:"index_current"`
-		IndexTimeInMillis  float64 `json:"index_time_in_millis"`
-		IndexTotal         float64 `json:"index_total"`
-	} `json:"indexing"`
-	Merges struct {
-		Current            float64 `json:"current"`
-		CurrentDocs        float64 `json:"current_docs"`
-		CurrentSizeInBytes float64 `json:"current_size_in_bytes"`
-		Total              float64 `json:"total"`
-		TotalDocs          float64 `json:"total_docs"`
-		TotalSizeInBytes   float64 `json:"total_size_in_bytes"`
-		TotalTimeInMillis  float64 `json:"total_time_in_millis"`
-	} `json:"merges"`
-	Percolate struct {
-		Current           float64 `json:"current"`
-		MemorySize        string  `json:"memory_size"`
-		MemorySizeInBytes float64 `json:"memory_size_in_bytes"`
-		Queries           float64 `json:"queries"`
-		TimeInMillis      float64 `json:"time_in_millis"`
-		Total             float64 `json:"total"`
-	} `json:"percolate"`
-	Refresh struct {
-		Total             float64 `json:"total"`
-		TotalTimeInMillis float64 `json:"total_time_in_millis"`
-	} `json:"refresh"`
-	Search struct {
-		FetchCurrent      float64 `json:"fetch_current"`
-		FetchTimeInMillis float64 `json:"fetch_time_in_millis"`
-		FetchTotal        float64 `json:"fetch_total"`
-		OpenContexts      float64 `json:"open_contexts"`
-		QueryCurrent      float64 `json:"query_current"`
-		QueryTimeInMillis float64 `json:"query_time_in_millis"`
-		QueryTotal        float64 `json:"query_total"`
-	} `json:"search"`
-	Segments struct {
-		Count         float64 `json:"count"`
-		MemoryInBytes float64 `json:"memory_in_bytes"`
-	} `json:"segments"`
-	Store struct {
-		SizeInBytes          float64 `json:"size_in_bytes"`
-		ThrottleTimeInMillis float64 `json:"throttle_time_in_millis"`
-	} `json:"store"`
-	Suggest struct {
-		Current      float64 `json:"current"`
-		TimeInMillis float64 `json:"time_in_millis"`
-		Total        float64 `json:"total"`
-	} `json:"suggest"`
-	Translog struct {
-		Operations  float64 `json:"operations"`
-		SizeInBytes float64 `json:"size_in_bytes"`
-	} `json:"translog"`
-	Warmer struct {
-		Current           float64 `json:"current"`
-		Total             float64 `json:"total"`
-		TotalTimeInMillis float64 `json:"total_time_in_millis"`
-	} `json:"warmer"`
-}
-
-const (
-	descCompletionSizeInBytes        = "Size of the completion index (used for auto-complete functionallity)."
-	descDocsCount                    = "The number of documents in the index."
-	descDocsDeleted                  = "The number of deleted documents in the index."
-	descFielddataEvictions           = "The number of cache evictions for field data."
-	descFielddataMemorySizeInBytes   = "The amount of memory used for field data."
-	descFilterCacheEvictions         = "The number of cache evictions for filter data."
-	descFilterCacheMemorySizeInBytes = "The amount of memory used for filter data."
-	descFlushTotal                   = "The number of flush operations. The flush process of an index basically frees memory from the index by flushing data to the index storage and clearing the internal transaction log."
-	descFlushTotalTimeInMillis       = "The total amount of time spent on flush operations. The flush process of an index basically frees memory from the index by flushing data to the index storage and clearing the internal transaction log."
-	descGetCurrent                   = "The current number of get operations. Gets get a typed JSON document from the index based on its id."
-	descGetTimeInMillis              = "The total amount of time spent on get operations. Gets get a typed JSON document from the index based on its id."
-	descGetTotal                     = "The total number of get operations. Gets get a typed JSON document from the index based on its id."
-	descGetMissingTimeInMillis       = "The total amount of time spent trying to get documents that turned out to be missing."
-	descGetMissingTotal              = "The total number of operations that tried to get a document that turned out to be missing."
-	descGetExistsTimeInMillis        = "The total amount of time spent on get exists operations. Gets exists sees if a document exists."
-	descGetExistsTotal               = "The total number of get exists operations. Gets exists sees if a document exists."
-	descIDCacheMemorySizeInBytes     = "The size of the id cache."
-	descIndexingDeleteCurrent        = "The current number of documents being deleted via indexing commands (such as a delete query)."
-	descIndexingDeleteTimeInMillis   = "The time spent deleting documents."
-	descIndexingDeleteTotal          = "The total number of documents deleted."
-	descIndexingIndexCurrent         = "The current number of documents being indexed."
-	descIndexingIndexTimeInMillis    = "The total amount of time spent indexing documents."
-	descIndexingIndexTotal           = "The total number of documents indexed."
-	descMergesCurrent                = "The current number of merge operations. In elastic Lucene segments are merged behind the scenes. It is possible these can impact search performance."
-	descMergesCurrentDocs            = "The current number of documents that have an underlying merge operation going on. In elastic Lucene segments are merged behind the scenes. It is possible these can impact search performance."
-	descMergesCurrentSizeInBytes     = "The current number of bytes being merged. In elastic Lucene segments are merged behind the scenes. It is possible these can impact search performance."
-	descMergesTotal                  = "The total number of merges. In elastic Lucene segments are merged behind the scenes. It is possible these can impact search performance."
-	descMergesTotalDocs              = "The total number of documents that have had an underlying merge operation. In elastic Lucene segments are merged behind the scenes. It is possible these can impact search performance."
-	descMergesTotalSizeInBytes       = "The total number of bytes merged. In elastic Lucene segments are merged behind the scenes. It is possible these can impact search performance."
-	descMergesTotalTimeInMillis      = "The total amount of time spent on merge operations. In elastic Lucene segments are merged behind the scenes. It is possible these can impact search performance."
-	descPercolateCurrent             = "The current number of percolate operations."
-	descPercolateMemorySizeInBytes   = "The amount of memory used for the percolate index. Percolate is a reverse query to document operation."
-	descPercolateQueries             = "The total number of percolate queries. Percolate is a reverse query to document operation."
-	descPercolateTimeInMillis        = "The total amount of time spent on percolating. Percolate is a reverse query to document operation."
-	descPercolateTotal               = "The total number of percolate operations. Percolate is a reverse query to document operation."
-	descRefreshTotal                 = "The total number of refreshes. Refreshing makes all operations performed since the last search available."
-	descRefreshTotalTimeInMillis     = "The total amount of time spent on refreshes. Refreshing makes all operations performed since the last search available."
-	descSearchFetchCurrent           = "The current number of documents being fetched. Fetching is a phase of querying in a distributed search."
-	descSearchFetchTimeInMillis      = "The total time spent fetching documents. Fetching is a phase of querying in a distributed search."
-	descSearchFetchTotal             = "The total number of documents fetched. Fetching is a phase of querying in a distributed search."
-	descSearchOpenContexts           = "The current number of open contexts. A search is left open when srolling (i.e. pagination)."
-	descSearchQueryCurrent           = "The current number of queries."
-	descSearchQueryTimeInMillis      = "The total amount of time spent querying."
-	descSearchQueryTotal             = "The total number of queries."
-	descSegmentsMemoryInBytes        = "The total amount of memory used for Lucene segments."
-	descSegmentsCount                = "The number of segments that make up the index."
-	descStoreSizeInBytes             = "The current size of the store."
-	descStoreThrottleTimeInMillis    = "The amount of time that merges where throttled."
-	descSuggestCurrent               = "The current number of suggest operations."
-	descSuggestTimeInMillis          = "The total amount of time spent on suggest operations."
-	descSuggestTotal                 = "The total number of suggest operations."
-	descTranslogOperations           = "The total number of translog operations. The transaction logs (or write ahead logs) ensure atomicity of operations."
-	descTranslogSizeInBytes          = "The current size of transaction log. The transaction log (or write ahead log) ensure atomicity of operations."
-	descWarmerCurrent                = "The current number of warmer operations. Warming registers search requests in the background to speed up actual search requests."
-	descWarmerTotal                  = "The total number of warmer operations. Warming registers search requests in the background to speed up actual search requests."
-	descWarmerTotalTimeInMillis      = "The total time spent on warmer operations. Warming registers search requests in the background to speed up actual search requests."
-)
-
-type ElasticIndicesHealth struct {
-	ActivePrimaryShards float64                       `json:"active_primary_shards"`
-	ActiveShards        float64                       `json:"active_shards"`
-	ClusterName         string                        `json:"cluster_name"`
-	Indices             map[string]ElasticIndexHealth `json:"indices"`
-	InitializingShards  float64                       `json:"initializing_shards"`
-	NumberOfDataNodes   float64                       `json:"number_of_data_nodes"`
-	NumberOfNodes       float64                       `json:"number_of_nodes"`
-	RelocatingShards    float64                       `json:"relocating_shards"`
-	Status              string                        `json:"status"`
-	TimedOut            bool                          `json:"timed_out"`
-	UnassignedShards    float64                       `json:"unassigned_shards"`
-}
-
-type ElasticIndexHealth struct {
-	ActivePrimaryShards float64 `json:"active_primary_shards"`
-	ActiveShards        float64 `json:"active_shards"`
-	InitializingShards  float64 `json:"initializing_shards"`
-	NumberOfReplicas    float64 `json:"number_of_replicas"`
-	NumberOfShards      float64 `json:"number_of_shards"`
-	RelocatingShards    float64 `json:"relocating_shards"`
-	Status              string  `json:"status"`
-	UnassignedShards    float64 `json:"unassigned_shards"`
-}
-
-const (
-	descStatus              = "The current status of the index. Zero for green, one for yellow, two for red."
-	descActivePrimaryShards = "The number of active primary shards. Each document is stored in a single primary shard and then when it is indexed it is copied the replicas of that shard."
-	descActiveShards        = "The number of active shards."
-	descInitializingShards  = "The number of initalizing shards."
-	descNumberOfShards      = "The number of shards."
-	descRelocatingShards    = "The number of shards relocating."
-	descNumberOfReplicas    = "The number of replicas."
-)
-
-func c_elasticsearch_indices() (opentsdb.MultiDataPoint, error) {
-	var stats ElasticIndexStats
-	var health ElasticIndicesHealth
-	if err := esReq("/_cluster/health", "level=indices", &health); err != nil {
-		return nil, err
-	}
-	cluster := health.ClusterName
-	var md opentsdb.MultiDataPoint
-	for k, v := range health.Indices {
-		ts := opentsdb.TagSet{"index_name": k, "cluster": cluster}
-		if status, ok := esStatusMap[v.Status]; ok {
-			Add(&md, "elastic.indices.status", status, ts, metadata.Gauge, metadata.StatusCode, descStatus)
-		}
-		Add(&md, "elastic.indices.shards.active_primary", v.ActivePrimaryShards, ts, metadata.Gauge, metadata.Shard, descActivePrimaryShards)
-		Add(&md, "elastic.indices.shards.active", v.ActiveShards, ts, metadata.Gauge, metadata.Shard, descActiveShards)
-		Add(&md, "elastic.indices.shards.initalizing", v.InitializingShards, ts, metadata.Gauge, metadata.Shard, descInitializingShards)
-		Add(&md, "elastic.indices.shards.number", v.NumberOfShards, ts, metadata.Gauge, metadata.Shard, descNumberOfShards)
-		Add(&md, "elastic.indices.shards.relocating", v.RelocatingShards, ts, metadata.Gauge, metadata.Shard, descRelocatingShards)
-		Add(&md, "elastic.indices.replicas", v.NumberOfReplicas, ts, metadata.Gauge, metadata.Replica, descNumberOfReplicas)
-
-	}
-	if err := esReq("/_stats", "", &stats); err != nil {
-		return nil, err
-	}
-	for k, v := range stats.Indices {
-		ts := opentsdb.TagSet{"index_name": k, "cluster": cluster}
-		Add(&md, "elastic.indices.completion.size", v.Primaries.Completion.SizeInBytes, ts, metadata.Gauge, metadata.Bytes, descCompletionSizeInBytes)
-		Add(&md, "elastic.indices.docs.count", v.Primaries.Docs.Count, ts, metadata.Gauge, metadata.Document, descDocsCount)
-		Add(&md, "elastic.indices.docs.deleted", v.Primaries.Docs.Deleted, ts, metadata.Gauge, metadata.Document, descDocsDeleted)
-		Add(&md, "elastic.indices.fielddata.evictions", v.Primaries.Fielddata.Evictions, ts, metadata.Counter, metadata.Eviction, descFielddataEvictions)
-		Add(&md, "elastic.indices.fielddata.memory_size", v.Primaries.Fielddata.MemorySizeInBytes, ts, metadata.Gauge, metadata.Bytes, descFielddataMemorySizeInBytes)
-		Add(&md, "elastic.indices.filter_cache.evictions", v.Primaries.FilterCache.Evictions, ts, metadata.Counter, metadata.Eviction, descFilterCacheEvictions)
-		Add(&md, "elastic.indices.filter_cache.memory_size", v.Primaries.FilterCache.MemorySizeInBytes, ts, metadata.Counter, metadata.Bytes, descFilterCacheMemorySizeInBytes)
-		Add(&md, "elastic.indices.flush.total", v.Primaries.Flush.Total, ts, metadata.Counter, metadata.Flush, descFlushTotal)
-		Add(&md, "elastic.indices.flush.total_time", v.Primaries.Flush.TotalTimeInMillis, ts, metadata.Counter, metadata.MilliSecond, descFlushTotalTimeInMillis)
-		Add(&md, "elastic.indices.get.current", v.Primaries.Get.Current, ts, metadata.Gauge, metadata.Get, descGetCurrent)
-		Add(&md, "elastic.indices.get.exists_time", v.Primaries.Get.ExistsTimeInMillis, ts, metadata.Counter, metadata.GetExists, descGetExistsTimeInMillis)
-		Add(&md, "elastic.indices.get.exists_total", v.Primaries.Get.ExistsTotal, ts, metadata.Counter, metadata.GetExists, descGetExistsTotal)
-		Add(&md, "elastic.indices.get.missing_time", v.Primaries.Get.MissingTimeInMillis, ts, metadata.Counter, metadata.MilliSecond, descGetMissingTimeInMillis)
-		Add(&md, "elastic.indices.get.missing_total", v.Primaries.Get.MissingTotal, ts, metadata.Counter, metadata.Operation, descGetMissingTotal)
-		Add(&md, "elastic.indices.get.time", v.Primaries.Get.TimeInMillis, ts, metadata.Counter, metadata.MilliSecond, descGetTimeInMillis)
-		Add(&md, "elastic.indices.get.total", v.Primaries.Get.Total, ts, metadata.Counter, metadata.Get, descGetTotal)
-		Add(&md, "elastic.indices.id_cache.memory_size", v.Primaries.IDCache.MemorySizeInBytes, ts, metadata.Gauge, metadata.Bytes, descIDCacheMemorySizeInBytes)
-		Add(&md, "elastic.indices.indexing.delete_current", v.Primaries.Indexing.DeleteCurrent, ts, metadata.Gauge, metadata.Document, descIndexingDeleteCurrent)
-		Add(&md, "elastic.indices.indexing.delete_time", v.Primaries.Indexing.DeleteTimeInMillis, ts, metadata.Counter, metadata.MilliSecond, descIndexingDeleteTimeInMillis)
-		Add(&md, "elastic.indices.indexing.delete_total", v.Primaries.Indexing.DeleteTotal, ts, metadata.Counter, metadata.Document, descIndexingDeleteTotal)
-		Add(&md, "elastic.indices.indexing.index_current", v.Primaries.Indexing.IndexCurrent, ts, metadata.Gauge, metadata.Document, descIndexingIndexCurrent)
-		Add(&md, "elastic.indices.indexing.index_time", v.Primaries.Indexing.IndexTimeInMillis, ts, metadata.Counter, metadata.MilliSecond, descIndexingIndexTimeInMillis)
-		Add(&md, "elastic.indices.indexing.index_total", v.Primaries.Indexing.IndexTotal, ts, metadata.Counter, metadata.Document, descIndexingIndexTotal)
-		Add(&md, "elastic.indices.merges.current", v.Primaries.Merges.Current, ts, metadata.Gauge, metadata.Merge, descMergesCurrent)
-		Add(&md, "elastic.indices.merges.current_docs", v.Primaries.Merges.CurrentDocs, ts, metadata.Gauge, metadata.Document, descMergesCurrentDocs)
-		Add(&md, "elastic.indices.merges.current_size", v.Primaries.Merges.CurrentSizeInBytes, ts, metadata.Gauge, metadata.Document, descMergesCurrentSizeInBytes)
-		Add(&md, "elastic.indices.merges.total", v.Primaries.Merges.Total, ts, metadata.Counter, metadata.Merge, descMergesTotal)
-		Add(&md, "elastic.indices.merges.total_docs", v.Primaries.Merges.TotalDocs, ts, metadata.Counter, metadata.Document, descMergesTotalDocs)
-		Add(&md, "elastic.indices.merges.total_size", v.Primaries.Merges.TotalSizeInBytes, ts, metadata.Counter, metadata.Bytes, descMergesTotalSizeInBytes)
-		Add(&md, "elastic.indices.merges.total_time", v.Primaries.Merges.TotalTimeInMillis, ts, metadata.Counter, metadata.MilliSecond, descMergesTotalTimeInMillis)
-		Add(&md, "elastic.indices.percolate.current", v.Primaries.Percolate.Current, ts, metadata.Gauge, "", descPercolateCurrent)
-		Add(&md, "elastic.indices.percolate.memory_size", v.Primaries.Percolate.MemorySizeInBytes, ts, metadata.Gauge, metadata.Bytes, descPercolateMemorySizeInBytes)
-		Add(&md, "elastic.indices.percolate.queries", v.Primaries.Percolate.Queries, ts, metadata.Counter, metadata.Query, descPercolateQueries)
-		Add(&md, "elastic.indices.percolate.time", v.Primaries.Percolate.TimeInMillis, ts, metadata.Counter, metadata.MilliSecond, descPercolateTimeInMillis)
-		Add(&md, "elastic.indices.percolate.total", v.Primaries.Percolate.Total, ts, metadata.Gauge, metadata.Operation, descPercolateTotal)
-		Add(&md, "elastic.indices.refresh.total", v.Primaries.Refresh.Total, ts, metadata.Counter, metadata.Refresh, descRefreshTotal)
-		Add(&md, "elastic.indices.refresh.total_time", v.Primaries.Refresh.TotalTimeInMillis, ts, metadata.Counter, metadata.MilliSecond, descRefreshTotalTimeInMillis)
-		Add(&md, "elastic.indices.search.fetch_current", v.Primaries.Search.FetchCurrent, ts, metadata.Gauge, metadata.Document, descSearchFetchCurrent)
-		Add(&md, "elastic.indices.search.fetch_time", v.Primaries.Search.FetchTimeInMillis, ts, metadata.Counter, metadata.MilliSecond, descSearchFetchTimeInMillis)
-		Add(&md, "elastic.indices.search.fetch_total", v.Primaries.Search.FetchTotal, ts, metadata.Counter, metadata.Document, descSearchFetchTotal)
-		Add(&md, "elastic.indices.search.open_contexts", v.Primaries.Search.OpenContexts, ts, metadata.Gauge, metadata.Context, descSearchOpenContexts)
-		Add(&md, "elastic.indices.search.query_current", v.Primaries.Search.QueryCurrent, ts, metadata.Gauge, metadata.Query, descSearchQueryCurrent)
-		Add(&md, "elastic.indices.search.query_time", v.Primaries.Search.QueryTimeInMillis, ts, metadata.Counter, metadata.MilliSecond, descSearchQueryTimeInMillis)
-		Add(&md, "elastic.indices.search.query_total", v.Primaries.Search.QueryTotal, ts, metadata.Counter, metadata.Query, descSearchQueryTotal)
-		Add(&md, "elastic.indices.segments.count", v.Primaries.Segments.Count, ts, metadata.Counter, metadata.Segment, descSegmentsCount)
-		Add(&md, "elastic.indices.segments.memory", v.Primaries.Segments.MemoryInBytes, ts, metadata.Gauge, metadata.Bytes, descSegmentsMemoryInBytes)
-		Add(&md, "elastic.indices.store.size_in_bytes", v.Primaries.Store.SizeInBytes, ts, metadata.Gauge, metadata.Bytes, descStoreSizeInBytes)
-		Add(&md, "elastic.indices.store.throttle_time", v.Primaries.Store.ThrottleTimeInMillis, ts, metadata.Gauge, metadata.MilliSecond, descStoreThrottleTimeInMillis)
-		Add(&md, "elastic.indices.suggest.current", v.Primaries.Suggest.Current, ts, metadata.Gauge, metadata.Suggest, descSuggestCurrent)
-		Add(&md, "elastic.indices.suggest.time", v.Primaries.Suggest.TimeInMillis, ts, metadata.Counter, metadata.MilliSecond, descSuggestTimeInMillis)
-		Add(&md, "elastic.indices.suggest.total", v.Primaries.Suggest.Total, ts, metadata.Counter, metadata.Suggest, descSuggestTotal)
-		Add(&md, "elastic.indices.translog.operations", v.Primaries.Translog.Operations, ts, metadata.Counter, metadata.Operation, descTranslogOperations)
-		Add(&md, "elastic.indices.translog.size_in_bytes", v.Primaries.Translog.SizeInBytes, ts, metadata.Gauge, metadata.Bytes, descTranslogSizeInBytes)
-		Add(&md, "elastic.indices.warmer.current", v.Primaries.Warmer.Current, ts, metadata.Gauge, metadata.Operation, descWarmerCurrent)
-		Add(&md, "elastic.indices.warmer.total", v.Primaries.Warmer.Total, ts, metadata.Counter, metadata.Operation, descWarmerTotal)
-		Add(&md, "elastic.indices.warmer.total_time", v.Primaries.Warmer.TotalTimeInMillis, ts, metadata.Counter, metadata.MilliSecond, descWarmerTotalTimeInMillis)
-	}
-	return md, nil
-}
-
-func esReq(path, query string, v interface{}) error {
-	u := &url.URL{
-		Scheme:   "http",
-		Host:     "localhost:9200",
-		Path:     path,
-		RawQuery: query,
-	}
-	resp, err := http.Get(u.String())
-	if err != nil {
-		return nil
-	}
-	defer resp.Body.Close()
-	if resp.StatusCode != http.StatusOK {
-		return nil
-	}
-	j := json.NewDecoder(resp.Body)
-	return j.Decode(v)
-}
-
-func esStatsURL(version string) string {
-	if esPreV1.MatchString(version) {
-		return "/_cluster/nodes/_local/stats"
-	}
-	return "/_nodes/_local/stats"
-}
-
-type esStatus struct {
-	Status  int    `json:"status"`
-	Name    string `json:"name"`
-	Version struct {
-		Number string `json:"number"`
-	} `json:"version"`
-}
-
-type esStats struct {
-	ClusterName string `json:"cluster_name"`
-	Nodes       map[string]struct {
-		Indices   map[string]map[string]interface{} `json:"indices"`
-		Process   map[string]interface{}            `json:"process"`
-		JVM       map[string]interface{}            `json:"jvm"`
-		Network   map[string]interface{}            `json:"network"`
-		Transport map[string]interface{}            `json:"transport"`
-		HTTP      map[string]interface{}            `json:"http"`
-	} `json:"nodes"`
-}
-
-type esClusterState struct {
-	MasterNode string `json:"master_node"`
-}
-
-func divInterfaceFlt(a, b interface{}) (float64, error) {
-	af, ok := a.(float64)
-	if !ok {
-		return 0, errors.New("elasticsearch: expected float64")
-	}
-	bf, ok := b.(float64)
-	if !ok {
-		return 0, errors.New("elasticsearch: expected float64")
-	}
-	r := af / bf
-	if math.IsNaN(r) {
-		return 0, errors.New("elasticsearch: got NaN")
-	} else if math.IsInf(r, 0) {
-		return 0, errors.New("elasticsearch: got Inf")
-	}
-	return r, nil
-}
diff --git a/cmd/scollector/collectors/hbase_unix.go b/cmd/scollector/collectors/hbase_unix.go
deleted file mode 100644
index 3177ac8..0000000
--- a/cmd/scollector/collectors/hbase_unix.go
+++ /dev/null
@@ -1,109 +0,0 @@
-// +build darwin linux
-
-package collectors
-
-import (
-	"encoding/json"
-	"net/http"
-	"strings"
-
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-)
-
-func init() {
-	collectors = append(collectors, &IntervalCollector{F: c_hbase_region, Enable: enableURL(hbURL)})
-	collectors = append(collectors, &IntervalCollector{F: c_hbase_replication, Enable: enableURL(hbRepURL)})
-	collectors = append(collectors, &IntervalCollector{F: c_hbase_gc, Enable: enableURL(hbGCURL)})
-}
-
-const (
-	hbURL    = "http://localhost:60030/jmx?qry=hadoop:service=RegionServer,name=RegionServerStatistics"
-	hbRepURL = "http://localhost:60030/jmx?qry=hadoop:service=Replication,name=*"
-	hbGCURL  = "http://localhost:60030/jmx?qry=java.lang:type=GarbageCollector,name=*"
-)
-
-type jmx struct {
-	Beans []map[string]interface{} `json:"beans"`
-}
-
-func getBeans(url string, jmx *jmx) error {
-	res, err := http.Get(url)
-	if err != nil {
-		return err
-	}
-	defer res.Body.Close()
-	if err := json.NewDecoder(res.Body).Decode(&jmx); err != nil {
-		return err
-	}
-	return nil
-}
-
-func c_hbase_region() (opentsdb.MultiDataPoint, error) {
-	var j jmx
-	if err := getBeans(hbURL, &j); err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	if len(j.Beans) > 0 && len(j.Beans[0]) > 0 {
-		for k, v := range j.Beans[0] {
-			if _, ok := v.(float64); ok {
-				Add(&md, "hbase.region."+k, v, nil, metadata.Unknown, metadata.None, "")
-			}
-		}
-	}
-	return md, nil
-}
-
-func c_hbase_gc() (opentsdb.MultiDataPoint, error) {
-	var j jmx
-	if err := getBeans(hbGCURL, &j); err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	const metric = "hbase.region.gc."
-	for _, bean := range j.Beans {
-		if name, ok := bean["Name"].(string); ok && name != "" {
-			ts := opentsdb.TagSet{"name": name}
-			for k, v := range bean {
-				if _, ok := v.(float64); ok {
-					switch k {
-					case "CollectionCount":
-						Add(&md, metric+k, v, ts, metadata.Counter, metadata.Count, "A counter for the number of times that garbage collection has been called.")
-					case "CollectionTime":
-						Add(&md, metric+k, v, ts, metadata.Counter, metadata.None, "The total amount of time spent in garbage collection.")
-					}
-				}
-			}
-		}
-	}
-	return md, nil
-}
-
-func c_hbase_replication() (opentsdb.MultiDataPoint, error) {
-	var j jmx
-	if err := getBeans(hbRepURL, &j); err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, section := range j.Beans {
-		var tags opentsdb.TagSet
-		for k, v := range section {
-			if s, ok := v.(string); ok && k == "name" {
-				if strings.HasPrefix(s, "hadoop:service=Replication,name=ReplicationSource for") {
-					sa := strings.Split(s, " ")
-					if len(sa) == 3 {
-						tags = opentsdb.TagSet{"instance": sa[2]}
-						break
-					}
-				}
-			}
-		}
-		for k, v := range section {
-			if _, ok := v.(float64); ok {
-				Add(&md, "hbase.region."+k, v, tags, metadata.Unknown, metadata.None, "")
-			}
-		}
-	}
-	return md, nil
-}
diff --git a/cmd/scollector/collectors/ifstat_linux.go b/cmd/scollector/collectors/ifstat_linux.go
index 898cbc9..44a643b 100644
--- a/cmd/scollector/collectors/ifstat_linux.go
+++ b/cmd/scollector/collectors/ifstat_linux.go
@@ -7,6 +7,8 @@ import (
 	"bosun.org/metadata"
 	"bosun.org/opentsdb"
 	"bosun.org/util"
+
+	"strconv"
 )
 
 func init() {
@@ -37,7 +39,7 @@ var netFields = []struct {
 	{"compressed", metadata.Counter, metadata.Count},
 }
 
-var ifstatRE = regexp.MustCompile(`\s+(eth\d+|em\d+_\d+/\d+|em\d+_\d+|em\d+|` +
+var ifstatRE = regexp.MustCompile(`\s+(eth\d+|em\d+_\d+/\d+|vpn\d+|tun\d+|tap\d+|if\d+|em\d+_\d+|em\d+|` +
 	`bond\d+|team\d+|` + `p\d+p\d+_\d+/\d+|p\d+p\d+_\d+|p\d+p\d+):(.*)`)
 
 func c_ipcount_linux() (opentsdb.MultiDataPoint, error) {
@@ -101,6 +103,13 @@ func c_ifstat_linux() (opentsdb.MultiDataPoint, error) {
 				}, netFields[i].rate, netFields[i].unit, "")
 
 			}
+                        if i == 0 || i == 8 {
+				value, _ := strconv.ParseInt(v, 10, 64)
+                                Add(&md, "linux.net.bits", value * 8, opentsdb.TagSet{
+                                "iface":     intf,
+                                "direction": direction(i),
+                                }, netFields[i].rate, "bits", "")
+                        }
 		}
 		return nil
 	})
diff --git a/cmd/scollector/collectors/iis_windows.go b/cmd/scollector/collectors/iis_windows.go
deleted file mode 100644
index b7e8711..0000000
--- a/cmd/scollector/collectors/iis_windows.go
+++ /dev/null
@@ -1,173 +0,0 @@
-package collectors
-
-import (
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-)
-
-func init() {
-	c := &IntervalCollector{
-		F: c_iis_webservice,
-	}
-	c.init = wmiInit(c, func() interface{} { return &[]Win32_PerfRawData_W3SVC_WebService{} }, `WHERE Name <> '_Total'`, &iisQuery)
-	collectors = append(collectors, c)
-
-	c = &IntervalCollector{
-		F: c_iis_apppool,
-	}
-	c.init = wmiInit(c, func() interface{} { return &[]Win32_PerfRawData_APPPOOLCountersProvider_APPPOOLWAS{} }, `WHERE Name <> '_Total'`, &iisQueryAppPool)
-	collectors = append(collectors, c)
-}
-
-var (
-	iisQuery        string
-	iisQueryAppPool string
-)
-
-func c_iis_webservice() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_PerfRawData_W3SVC_WebService
-	err := queryWmi(iisQuery, &dst)
-	if err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		Add(&md, "iis.bytes", v.BytesReceivedPersec, opentsdb.TagSet{"site": v.Name, "direction": "received"}, metadata.Counter, metadata.BytesPerSecond, descIISBytesReceivedPersec)
-		Add(&md, "iis.bytes", v.BytesSentPersec, opentsdb.TagSet{"site": v.Name, "direction": "sent"}, metadata.Counter, metadata.BytesPerSecond, descIISBytesSentPersec)
-		Add(&md, "iis.requests", v.CGIRequestsPersec, opentsdb.TagSet{"site": v.Name, "method": "cgi"}, metadata.Counter, metadata.PerSecond, descIISCGIRequestsPersec)
-		Add(&md, "iis.connection_attempts", v.ConnectionAttemptsPersec, opentsdb.TagSet{"site": v.Name}, metadata.Counter, metadata.PerSecond, descIISConnectionAttemptsPersec)
-		Add(&md, "iis.requests", v.CopyRequestsPersec, opentsdb.TagSet{"site": v.Name, "method": "copy"}, metadata.Counter, metadata.PerSecond, descIISCopyRequestsPersec)
-		Add(&md, "iis.connections", v.CurrentConnections, opentsdb.TagSet{"site": v.Name}, metadata.Gauge, metadata.Count, descIISCurrentConnections)
-		Add(&md, "iis.requests", v.DeleteRequestsPersec, opentsdb.TagSet{"site": v.Name, "method": "delete"}, metadata.Counter, metadata.PerSecond, descIISDeleteRequestsPersec)
-		Add(&md, "iis.requests", v.GetRequestsPersec, opentsdb.TagSet{"site": v.Name, "method": "get"}, metadata.Counter, metadata.PerSecond, descIISGetRequestsPersec)
-		Add(&md, "iis.requests", v.HeadRequestsPersec, opentsdb.TagSet{"site": v.Name, "method": "head"}, metadata.Counter, metadata.PerSecond, descIISHeadRequestsPersec)
-		Add(&md, "iis.requests", v.ISAPIExtensionRequestsPersec, opentsdb.TagSet{"site": v.Name, "method": "isapi"}, metadata.Counter, metadata.PerSecond, descIISISAPIExtensionRequestsPersec)
-		Add(&md, "iis.errors", v.LockedErrorsPersec, opentsdb.TagSet{"site": v.Name, "type": "locked"}, metadata.Counter, metadata.PerSecond, descIISLockedErrorsPersec)
-		Add(&md, "iis.requests", v.LockRequestsPersec, opentsdb.TagSet{"site": v.Name, "method": "lock"}, metadata.Counter, metadata.PerSecond, descIISLockRequestsPersec)
-		Add(&md, "iis.requests", v.MkcolRequestsPersec, opentsdb.TagSet{"site": v.Name, "method": "mkcol"}, metadata.Counter, metadata.PerSecond, descIISMkcolRequestsPersec)
-		Add(&md, "iis.requests", v.MoveRequestsPersec, opentsdb.TagSet{"site": v.Name, "method": "move"}, metadata.Counter, metadata.PerSecond, descIISMoveRequestsPersec)
-		Add(&md, "iis.errors", v.NotFoundErrorsPersec, opentsdb.TagSet{"site": v.Name, "type": "notfound"}, metadata.Counter, metadata.PerSecond, descIISNotFoundErrorsPersec)
-		Add(&md, "iis.requests", v.OptionsRequestsPersec, opentsdb.TagSet{"site": v.Name, "method": "options"}, metadata.Counter, metadata.PerSecond, descIISOptionsRequestsPersec)
-		Add(&md, "iis.requests", v.PostRequestsPersec, opentsdb.TagSet{"site": v.Name, "method": "post"}, metadata.Counter, metadata.PerSecond, descIISPostRequestsPersec)
-		Add(&md, "iis.requests", v.PropfindRequestsPersec, opentsdb.TagSet{"site": v.Name, "method": "propfind"}, metadata.Counter, metadata.PerSecond, descIISPropfindRequestsPersec)
-		Add(&md, "iis.requests", v.ProppatchRequestsPersec, opentsdb.TagSet{"site": v.Name, "method": "proppatch"}, metadata.Counter, metadata.PerSecond, descIISProppatchRequestsPersec)
-		Add(&md, "iis.requests", v.PutRequestsPersec, opentsdb.TagSet{"site": v.Name, "method": "put"}, metadata.Counter, metadata.PerSecond, descIISPutRequestsPersec)
-		Add(&md, "iis.requests", v.SearchRequestsPersec, opentsdb.TagSet{"site": v.Name, "method": "search"}, metadata.Counter, metadata.PerSecond, descIISSearchRequestsPersec)
-		Add(&md, "iis.requests", v.TraceRequestsPersec, opentsdb.TagSet{"site": v.Name, "method": "trace"}, metadata.Counter, metadata.PerSecond, descIISTraceRequestsPersec)
-		Add(&md, "iis.requests", v.UnlockRequestsPersec, opentsdb.TagSet{"site": v.Name, "method": "unlock"}, metadata.Counter, metadata.PerSecond, descIISUnlockRequestsPersec)
-	}
-	return md, nil
-}
-
-const (
-	descIISBytesReceivedPersec          = "The rate that data bytes are received by the Web service."
-	descIISBytesSentPersec              = "The rate data bytes are being sent by the Web service."
-	descIISCGIRequestsPersec            = "The rate CGI requests are received by the Web service."
-	descIISConnectionAttemptsPersec     = "The rate that connections to the Web service are being attempted."
-	descIISCopyRequestsPersec           = "The rate HTTP requests using the COPY method are made.  Copy requests are used for copying files and directories."
-	descIISCurrentConnections           = "The current number of connections established with the Web service."
-	descIISDeleteRequestsPersec         = "The rate HTTP requests using the DELETE method are made.  Delete requests are generally used for file removals."
-	descIISGetRequestsPersec            = "The rate HTTP requests using the GET method are made.  Get requests are the most common HTTP request."
-	descIISHeadRequestsPersec           = "The rate HTTP requests using the HEAD method are made.  Head requests generally indicate a client is querying the state of a document they already have to see if it needs to be refreshed."
-	descIISISAPIExtensionRequestsPersec = "The rate that ISAPI Extension requests are received by the Web service."
-	descIISLockedErrorsPersec           = "The rate of errors due to requests that couldn't be satisfied by the server because the requested document was locked.  These are generally reported as an HTTP 423 error code to the client."
-	descIISLockRequestsPersec           = "The rate HTTP requests using the LOCK method are made.  Lock requests are used to lock a file for one user so that only that user can modify the file."
-	descIISMkcolRequestsPersec          = "The rate HTTP requests using the MKCOL method are made.  Mkcol requests are used to create directories on the server."
-	descIISMoveRequestsPersec           = "The rate HTTP requests using the MOVE method are made.  Move requests are used for moving files and directories."
-	descIISNotFoundErrorsPersec         = "The rate of errors due to requests that couldn't be satisfied by the server because the requested document could not be found.  These are generally reported as an HTTP 404 error code to the client."
-	descIISOptionsRequestsPersec        = "The rate HTTP requests using the OPTIONS method are made."
-	descIISPostRequestsPersec           = "The rate HTTP requests using the POST method are made."
-	descIISPropfindRequestsPersec       = "The rate HTTP requests using the PROPFIND method are made.  Propfind requests retrieve property values on files and directories."
-	descIISProppatchRequestsPersec      = "The rate HTTP requests using the PROPPATCH method are made.  Proppatch requests set property values on files and directories."
-	descIISPutRequestsPersec            = "The rate HTTP requests using the PUT method are made."
-	descIISSearchRequestsPersec         = "The rate HTTP requests using the SEARCH method are made.  Search requests are used to query the server to find resources that match a set of conditions provided by the client."
-	descIISTraceRequestsPersec          = "The rate HTTP requests using the TRACE method are made.  Trace requests allow the client to see what is being received at the end of the request chain and use the information for diagnostic purposes."
-	descIISUnlockRequestsPersec         = "The rate HTTP requests using the UNLOCK method are made.  Unlock requests are used to remove locks from files."
-)
-
-type Win32_PerfRawData_W3SVC_WebService struct {
-	BytesReceivedPersec          uint64
-	BytesSentPersec              uint64
-	CGIRequestsPersec            uint32
-	ConnectionAttemptsPersec     uint32
-	CopyRequestsPersec           uint32
-	CurrentConnections           uint32
-	DeleteRequestsPersec         uint32
-	GetRequestsPersec            uint32
-	HeadRequestsPersec           uint32
-	ISAPIExtensionRequestsPersec uint32
-	LockRequestsPersec           uint32
-	LockedErrorsPersec           uint32
-	MkcolRequestsPersec          uint32
-	MoveRequestsPersec           uint32
-	Name                         string
-	NotFoundErrorsPersec         uint32
-	OptionsRequestsPersec        uint32
-	PostRequestsPersec           uint32
-	PropfindRequestsPersec       uint32
-	ProppatchRequestsPersec      uint32
-	PutRequestsPersec            uint32
-	SearchRequestsPersec         uint32
-	TraceRequestsPersec          uint32
-	UnlockRequestsPersec         uint32
-}
-
-func c_iis_apppool() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_PerfRawData_APPPOOLCountersProvider_APPPOOLWAS
-	err := queryWmi(iisQueryAppPool, &dst)
-	if err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		tags := opentsdb.TagSet{"name": v.Name}
-		uptime := (v.Timestamp_Object - v.CurrentApplicationPoolUptime) / v.Frequency_Object
-		failtime := (v.Timestamp_Object - v.TimeSinceLastWorkerProcessFailure) / v.Frequency_Object
-		Add(&md, "iis.apppool.state", v.CurrentApplicationPoolState, tags, metadata.Gauge, metadata.StatusCode, descIISAppPoolCurrentApplicationPoolState)
-		Add(&md, "iis.apppool.uptime", uptime, tags, metadata.Gauge, metadata.Second, descIISAppPoolCurrentApplicationPoolUptime)
-		Add(&md, "iis.apppool.time_since_failure", failtime, tags, metadata.Gauge, metadata.Second, descIISAppPoolTimeSinceLastWorkerProcessFailure)
-		Add(&md, "iis.apppool.processes", v.CurrentWorkerProcesses, opentsdb.TagSet{"name": v.Name, "type": "current"}, metadata.Gauge, metadata.Count, descIISAppPoolCurrentWorkerProcesses)
-		Add(&md, "iis.apppool.processes", v.MaximumWorkerProcesses, opentsdb.TagSet{"name": v.Name, "type": "maximum"}, metadata.Gauge, metadata.Count, descIISAppPoolMaximumWorkerProcesses)
-		Add(&md, "iis.apppool.processes", v.RecentWorkerProcessFailures, opentsdb.TagSet{"name": v.Name, "type": "failed"}, metadata.Gauge, metadata.Count, descIISAppPoolRecentWorkerProcessFailures)
-		Add(&md, "iis.apppool.events", v.TotalApplicationPoolRecycles, opentsdb.TagSet{"name": v.Name, "type": "recycled"}, metadata.Counter, metadata.Event, descIISAppPoolTotalApplicationPoolRecycles)
-		Add(&md, "iis.apppool.events", v.TotalWorkerProcessesCreated, opentsdb.TagSet{"name": v.Name, "type": "created"}, metadata.Counter, metadata.Event, descIISAppPoolTotalWorkerProcessesCreated)
-		Add(&md, "iis.apppool.events", v.TotalWorkerProcessFailures, opentsdb.TagSet{"name": v.Name, "type": "failed_crash"}, metadata.Counter, metadata.Event, descIISAppPoolTotalWorkerProcessFailures)
-		Add(&md, "iis.apppool.events", v.TotalWorkerProcessPingFailures, opentsdb.TagSet{"name": v.Name, "type": "failed_ping"}, metadata.Counter, metadata.Event, descIISAppPoolTotalWorkerProcessPingFailures)
-		Add(&md, "iis.apppool.events", v.TotalWorkerProcessShutdownFailures, opentsdb.TagSet{"name": v.Name, "type": "failed_shutdown"}, metadata.Counter, metadata.Event, descIISAppPoolTotalWorkerProcessShutdownFailures)
-		Add(&md, "iis.apppool.events", v.TotalWorkerProcessStartupFailures, opentsdb.TagSet{"name": v.Name, "type": "failed_startup"}, metadata.Counter, metadata.Event, descIISAppPoolTotalWorkerProcessStartupFailures)
-	}
-	return md, nil
-}
-
-const (
-	descIISAppPoolCurrentApplicationPoolState        = "The current status of the application pool (1 - Uninitialized, 2 - Initialized, 3 - Running, 4 - Disabling, 5 - Disabled, 6 - Shutdown Pending, 7 - Delete Pending)."
-	descIISAppPoolCurrentApplicationPoolUptime       = "The length of time, in seconds, that the application pool has been running since it was started."
-	descIISAppPoolCurrentWorkerProcesses             = "The current number of worker processes that are running in the application pool."
-	descIISAppPoolMaximumWorkerProcesses             = "The maximum number of worker processes that have been created for the application pool since Windows Process Activation Service (WAS) started."
-	descIISAppPoolRecentWorkerProcessFailures        = "The number of times that worker processes for the application pool failed during the rapid-fail protection interval."
-	descIISAppPoolTimeSinceLastWorkerProcessFailure  = "The length of time, in seconds, since the last worker process failure occurred for the application pool."
-	descIISAppPoolTotalApplicationPoolRecycles       = "The number of times that the application pool has been recycled since Windows Process Activation Service (WAS) started."
-	descIISAppPoolTotalWorkerProcessesCreated        = "The number of worker processes created for the application pool since Windows Process Activation Service (WAS) started."
-	descIISAppPoolTotalWorkerProcessFailures         = "The number of times that worker processes have crashed since the application pool was started."
-	descIISAppPoolTotalWorkerProcessPingFailures     = "The number of times that Windows Process Activation Service (WAS) did not receive a response to ping messages sent to a worker process."
-	descIISAppPoolTotalWorkerProcessShutdownFailures = "The number of times that Windows Process Activation Service (WAS) failed to shut down a worker process."
-	descIISAppPoolTotalWorkerProcessStartupFailures  = "The number of times that Windows Process Activation Service (WAS) failed to start a worker process."
-)
-
-type Win32_PerfRawData_APPPOOLCountersProvider_APPPOOLWAS struct {
-	CurrentApplicationPoolState        uint32
-	CurrentApplicationPoolUptime       uint64
-	CurrentWorkerProcesses             uint32
-	Frequency_Object                   uint64
-	MaximumWorkerProcesses             uint32
-	Name                               string
-	RecentWorkerProcessFailures        uint32
-	TimeSinceLastWorkerProcessFailure  uint64
-	Timestamp_Object                   uint64
-	TotalApplicationPoolRecycles       uint32
-	TotalWorkerProcessesCreated        uint32
-	TotalWorkerProcessFailures         uint32
-	TotalWorkerProcessPingFailures     uint32
-	TotalWorkerProcessShutdownFailures uint32
-	TotalWorkerProcessStartupFailures  uint32
-}
diff --git a/cmd/scollector/collectors/keepalived_linux.go b/cmd/scollector/collectors/keepalived_linux.go
deleted file mode 100644
index c1dd54b..0000000
--- a/cmd/scollector/collectors/keepalived_linux.go
+++ /dev/null
@@ -1,186 +0,0 @@
-package collectors
-
-import (
-	"fmt"
-	"reflect"
-	"strings"
-
-	"bosun.org/_third_party/github.com/mjibson/snmp"
-
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-)
-
-type VRRPInstanceEntry struct {
-	VInstanceIndex             int64
-	VInstanceName              string
-	VInstanceVirtualRouterId   int64
-	VInstanceState             int64
-	VInstanceInitialState      int64
-	VInstanceWantedState       int64
-	VInstanceBasePriority      int64
-	VInstanceEffectivePriority int64
-	VInstanceVipsStatus        int64
-	VInstancePrimaryInterface  string
-	VInstanceTrackPrimaryIf    int64
-	VInstanceAdvertisementsInt int64
-	VInstancePreempt           int64
-	VInstancePreemptDelay      int64
-	VInstanceAuthType          int64
-	VInstanceLvsSyncDaemon     int64
-	VInstanceLvsSyncInterface  string
-	VInstanceSyncGroup         string
-	VInstanceGarpDelay         int64
-	VInstanceSmtpAlert         int64
-	VInstanceNotifyExec        int64
-	VInstanceScriptMaster      string
-	VInstanceScriptBackup      string
-	VInstanceScriptFault       string
-	VInstanceScriptStop        string
-	VInstanceScript            string
-}
-
-const (
-	VRRPInstanceTable = ".1.3.6.1.4.1.9586.100.5.2.3.1"
-	VRRPAddressTable  = ".1.3.6.1.4.1.9586.100.5.2.6.1"
-)
-
-const (
-	descVRRPState              = "VRRP Can be in one of the following states: init(0), backup(1), master(2), fault(3), unknown(4)."
-	descVRRPVipsStatus         = "Indicates if all the VIPs of this VRRP instance are enabled."
-	descVRRPBasePriority       = "Base priority (as defined in the configuration file) for this VRRP instance. This value can be modified to force the virtual router instance to become backup or master."
-	descVRRPEffectivePriority  = "Effective priority for this VRRP instance. Status of interfaces and script results are used to compute this value from the base priority."
-	descVRRPAddressStatus      = "Indicates if the IP address is set or not."
-	descVRRPAddressAdvertising = "Indicates if the IP address is being advertised or not."
-)
-
-func init() {
-	collectors = append(collectors, &IntervalCollector{F: c_snmp_keepalived_vrrp_instances})
-}
-
-func c_snmp_keepalived_vrrp_instances() (opentsdb.MultiDataPoint, error) {
-	if KeepalivedCommunity == "" {
-		return nil, nil
-	}
-	var md opentsdb.MultiDataPoint
-	entries := make(map[int]*VRRPInstanceEntry)
-	rows, err := snmp.Walk("localhost", KeepalivedCommunity, VRRPInstanceTable)
-	if err != nil {
-		return nil, nil
-	}
-	for rows.Next() {
-		var a interface{}
-		i, err := rows.Scan(&a)
-		if err != nil {
-			return nil, err
-		}
-		id, ok := i.([]int)
-		if !ok || len(id) != 2 {
-			return nil, fmt.Errorf("unexpected type for snmp keepalived index")
-		}
-		entry, ok := entries[id[1]]
-		if !ok {
-			entries[id[1]] = &VRRPInstanceEntry{}
-			entry = entries[id[1]]
-		}
-		s := reflect.ValueOf(entry)
-		nFields := reflect.ValueOf(*entry).NumField()
-		if id[0]+1 > nFields {
-			return nil, fmt.Errorf("unexpected number of fields for snmp keepalived VRRPInstanceTable")
-		}
-		v := s.Elem().Field(id[0] - 1)
-		switch t := a.(type) {
-		case int64:
-			v.SetInt(t)
-		case []uint8:
-			v.SetString(string(t))
-		}
-	}
-	for _, entry := range entries {
-		ts := opentsdb.TagSet{"instance_name": entry.VInstanceName, "instance_id": fmt.Sprint(entry.VInstanceVirtualRouterId)}
-		Add(&md, "keepalived.vrrp.state", entry.VInstanceState, ts, metadata.Gauge, metadata.StatusCode, descVRRPState)
-		Add(&md, "keepalived.vrrp.wanted_state", entry.VInstanceWantedState, ts, metadata.Gauge, metadata.StatusCode, descVRRPState)
-		Add(&md, "keepalived.vrrp.vips_status", entry.VInstanceVipsStatus, ts, metadata.Gauge, metadata.StatusCode, descVRRPVipsStatus)
-		Add(&md, "keepalived.vrrp.base_priority", entry.VInstanceBasePriority, ts, metadata.Gauge, metadata.Priority, descVRRPBasePriority)
-		Add(&md, "keepalived.vrrp.effective_priority", entry.VInstanceEffectivePriority, ts, metadata.Gauge, metadata.Priority, descVRRPEffectivePriority)
-	}
-	if err := keepalived_vrrp_addresses(&md, entries); err != nil {
-		return nil, err
-	}
-	return md, nil
-}
-
-type VRRPAddressEntry struct {
-	VRRPAddressIndex       int64
-	VRRPAddressType        int64
-	VRRPAddressValue       string `snmp:"octet"`
-	VRRPAddressBroadcast   string `snmp:"octet"`
-	VRRPAddressMask        int64
-	VRRPAddressScope       int64
-	VRRPAddressIfIndex     int64
-	VRRPAddressIfName      string
-	VRRPAddressIfAlias     string
-	VRRPAddressStatus      int64
-	VRRPAddressAdvertising int64
-}
-
-// Field (i.e Vrrp address type), Instance Index, Identifer
-
-func keepalived_vrrp_addresses(md *opentsdb.MultiDataPoint, instances map[int]*VRRPInstanceEntry) error {
-	entries := make(map[int]map[int]*VRRPAddressEntry)
-	rows, err := snmp.Walk("localhost", KeepalivedCommunity, VRRPAddressTable)
-	if err != nil {
-		return nil
-	}
-	for rows.Next() {
-		var a interface{}
-		i, err := rows.Scan(&a)
-		if err != nil {
-			return err
-		}
-		id, ok := i.([]int)
-		if !ok || len(id) != 3 {
-			return fmt.Errorf("unexpected type for snmp keepalived index")
-		}
-		if _, ok := entries[id[1]]; !ok {
-			entries[id[1]] = make(map[int]*VRRPAddressEntry)
-		}
-		entry, ok := entries[id[1]][id[2]]
-		if !ok {
-			entries[id[1]][id[2]] = &VRRPAddressEntry{}
-			entry = entries[id[1]][id[2]]
-		}
-		s := reflect.ValueOf(entry)
-		nFields := reflect.ValueOf(*entry).NumField()
-		nonPointerType := reflect.ValueOf(*entry).Type()
-		if id[0]-1 > nFields {
-			return fmt.Errorf("unexpected number of fields for snmp keepalived VRRPAddressTable")
-		}
-		v := s.Elem().Field(id[0] - 1)
-		switch t := a.(type) {
-		case int64:
-			v.SetInt(t)
-		case []uint8:
-			if nonPointerType.Kind() == reflect.Struct && nonPointerType.Field(id[0]-1).Tag.Get("snmp") == "octet" {
-				var s []string
-				for _, runeValue := range t {
-					s = append(s, fmt.Sprintf("%v", runeValue))
-				}
-				v.SetString(strings.Join(s, "."))
-			} else {
-				v.SetString(string(t))
-			}
-		}
-	}
-	for instance_id, instance := range instances {
-		for _, entry := range entries[instance_id] {
-			ts := opentsdb.TagSet{
-				"instance_name": instance.VInstanceName,
-				"instance_id":   fmt.Sprint(instance.VInstanceVirtualRouterId),
-				"address":       entry.VRRPAddressValue}
-			Add(md, "keepalived.vrrp.address_status", entry.VRRPAddressStatus-1, ts, metadata.Gauge, metadata.Bool, descVRRPAddressStatus)
-			Add(md, "keepalived.vrrp.address_advertising", entry.VRRPAddressAdvertising-1, ts, metadata.Gauge, metadata.Bool, descVRRPAddressStatus)
-		}
-	}
-	return nil
-}
diff --git a/cmd/scollector/collectors/mem_windows.go b/cmd/scollector/collectors/mem_windows.go
deleted file mode 100644
index d9ca717..0000000
--- a/cmd/scollector/collectors/mem_windows.go
+++ /dev/null
@@ -1,164 +0,0 @@
-package collectors
-
-import (
-	"bosun.org/_third_party/github.com/StackExchange/wmi"
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-)
-
-func init() {
-	collectors = append(collectors, &IntervalCollector{F: c_simple_mem_windows})
-	collectors = append(collectors, &IntervalCollector{F: c_windows_memory})
-	collectors = append(collectors, &IntervalCollector{F: c_windows_pagefile})
-}
-
-func c_simple_mem_windows() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_OperatingSystem
-	var q = wmi.CreateQuery(&dst, "")
-	err := queryWmi(q, &dst)
-	if err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		Add(&md, "win.mem.vm.total", v.TotalVirtualMemorySize*1024, nil, metadata.Gauge, metadata.Bytes, descWinMemVirtual_Total)
-		Add(&md, "win.mem.vm.free", v.FreeVirtualMemory*1024, nil, metadata.Gauge, metadata.Bytes, descWinMemVirtual_Free)
-		Add(&md, "win.mem.total", v.TotalVisibleMemorySize*1024, nil, metadata.Gauge, metadata.Bytes, descWinMemVisible_Total)
-		Add(&md, "win.mem.free", v.FreePhysicalMemory*1024, nil, metadata.Gauge, metadata.Bytes, descWinMemVisible_Free)
-		Add(&md, osMemTotal, v.TotalVisibleMemorySize*1024, nil, metadata.Gauge, metadata.Bytes, osMemTotalDesc)
-		Add(&md, osMemFree, v.FreePhysicalMemory*1024, nil, metadata.Gauge, metadata.Bytes, osMemFreeDesc)
-		Add(&md, osMemUsed, v.TotalVisibleMemorySize*1024-v.FreePhysicalMemory*1024, nil, metadata.Gauge, metadata.Bytes, osMemUsedDesc)
-		Add(&md, osMemPctFree, float64(v.FreePhysicalMemory)/float64(v.TotalVisibleMemorySize)*100, nil, metadata.Gauge, metadata.Pct, osMemPctFreeDesc)
-	}
-	return md, nil
-}
-
-const (
-	descWinMemVirtual_Total = "Number, in bytes, of virtual memory."
-	descWinMemVirtual_Free  = "Number, in bytes, of virtual memory currently unused and available."
-	descWinMemVisible_Total = "Total amount, in bytes, of physical memory available to the operating system."
-	descWinMemVisible_Free  = "Number, in bytes, of physical memory currently unused and available."
-)
-
-type Win32_OperatingSystem struct {
-	FreePhysicalMemory     uint64
-	FreeVirtualMemory      uint64
-	TotalVirtualMemorySize uint64
-	TotalVisibleMemorySize uint64
-}
-
-func c_windows_memory() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_PerfRawData_PerfOS_Memory
-	var q = wmi.CreateQuery(&dst, "")
-	err := queryWmi(q, &dst)
-	if err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		Add(&md, "win.mem.cache", v.CacheBytes, nil, metadata.Gauge, metadata.Bytes, descWinMemCacheBytes)
-		Add(&md, "win.mem.cache_peak", v.CacheBytesPeak, nil, metadata.Gauge, metadata.Bytes, descWinMemCacheBytesPeak)
-		Add(&md, "win.mem.committed", v.CommittedBytes, nil, metadata.Gauge, metadata.Bytes, descWinMemCommittedBytes)
-		Add(&md, "win.mem.committed_limit", v.CommitLimit, nil, metadata.Gauge, metadata.Bytes, descWinMemCommitLimit)
-		Add(&md, "win.mem.committed_percent", float64(v.PercentCommittedBytesInUse)/float64(v.PercentCommittedBytesInUse_Base)*100, nil, metadata.Gauge, metadata.Pct, descWinMemPercentCommittedBytesInUse)
-		Add(&md, "win.mem.modified", v.ModifiedPageListBytes, nil, metadata.Gauge, metadata.Bytes, descWinMemModifiedPageListBytes)
-		Add(&md, "win.mem.page_faults", v.PageFaultsPersec, nil, metadata.Counter, metadata.PerSecond, descWinMemPageFaultsPersec)
-		Add(&md, "win.mem.faults", v.CacheFaultsPersec, opentsdb.TagSet{"type": "cache"}, metadata.Counter, metadata.PerSecond, descWinMemCacheFaultsPersec)
-		Add(&md, "win.mem.faults", v.DemandZeroFaultsPersec, opentsdb.TagSet{"type": "demand_zero"}, metadata.Counter, metadata.PerSecond, descWinMemDemandZeroFaultsPersec)
-		Add(&md, "win.mem.faults", v.TransitionFaultsPersec, opentsdb.TagSet{"type": "transition"}, metadata.Counter, metadata.PerSecond, descWinMemTransitionFaultsPersec)
-		Add(&md, "win.mem.faults", v.WriteCopiesPersec, opentsdb.TagSet{"type": "write_copies"}, metadata.Counter, metadata.PerSecond, descWinMemWriteCopiesPersec)
-		Add(&md, "win.mem.page_operations", v.PageReadsPersec, opentsdb.TagSet{"type": "read"}, metadata.Counter, metadata.PerSecond, descWinMemPageReadsPersec)
-		Add(&md, "win.mem.page_operations", v.PageWritesPersec, opentsdb.TagSet{"type": "write"}, metadata.Counter, metadata.PerSecond, descWinMemPageWritesPersec)
-		Add(&md, "win.mem.page_operations", v.PagesInputPersec, opentsdb.TagSet{"type": "input"}, metadata.Counter, metadata.PerSecond, descWinMemPagesInputPersec)
-		Add(&md, "win.mem.page_operations", v.PagesOutputPersec, opentsdb.TagSet{"type": "output"}, metadata.Counter, metadata.PerSecond, descWinMemPagesOutputPersec)
-		Add(&md, "win.mem.pool.bytes", v.PoolNonpagedBytes, opentsdb.TagSet{"type": "nonpaged"}, metadata.Gauge, metadata.Bytes, descWinMemPoolNonpagedBytes)
-		Add(&md, "win.mem.pool.bytes", v.PoolPagedBytes, opentsdb.TagSet{"type": "paged"}, metadata.Gauge, metadata.Bytes, descWinMemPoolPagedBytes)
-		Add(&md, "win.mem.pool.bytes", v.PoolPagedResidentBytes, opentsdb.TagSet{"type": "paged_resident"}, metadata.Gauge, metadata.Bytes, descWinMemPoolPagedResidentBytes)
-		Add(&md, "win.mem.pool.allocations", v.PoolPagedAllocs, opentsdb.TagSet{"type": "paged"}, metadata.Gauge, metadata.Operation, descWinMemPoolPagedAllocs)
-		Add(&md, "win.mem.pool.allocations", v.PoolNonpagedAllocs, opentsdb.TagSet{"type": "nonpaged"}, metadata.Gauge, metadata.Operation, descWinMemPoolNonpagedAllocs)
-	}
-	return md, nil
-}
-
-const (
-	descWinMemCacheBytes                 = "Cache Bytes the size, in bytes, of the portion of the system file cache which is currently resident and active in physical memory."
-	descWinMemCacheBytesPeak             = "Cache Bytes Peak is the maximum number of bytes used by the system file cache since the system was last restarted. This might be larger than the current size of the cache."
-	descWinMemCacheFaultsPersec          = "Cache Faults/sec is the rate at which faults occur when a page sought in the file system cache is not found and must be retrieved from elsewhere in memory (a soft fault) or from disk (a hard fault). The file system cache is an area of physical memory that stores recently used pages of data for applications. Cache activity is a reliable indicator of most application I/O operations. This counter shows the number of faults, without regard for the number of pages faulted in each operation."
-	descWinMemCommitLimit                = "Commit Limit is the amount of virtual memory that can be committed without having to extend the paging file(s).  It is measured in bytes. Committed memory is the physical memory which has space reserved on the disk paging files. If the paging file(s) are be expanded, this limit increases accordingly."
-	descWinMemCommittedBytes             = "Committed Bytes is the amount of committed virtual memory, in bytes. Committed memory is the physical memory which has space reserved on the disk paging file(s)."
-	descWinMemDemandZeroFaultsPersec     = "Demand Zero Faults/sec is the rate at which a zeroed page is required to satisfy the fault.  Zeroed pages, pages emptied of previously stored data and filled with zeros, are a security feature of Windows that prevent processes from seeing data stored by earlier processes that used the memory space. Windows maintains a list of zeroed pages to accelerate this process. This counter shows the number of faults, without regard to the number of pages retrieved to satisfy the fault."
-	descWinMemModifiedPageListBytes      = "Modified Page List Bytes is the amount of physical memory, in bytes, that is assigned to the modified page list. This memory contains cached data and code that is not actively in use by processes, the system and the system cache. This memory needs to be written out before it will be available for allocation to a process or for system use."
-	descWinMemPageFaultsPersec           = "Page Faults/sec is the average number of pages faulted per second. It is measured in number of pages faulted per second because only one page is faulted in each fault operation, hence this is also equal to the number of page fault operations. This counter includes both hard faults (those that require disk access) and soft faults (where the faulted page is found elsewhere in physical memory.) Most processors can handle large numbers of soft faults without significant consequence. However, hard faults, which require disk access, can cause significant delays."
-	descWinMemPageReadsPersec            = "Page Reads/sec is the rate at which the disk was read to resolve hard page faults. It shows the number of reads operations, without regard to the number of pages retrieved in each operation. Hard page faults occur when a process references a page in virtual memory that is not in working set or elsewhere in physical memory, and must be retrieved from disk. This counter is a primary indicator of the kinds of faults that cause system-wide delays. It includes read operations to satisfy faults in the file system cache (usually requested by applications) and in non-cached mapped memory files. Compare the value of Memory\\Pages Reads/sec to the value of Memory\\Pages Input/sec to determine the average number of pages read during each operation."
-	descWinMemPagesInputPersec           = "Pages Input/sec is the rate at which pages are read from disk to resolve hard page faults. Hard page faults occur when a process refers to a page in virtual memory that is not in its working set or elsewhere in physical memory, and must be retrieved from disk. When a page is faulted, the system tries to read multiple contiguous pages into memory to maximize the benefit of the read operation. Compare the value of Memory\\Pages Input/sec to the value of  Memory\\Page Reads/sec to determine the average number of pages read into memory during each read operation."
-	descWinMemPagesOutputPersec          = "Pages Output/sec is the rate at which pages are written to disk to free up space in physical memory. Pages are written back to disk only if they are changed in physical memory, so they are likely to hold data, not code. A high rate of pages output might indicate a memory shortage. Windows writes more pages back to disk to free up space when physical memory is in short supply.  This counter shows the number of pages, and can be compared to other counts of pages, without conversion."
-	descWinMemPageWritesPersec           = "Page Writes/sec is the rate at which pages are written to disk to free up space in physical memory. Pages are written to disk only if they are changed while in physical memory, so they are likely to hold data, not code. This counter shows write operations, without regard to the number of pages written in each operation."
-	descWinMemPercentCommittedBytesInUse = "% Committed Bytes In Use is the ratio of Memory\\Committed Bytes to the Memory\\Commit Limit. Committed memory is the physical memory in use for which space has been reserved in the paging file should it need to be written to disk. The commit limit is determined by the size of the paging file.  If the paging file is enlarged, the commit limit increases, and the ratio is reduced)."
-	descWinMemPoolNonpagedAllocs         = "Pool Nonpaged Allocs is the number of calls to allocate space in the nonpaged pool. The nonpaged pool is an area of system memory area for objects that cannot be written to disk, and must remain in physical memory as long as they are allocated.  It is measured in numbers of calls to allocate space, regardless of the amount of space allocated in each call."
-	descWinMemPoolNonpagedBytes          = "Pool Nonpaged Bytes is the size, in bytes, of the nonpaged pool, an area of the system virtual memory that is used for objects that cannot be written to disk, but must remain in physical memory as long as they are allocated.  Memory\\Pool Nonpaged Bytes is calculated differently than Process\\Pool Nonpaged Bytes, so it might not equal Process(_Total)\\Pool Nonpaged Bytes."
-	descWinMemPoolPagedAllocs            = "Pool Paged Allocs is the number of calls to allocate space in the paged pool. The paged pool is an area of the system virtual memory that is used for objects that can be written to disk when they are not being used. It is measured in numbers of calls to allocate space, regardless of the amount of space allocated in each call."
-	descWinMemPoolPagedBytes             = "Pool Paged Bytes is the size, in bytes, of the paged pool, an area of the system virtual memory that is used for objects that can be written to disk when they are not being used."
-	descWinMemPoolPagedResidentBytes     = "Pool Paged Resident Bytes is the size, in bytes, of the portion of the paged pool that is currently resident and active in physical memory."
-	descWinMemTransitionFaultsPersec     = "Transition Faults/sec is the rate at which page faults are resolved by recovering pages that were being used by another process sharing the page, or were on the modified page list or the standby list, or were being written to disk at the time of the page fault. The pages were recovered without additional disk activity. Transition faults are counted in numbers of faults; because only one page is faulted in each operation, it is also equal to the number of pages faulted."
-	descWinMemWriteCopiesPersec          = "Write Copies/sec is the rate at which page faults are caused by attempts to write that have been satisfied by coping of the page from elsewhere in physical memory. This is an economical way of sharing data since pages are only copied when they are written to; otherwise, the page is shared. This counter shows the number of copies, without regard for the number of pages copied in each operation."
-)
-
-type Win32_PerfRawData_PerfOS_Memory struct {
-	CacheBytes                      uint64
-	CacheBytesPeak                  uint64
-	CacheFaultsPersec               uint32
-	CommitLimit                     uint64
-	CommittedBytes                  uint64
-	DemandZeroFaultsPersec          uint32
-	ModifiedPageListBytes           uint64
-	PageFaultsPersec                uint32
-	PageReadsPersec                 uint32
-	PagesInputPersec                uint32
-	PagesOutputPersec               uint32
-	PageWritesPersec                uint32
-	PercentCommittedBytesInUse      uint32
-	PercentCommittedBytesInUse_Base uint32
-	PoolNonpagedAllocs              uint32
-	PoolNonpagedBytes               uint64
-	PoolPagedAllocs                 uint32
-	PoolPagedBytes                  uint64
-	PoolPagedResidentBytes          uint64
-	TransitionFaultsPersec          uint32
-	WriteCopiesPersec               uint32
-}
-
-func c_windows_pagefile() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_PageFileUsage
-	var q = wmi.CreateQuery(&dst, "")
-	err := queryWmi(q, &dst)
-	if err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		driveletter := "unknown"
-		if len(v.Name) >= 1 {
-			driveletter = v.Name[0:1]
-		}
-		tags := opentsdb.TagSet{"drive": driveletter}
-		Add(&md, "win.mem.pagefile.size", int64(v.AllocatedBaseSize)*1024*1024, tags, metadata.Gauge, metadata.Bytes, descWinMemPagefileAllocatedBaseSize)
-		Add(&md, "win.mem.pagefile.usage_current", int64(v.CurrentUsage)*1024*1024, tags, metadata.Gauge, metadata.Bytes, descWinMemPagefileCurrentUsage)
-		Add(&md, "win.mem.pagefile.usage_peak", int64(v.PeakUsage)*1024*1024, tags, metadata.Gauge, metadata.Bytes, descWinMemPagefilePeakUsage)
-		Add(&md, "win.mem.pagefile.usage_percent", float64(v.CurrentUsage)/float64(v.AllocatedBaseSize)*100, tags, metadata.Gauge, metadata.Pct, descWinMemPagefilePercent)
-	}
-	return md, nil
-}
-
-const (
-	descWinMemPagefileAllocatedBaseSize = "The actual amount of disk space in bytes allocated for use with this page file. This value corresponds to the range established in Win32_PageFileSetting under the InitialSize and MaximumSize properties, set at system startup."
-	descWinMemPagefileCurrentUsage      = "How many bytes of the total reserved page file are currently in use."
-	descWinMemPagefilePeakUsage         = "The maximum number of bytes used in the page file since the system was restarted."
-	descWinMemPagefilePercent           = "The current used page file size / total page file size."
-)
-
-type Win32_PageFileUsage struct {
-	AllocatedBaseSize uint32
-	CurrentUsage      uint32
-	PeakUsage         uint32
-	Name              string
-}
diff --git a/cmd/scollector/collectors/netbackup.go b/cmd/scollector/collectors/netbackup.go
deleted file mode 100644
index fc891c2..0000000
--- a/cmd/scollector/collectors/netbackup.go
+++ /dev/null
@@ -1,210 +0,0 @@
-package collectors
-
-import (
-	"encoding/csv"
-	"fmt"
-	"reflect"
-	"strconv"
-	"strings"
-	"time"
-
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-	"bosun.org/util"
-)
-
-func init() {
-	collectors = append(collectors, &IntervalCollector{F: c_netbackup_jobs})
-	collectors = append(collectors, &IntervalCollector{F: c_netbackup_frequency})
-}
-
-//jobtype
-// 0=backup, 1=archive, 2=restore, 3=verify, 4=duplicate, 5=import, 6=catalog backup, 7=vault, 8=label
-// 9=erase, 10=tape request, 11=tape clean, 12=format tape, 13=physical inventory, 14=qualification
-// 15=database recovery, 16=media contents, 17=image delete, 18=LiveUpdate
-
-//state
-// 0=queued, 1=active, 2=wait for retry, 3=done, 4=suspended, 5=incomplete
-
-//NOTE!!
-// This depends on the retention of the job log being greater than the jobs,
-// else things are going to go unknown. See
-// http://www.symantec.com/connect/forums/netbackup-75-activity-monitor-job-logs
-// In my case I created the two registry entries mentioned in that link
-// (KEEP_JOB_HOURS) and (KEEP_JOBS_SUCCESSFUL_HOURS). I also changed the
-// rentention under "Clean-up" under the master server properties via the Java
-// Admin Console. One of those seems to have worked. This *is* netbackup, so I
-// wish you the best of luck ;-).
-
-type nbJob struct {
-	Jobid             string
-	Jobtype           int
-	State             int
-	Status            string
-	Class             string
-	Schedule          string
-	Client            string
-	Server            string
-	Started           time.Time
-	Elapsed           string
-	Ended             time.Time
-	Stunit            string
-	Try               string
-	Operation         string
-	Kbytes            int
-	Files             int
-	Pathlastwritten   string
-	Percent           string
-	Jobpid            string
-	Owner             string
-	Subtype           string
-	Classtype         string
-	Schedule_Type     string
-	Priority          string
-	Group             string
-	Masterserver      string
-	Retentionunits    string
-	Retentionperiod   string
-	Compression       string
-	Kbyteslastwritten string
-	Fileslastwritten  string
-}
-
-var timeType = reflect.TypeOf(time.Time{})
-
-func nbUnmarhsall(reader *csv.Reader, v interface{}) error {
-	record, err := reader.Read()
-	if err != nil {
-		return err
-	}
-	if len(record) < 32 {
-		return fmt.Errorf("record too short, expected at least 32 fields, got %v", len(record))
-	}
-	s := reflect.ValueOf(v).Elem()
-	for i := 0; i < s.NumField(); i++ {
-		f := s.Field(i)
-		switch f.Kind() {
-		case reflect.String:
-			f.SetString(record[i])
-		case reflect.Int:
-			var ival int64
-			if record[i] == "" {
-				continue
-			}
-			ival, err = strconv.ParseInt(record[i], 10, 64)
-			if err != nil {
-				return err
-			}
-			f.SetInt(ival)
-		case reflect.Struct:
-			switch f.Type() {
-			case timeType:
-				ival, err := strconv.ParseInt(record[i], 10, 64)
-				if err != nil {
-					return err
-				}
-				t := time.Unix(ival, 0)
-				f.Set(reflect.ValueOf(t))
-			default:
-				return fmt.Errorf("unsupported type: %s", f.Type())
-			}
-		default:
-			return fmt.Errorf("unsupported type: %s", f.Type())
-		}
-	}
-	return nil
-}
-
-func c_netbackup_jobs() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	latest := make(map[string]nbJob)
-	if err := util.ReadCommand(func(line string) error {
-		if len(line) < 32 {
-			return nil
-		}
-		var r nbJob
-		reader := csv.NewReader(strings.NewReader(line))
-		if err := nbUnmarhsall(reader, &r); err != nil {
-			return err
-		}
-		if !(r.Jobtype == 0 || r.Jobtype == 6) {
-			return nil
-		}
-		if r.State != 3 && r.State != 5 {
-			return nil
-		}
-		key := r.Class + r.Schedule + r.Client
-		if existing, ok := latest[key]; !ok {
-			latest[key] = r
-		} else if r.Started.After(existing.Started) {
-			latest[key] = r
-		}
-		return nil
-	}, "bpdbjobs", "-report", "-all_columns"); err == util.ErrPath {
-		return nil, nil
-	} else if err != nil {
-		return nil, err
-	}
-	now := time.Now()
-	for _, r := range latest {
-		tags := opentsdb.TagSet{"class": r.Class, "client": r.Client, "schedule": r.Schedule}
-		Add(&md, "netbackup.backup.status", r.Status, tags, metadata.Gauge, metadata.StatusCode, "")
-		Add(&md, "netbackup.backup.duration", r.Elapsed, tags, metadata.Gauge, metadata.Second, "")
-		Add(&md, "netbackup.backup.attempt_age", now.Sub(r.Ended).Seconds(), tags, metadata.Gauge, metadata.Second, "")
-		Add(&md, "netbackup.backup.duration", r.Elapsed, tags, metadata.Gauge, metadata.Second, "")
-		Add(&md, "netbackup.backup.no_files", r.Files, tags, metadata.Gauge, metadata.Count, "")
-		Add(&md, "netbackup.backup.kbytes", r.Kbytes, tags, metadata.Gauge, metadata.KBytes, "")
-	}
-	return md, nil
-}
-
-func c_netbackup_frequency() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	var class, schedule string
-	var clients []string
-	if err := util.ReadCommand(func(line string) error {
-		if strings.HasPrefix(line, "Policy Name:") {
-			clients = nil
-			f := strings.Fields(line)
-			if len(f) == 3 {
-				class = f[2]
-				return nil
-			}
-			return fmt.Errorf("error parsing policy: %v", line)
-		}
-		if strings.HasPrefix(line, "Client/HW/OS/Pri/DMI/CIT:") {
-			f := strings.Fields(line)
-			if len(f) == 9 {
-				clients = append(clients, f[1])
-				return nil
-			}
-			return fmt.Errorf("error parsing client")
-		}
-		if strings.HasPrefix(line, "Schedule:") {
-			f := strings.Fields(line)
-			if len(f) > 1 {
-				schedule = f[1]
-				return nil
-			}
-			return fmt.Errorf("error parsing client: %v", line)
-		}
-		if strings.HasPrefix(strings.TrimSpace(line), "Frequency:") {
-			f := strings.Fields(line)
-			if len(f) == 5 {
-				freq := strings.TrimLeft(f[3], "(")
-				for _, client := range clients {
-					tags := opentsdb.TagSet{"class": class, "client": client, "schedule": schedule}
-					Add(&md, "netbackup.backup.frequency", freq, tags, metadata.Gauge, metadata.Second, "")
-				}
-				return nil
-			}
-			return fmt.Errorf("error parsing frequency: %v", line)
-		}
-		return nil
-	}, "bppllist", "-L", "-allpolicies"); err == util.ErrPath {
-		return nil, nil
-	} else if err != nil {
-		return nil, err
-	}
-	return md, nil
-}
diff --git a/cmd/scollector/collectors/network_windows.go b/cmd/scollector/collectors/network_windows.go
deleted file mode 100644
index 037d015..0000000
--- a/cmd/scollector/collectors/network_windows.go
+++ /dev/null
@@ -1,371 +0,0 @@
-package collectors
-
-import (
-	"fmt"
-	"math"
-	"regexp"
-	"strings"
-	"time"
-
-	"bosun.org/_third_party/github.com/StackExchange/wmi"
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-	"bosun.org/slog"
-)
-
-func init() {
-	collectors = append(collectors, &IntervalCollector{F: c_network_windows, init: winNetworkInit})
-
-	c_winnetteam := &IntervalCollector{
-		F: c_network_team_windows,
-	}
-	// Make sure MSFT_NetImPlatAdapter and MSFT_NetAdapterStatisticsSettingData
-	// are valid WMI classes when initializing c_network_team_windows
-	c_winnetteam.init = func() {
-		var dstTeamNic []MSFT_NetLbfoTeamNic
-		var dstStats []MSFT_NetAdapterStatisticsSettingData
-		queryTeamAdapter = wmi.CreateQuery(&dstTeamNic, "")
-		queryTeamStats = wmi.CreateQuery(&dstStats, "")
-		c_winnetteam.Enable = func() bool {
-			errTeamNic := queryWmiNamespace(queryTeamAdapter, &dstTeamNic, namespaceStandardCimv2)
-			errStats := queryWmiNamespace(queryTeamStats, &dstStats, namespaceStandardCimv2)
-			result := errTeamNic == nil && errStats == nil
-			return result
-		}
-	}
-	collectors = append(collectors, c_winnetteam)
-	c := &IntervalCollector{
-		F: c_network_windows_tcp,
-	}
-	c.init = wmiInit(c, func() interface{} { return &[]Win32_PerfRawData_Tcpip_TCPv4{} }, "", &winNetTCPQuery)
-	collectors = append(collectors, c)
-}
-
-var (
-	queryTeamStats         string
-	queryTeamAdapter       string
-	winNetTCPQuery         string
-	namespaceStandardCimv2 = "root\\StandardCimv2"
-	interfaceExclusions    = regexp.MustCompile("isatap|Teredo")
-
-	// instanceNameToUnderscore matches '#' '/' and '\' for replacing with '_'.
-	instanceNameToUnderscore         = regexp.MustCompile("[#/\\\\]")
-	mNicInstanceNameToInterfaceIndex = make(map[string]string)
-)
-
-// winNetworkToInstanceName converts a Network Adapter Name to the InstanceName
-// that is used in Win32_PerfRawData_Tcpip_NetworkInterface.
-func winNetworkToInstanceName(Name string) string {
-	instanceName := Name
-	instanceName = strings.Replace(instanceName, "(", "[", -1)
-	instanceName = strings.Replace(instanceName, ")", "]", -1)
-	instanceName = instanceNameToUnderscore.ReplaceAllString(instanceName, "_")
-	return instanceName
-}
-
-// winNetworkInit maintains a mapping of InstanceName to InterfaceIndex
-func winNetworkInit() {
-	update := func() {
-		var dstNetworkAdapter []Win32_NetworkAdapter
-		q := wmi.CreateQuery(&dstNetworkAdapter, "WHERE PhysicalAdapter=True and MACAddress <> null")
-		err := queryWmi(q, &dstNetworkAdapter)
-		if err != nil {
-			slog.Error(err)
-			return
-		}
-		for _, nic := range dstNetworkAdapter {
-			var iface = fmt.Sprint("Interface", nic.InterfaceIndex)
-			// Get PnPName using Win32_PnPEntity class
-			var pnpname = ""
-			var escapeddeviceid = strings.Replace(nic.PNPDeviceID, "\\", "\\\\", -1)
-			var filter = fmt.Sprintf("WHERE DeviceID='%s'", escapeddeviceid)
-			var dstPnPName []Win32_PnPEntity
-			q = wmi.CreateQuery(&dstPnPName, filter)
-			err = queryWmi(q, &dstPnPName)
-			if err != nil {
-				slog.Error(err)
-				return
-			}
-			for _, pnp := range dstPnPName { // Really should be a single item
-				pnpname = pnp.Name
-			}
-			if pnpname == "" {
-				slog.Errorf("%s cannot find Win32_PnPEntity %s", iface, filter)
-				continue
-			}
-
-			// Convert to instance name (see http://goo.gl/jfq6pq )
-			instanceName := winNetworkToInstanceName(pnpname)
-			mNicInstanceNameToInterfaceIndex[instanceName] = iface
-		}
-	}
-	update()
-	go func() {
-		for range time.Tick(time.Minute * 5) {
-			update()
-		}
-	}()
-}
-
-func c_network_windows() (opentsdb.MultiDataPoint, error) {
-	var dstStats []Win32_PerfRawData_Tcpip_NetworkInterface
-	var q = wmi.CreateQuery(&dstStats, "")
-	err := queryWmi(q, &dstStats)
-	if err != nil {
-		return nil, err
-	}
-
-	var md opentsdb.MultiDataPoint
-	for _, nicStats := range dstStats {
-		if interfaceExclusions.MatchString(nicStats.Name) {
-			continue
-		}
-
-		iface := mNicInstanceNameToInterfaceIndex[nicStats.Name]
-		if iface == "" {
-			continue
-		}
-		// This does NOT include TEAM network adapters. Those will go to os.net.bond
-		tagsIn := opentsdb.TagSet{"iface": iface, "direction": "in"}
-		tagsOut := opentsdb.TagSet{"iface": iface, "direction": "out"}
-		Add(&md, "win.net.ifspeed", nicStats.CurrentBandwidth, opentsdb.TagSet{"iface": iface}, metadata.Gauge, metadata.BitsPerSecond, descWinNetCurrentBandwidth)
-		Add(&md, "win.net.bytes", nicStats.BytesReceivedPersec, tagsIn, metadata.Counter, metadata.BytesPerSecond, descWinNetBytesReceivedPersec)
-		Add(&md, "win.net.bytes", nicStats.BytesSentPersec, tagsOut, metadata.Counter, metadata.BytesPerSecond, descWinNetBytesSentPersec)
-		Add(&md, "win.net.packets", nicStats.PacketsReceivedPersec, tagsIn, metadata.Counter, metadata.PerSecond, descWinNetPacketsReceivedPersec)
-		Add(&md, "win.net.packets", nicStats.PacketsSentPersec, tagsOut, metadata.Counter, metadata.PerSecond, descWinNetPacketsSentPersec)
-		Add(&md, "win.net.dropped", nicStats.PacketsOutboundDiscarded, tagsOut, metadata.Counter, metadata.PerSecond, descWinNetPacketsOutboundDiscarded)
-		Add(&md, "win.net.dropped", nicStats.PacketsReceivedDiscarded, tagsIn, metadata.Counter, metadata.PerSecond, descWinNetPacketsReceivedDiscarded)
-		Add(&md, "win.net.errs", nicStats.PacketsOutboundErrors, tagsOut, metadata.Counter, metadata.PerSecond, descWinNetPacketsOutboundErrors)
-		Add(&md, "win.net.errs", nicStats.PacketsReceivedErrors, tagsIn, metadata.Counter, metadata.PerSecond, descWinNetPacketsReceivedErrors)
-		Add(&md, osNetBytes, nicStats.BytesReceivedPersec, tagsIn, metadata.Counter, metadata.BytesPerSecond, osNetBytesDesc)
-		Add(&md, osNetBytes, nicStats.BytesSentPersec, tagsOut, metadata.Counter, metadata.BytesPerSecond, osNetBytesDesc)
-		Add(&md, osNetPackets, nicStats.PacketsReceivedPersec, tagsIn, metadata.Counter, metadata.PerSecond, osNetPacketsDesc)
-		Add(&md, osNetPackets, nicStats.PacketsSentPersec, tagsOut, metadata.Counter, metadata.PerSecond, osNetPacketsDesc)
-		Add(&md, osNetDropped, nicStats.PacketsOutboundDiscarded, tagsOut, metadata.Counter, metadata.PerSecond, osNetDroppedDesc)
-		Add(&md, osNetDropped, nicStats.PacketsReceivedDiscarded, tagsIn, metadata.Counter, metadata.PerSecond, osNetDroppedDesc)
-		Add(&md, osNetErrors, nicStats.PacketsOutboundErrors, tagsOut, metadata.Counter, metadata.PerSecond, osNetErrorsDesc)
-		Add(&md, osNetErrors, nicStats.PacketsReceivedErrors, tagsIn, metadata.Counter, metadata.PerSecond, osNetErrorsDesc)
-	}
-	return md, nil
-}
-
-const (
-	descWinNetCurrentBandwidth         = "Estimate of the interface's current bandwidth in bits per second (bps). For interfaces that do not vary in bandwidth or for those where no accurate estimation can be made, this value is the nominal bandwidth."
-	descWinNetBytesReceivedPersec      = "Bytes Received/sec is the rate at which bytes are received over each network adapter, including framing characters. Network Interface\\Bytes Received/sec is a subset of Network Interface\\Bytes Total/sec."
-	descWinNetBytesSentPersec          = "Bytes Sent/sec is the rate at which bytes are sent over each network adapter, including framing characters. Network Interface\\Bytes Sent/sec is a subset of Network Interface\\Bytes Total/sec."
-	descWinNetPacketsReceivedPersec    = "Packets Received/sec is the rate at which packets are received on the network interface."
-	descWinNetPacketsSentPersec        = "Packets Sent/sec is the rate at which packets are sent on the network interface."
-	descWinNetPacketsOutboundDiscarded = "Packets Outbound Discarded is the number of outbound packets that were chosen to be discarded even though no errors had been detected to prevent transmission. One possible reason for discarding packets could be to free up buffer space."
-	descWinNetPacketsReceivedDiscarded = "Packets Received Discarded is the number of inbound packets that were chosen to be discarded even though no errors had been detected to prevent their delivery to a higher-layer protocol.  One possible reason for discarding packets could be to free up buffer space."
-	descWinNetPacketsOutboundErrors    = "Packets Outbound Errors is the number of outbound packets that could not be transmitted because of errors."
-	descWinNetPacketsReceivedErrors    = "Packets Received Errors is the number of inbound packets that contained errors preventing them from being deliverable to a higher-layer protocol."
-)
-
-type Win32_PnPEntity struct {
-	Name string // Intel(R) Gigabit ET Quad Port Server Adapter #3
-}
-
-type Win32_NetworkAdapter struct {
-	Description    string // Intel(R) Gigabit ET Quad Port Server Adapter (no index)
-	InterfaceIndex uint32
-	PNPDeviceID    string
-}
-
-type Win32_PerfRawData_Tcpip_NetworkInterface struct {
-	CurrentBandwidth         uint32
-	BytesReceivedPersec      uint32
-	BytesSentPersec          uint32
-	Name                     string
-	PacketsOutboundDiscarded uint32
-	PacketsOutboundErrors    uint32
-	PacketsReceivedDiscarded uint32
-	PacketsReceivedErrors    uint32
-	PacketsReceivedPersec    uint32
-	PacketsSentPersec        uint32
-}
-
-// c_network_team_windows will add metrics for team network adapters from
-// MSFT_NetAdapterStatisticsSettingData for any adapters that are in
-// MSFT_NetLbfoTeamNic and have a valid instanceName.
-func c_network_team_windows() (opentsdb.MultiDataPoint, error) {
-	var dstTeamNic []*MSFT_NetLbfoTeamNic
-	err := queryWmiNamespace(queryTeamAdapter, &dstTeamNic, namespaceStandardCimv2)
-	if err != nil {
-		return nil, err
-	}
-
-	var dstStats []MSFT_NetAdapterStatisticsSettingData
-	err = queryWmiNamespace(queryTeamStats, &dstStats, namespaceStandardCimv2)
-	if err != nil {
-		return nil, err
-	}
-
-	mDescriptionToTeamNic := make(map[string]*MSFT_NetLbfoTeamNic)
-	for _, teamNic := range dstTeamNic {
-		mDescriptionToTeamNic[teamNic.InterfaceDescription] = teamNic
-	}
-
-	var md opentsdb.MultiDataPoint
-	for _, nicStats := range dstStats {
-		TeamNic := mDescriptionToTeamNic[nicStats.InterfaceDescription]
-		if TeamNic == nil {
-			continue
-		}
-
-		instanceName := winNetworkToInstanceName(nicStats.InterfaceDescription)
-		iface := mNicInstanceNameToInterfaceIndex[instanceName]
-		if iface == "" {
-			continue
-		}
-		tagsIn := opentsdb.TagSet{"iface": iface, "direction": "in"}
-		tagsOut := opentsdb.TagSet{"iface": iface, "direction": "out"}
-		linkSpeed := math.Min(float64(TeamNic.ReceiveLinkSpeed), float64(TeamNic.Transmitlinkspeed))
-		Add(&md, "win.net.bond.ifspeed", linkSpeed, opentsdb.TagSet{"iface": iface}, metadata.Gauge, metadata.BitsPerSecond, descWinNetTeamlinkspeed)
-		Add(&md, "win.net.bond.bytes", nicStats.ReceivedBytes, tagsIn, metadata.Counter, metadata.BytesPerSecond, descWinNetTeamReceivedBytes)
-		Add(&md, "win.net.bond.bytes", nicStats.SentBytes, tagsOut, metadata.Counter, metadata.BytesPerSecond, descWinNetTeamSentBytes)
-		Add(&md, "win.net.bond.bytes_unicast", nicStats.ReceivedUnicastBytes, tagsIn, metadata.Counter, metadata.BytesPerSecond, descWinNetTeamReceivedUnicastBytes)
-		Add(&md, "win.net.bond.bytes_unicast", nicStats.SentUnicastBytes, tagsOut, metadata.Counter, metadata.BytesPerSecond, descWinNetTeamSentUnicastBytes)
-		Add(&md, "win.net.bond.bytes_broadcast", nicStats.ReceivedBroadcastBytes, tagsIn, metadata.Counter, metadata.BytesPerSecond, descWinNetTeamReceivedBroadcastBytes)
-		Add(&md, "win.net.bond.bytes_broadcast", nicStats.SentBroadcastBytes, tagsOut, metadata.Counter, metadata.BytesPerSecond, descWinNetTeamSentBroadcastBytes)
-		Add(&md, "win.net.bond.bytes_multicast", nicStats.ReceivedMulticastBytes, tagsIn, metadata.Counter, metadata.BytesPerSecond, descWinNetTeamReceivedMulticastBytes)
-		Add(&md, "win.net.bond.bytes_multicast", nicStats.SentMulticastBytes, tagsOut, metadata.Counter, metadata.BytesPerSecond, descWinNetTeamSentMulticastBytes)
-		Add(&md, "win.net.bond.packets_unicast", nicStats.ReceivedUnicastPackets, tagsIn, metadata.Counter, metadata.PerSecond, descWinNetTeamReceivedUnicastPackets)
-		Add(&md, "win.net.bond.packets_unicast", nicStats.SentUnicastPackets, tagsOut, metadata.Counter, metadata.PerSecond, descWinNetTeamSentUnicastPackets)
-		Add(&md, "win.net.bond.dropped", nicStats.ReceivedDiscardedPackets, tagsIn, metadata.Counter, metadata.PerSecond, descWinNetTeamReceivedDiscardedPackets)
-		Add(&md, "win.net.bond.dropped", nicStats.OutboundDiscardedPackets, tagsOut, metadata.Counter, metadata.PerSecond, descWinNetTeamOutboundDiscardedPackets)
-		Add(&md, "win.net.bond.errs", nicStats.ReceivedPacketErrors, tagsIn, metadata.Counter, metadata.PerSecond, descWinNetTeamReceivedPacketErrors)
-		Add(&md, "win.net.bond.errs", nicStats.OutboundPacketErrors, tagsOut, metadata.Counter, metadata.PerSecond, descWinNetTeamOutboundPacketErrors)
-		Add(&md, "win.net.bond.packets_multicast", nicStats.ReceivedMulticastPackets, tagsIn, metadata.Counter, metadata.PerSecond, descWinNetTeamReceivedMulticastPackets)
-		Add(&md, "win.net.bond.packets_multicast", nicStats.SentMulticastPackets, tagsOut, metadata.Counter, metadata.PerSecond, descWinNetTeamSentMulticastPackets)
-		Add(&md, "win.net.bond.packets_broadcast", nicStats.ReceivedBroadcastPackets, tagsIn, metadata.Counter, metadata.PerSecond, descWinNetTeamReceivedBroadcastPackets)
-		Add(&md, "win.net.bond.packets_broadcast", nicStats.SentBroadcastPackets, tagsOut, metadata.Counter, metadata.PerSecond, descWinNetTeamSentBroadcastPackets)
-		Add(&md, osNetBondifspeed, linkSpeed/1000000, opentsdb.TagSet{"iface": iface}, metadata.Gauge, metadata.Megabit, osNetBondifspeedDesc)
-		Add(&md, osNetBondBytes, nicStats.ReceivedBytes, tagsIn, metadata.Counter, metadata.Bytes, osNetBondBytesDesc)
-		Add(&md, osNetBondBytes, nicStats.SentBytes, tagsOut, metadata.Counter, metadata.Bytes, osNetBondBytesDesc)
-		Add(&md, osNetBondUnicast, nicStats.ReceivedUnicastPackets, tagsIn, metadata.Counter, metadata.Count, osNetBondUnicastDesc)
-		Add(&md, osNetBondUnicast, nicStats.SentUnicastPackets, tagsOut, metadata.Counter, metadata.Count, osNetBondUnicastDesc)
-		Add(&md, osNetBondMulticast, nicStats.ReceivedMulticastPackets, tagsIn, metadata.Counter, metadata.Count, osNetBondMulticastDesc)
-		Add(&md, osNetBondMulticast, nicStats.SentMulticastPackets, tagsOut, metadata.Counter, metadata.Count, osNetBondMulticastDesc)
-		Add(&md, osNetBondBroadcast, nicStats.ReceivedBroadcastPackets, tagsIn, metadata.Counter, metadata.Count, osNetBondBroadcastDesc)
-		Add(&md, osNetBondBroadcast, nicStats.SentBroadcastPackets, tagsOut, metadata.Counter, metadata.Count, osNetBondBroadcastDesc)
-		Add(&md, osNetBondPackets, float64(nicStats.ReceivedUnicastPackets)+float64(nicStats.ReceivedMulticastPackets)+float64(nicStats.ReceivedBroadcastPackets), tagsIn, metadata.Counter, metadata.Count, osNetBondPacketsDesc)
-		Add(&md, osNetBondPackets, float64(nicStats.SentUnicastPackets)+float64(nicStats.SentMulticastPackets)+float64(nicStats.SentBroadcastPackets), tagsOut, metadata.Counter, metadata.Count, osNetBondPacketsDesc)
-		Add(&md, osNetBondDropped, nicStats.ReceivedDiscardedPackets, tagsIn, metadata.Counter, metadata.Count, osNetBondDroppedDesc)
-		Add(&md, osNetBondDropped, nicStats.OutboundDiscardedPackets, tagsOut, metadata.Counter, metadata.Count, osNetBondDroppedDesc)
-		Add(&md, osNetBondErrors, nicStats.ReceivedPacketErrors, tagsIn, metadata.Counter, metadata.Count, osNetBondErrorsDesc)
-		Add(&md, osNetBondErrors, nicStats.OutboundPacketErrors, tagsOut, metadata.Counter, metadata.Count, osNetBondErrorsDesc)
-	}
-	return md, nil
-}
-
-const (
-	descWinNetTeamlinkspeed                = "The link speed of the adapter in bits per second."
-	descWinNetTeamReceivedBytes            = "The number of bytes of data received without errors through this interface. This value includes bytes in unicast, broadcast, and multicast packets."
-	descWinNetTeamReceivedUnicastPackets   = "The number of unicast packets received without errors through this interface."
-	descWinNetTeamReceivedMulticastPackets = "The number of multicast packets received without errors through this interface."
-	descWinNetTeamReceivedBroadcastPackets = "The number of broadcast packets received without errors through this interface."
-	descWinNetTeamReceivedUnicastBytes     = "The number of unicast bytes received without errors through this interface."
-	descWinNetTeamReceivedMulticastBytes   = "The number of multicast bytes received without errors through this interface."
-	descWinNetTeamReceivedBroadcastBytes   = "The number of broadcast bytes received without errors through this interface."
-	descWinNetTeamReceivedDiscardedPackets = "The number of inbound packets which were chosen to be discarded even though no errors were detected to prevent the packets from being deliverable to a higher-layer protocol."
-	descWinNetTeamReceivedPacketErrors     = "The number of incoming packets that were discarded because of errors."
-	descWinNetTeamSentBytes                = "The number of bytes of data transmitted without errors through this interface. This value includes bytes in unicast, broadcast, and multicast packets."
-	descWinNetTeamSentUnicastPackets       = "The number of unicast packets transmitted without errors through this interface."
-	descWinNetTeamSentMulticastPackets     = "The number of multicast packets transmitted without errors through this interface."
-	descWinNetTeamSentBroadcastPackets     = "The number of broadcast packets transmitted without errors through this interface."
-	descWinNetTeamSentUnicastBytes         = "The number of unicast bytes transmitted without errors through this interface."
-	descWinNetTeamSentMulticastBytes       = "The number of multicast bytes transmitted without errors through this interface."
-	descWinNetTeamSentBroadcastBytes       = "The number of broadcast bytes transmitted without errors through this interface."
-	descWinNetTeamOutboundDiscardedPackets = "The number of outgoing packets that were discarded even though they did not have errors."
-	descWinNetTeamOutboundPacketErrors     = "The number of outgoing packets that were discarded because of errors."
-)
-
-type MSFT_NetLbfoTeamNic struct {
-	Team                 string
-	Name                 string
-	ReceiveLinkSpeed     uint64
-	Transmitlinkspeed    uint64
-	InterfaceDescription string
-}
-
-type MSFT_NetAdapterStatisticsSettingData struct {
-	InstanceID               string
-	Name                     string
-	InterfaceDescription     string
-	ReceivedBytes            uint64
-	ReceivedUnicastPackets   uint64
-	ReceivedMulticastPackets uint64
-	ReceivedBroadcastPackets uint64
-	ReceivedUnicastBytes     uint64
-	ReceivedMulticastBytes   uint64
-	ReceivedBroadcastBytes   uint64
-	ReceivedDiscardedPackets uint64
-	ReceivedPacketErrors     uint64
-	SentBytes                uint64
-	SentUnicastPackets       uint64
-	SentMulticastPackets     uint64
-	SentBroadcastPackets     uint64
-	SentUnicastBytes         uint64
-	SentMulticastBytes       uint64
-	SentBroadcastBytes       uint64
-	OutboundDiscardedPackets uint64
-	OutboundPacketErrors     uint64
-}
-
-var (
-	winNetTCPSegmentsLastCount           uint32
-	winNetTCPSegmentsLastRetransmitCount uint32
-)
-
-func c_network_windows_tcp() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_PerfRawData_Tcpip_TCPv4
-	err := queryWmi(winNetTCPQuery, &dst)
-	if err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		Add(&md, "win.net.tcp.failures", v.ConnectionFailures, nil, metadata.Gauge, metadata.Connection, descWinNetTCPv4ConnectionFailures)
-		Add(&md, "win.net.tcp.active", v.ConnectionsActive, nil, metadata.Gauge, metadata.Connection, descWinNetTCPv4ConnectionsActive)
-		Add(&md, "win.net.tcp.established", v.ConnectionsEstablished, nil, metadata.Gauge, metadata.Connection, descWinNetTCPv4ConnectionsEstablished)
-		Add(&md, "win.net.tcp.passive", v.ConnectionsPassive, nil, metadata.Gauge, metadata.Connection, descWinNetTCPv4ConnectionsPassive)
-		Add(&md, "win.net.tcp.reset", v.ConnectionsReset, nil, metadata.Gauge, metadata.Connection, descWinNetTCPv4ConnectionsReset)
-		Add(&md, "win.net.tcp.segments", v.SegmentsReceivedPersec, opentsdb.TagSet{"type": "received"}, metadata.Counter, metadata.PerSecond, descWinNetTCPv4SegmentsReceivedPersec)
-		Add(&md, "win.net.tcp.segments", v.SegmentsRetransmittedPersec, opentsdb.TagSet{"type": "retransmitted"}, metadata.Counter, metadata.PerSecond, descWinNetTCPv4SegmentsRetransmittedPersec)
-		Add(&md, "win.net.tcp.segments", v.SegmentsSentPersec, opentsdb.TagSet{"type": "sent"}, metadata.Counter, metadata.PerSecond, descWinNetTCPv4SegmentsSentPersec)
-		if winNetTCPSegmentsLastCount != 0 &&
-			(v.SegmentsPersec-winNetTCPSegmentsLastCount) != 0 &&
-			(v.SegmentsRetransmittedPersec > winNetTCPSegmentsLastRetransmitCount) &&
-			(v.SegmentsPersec > winNetTCPSegmentsLastCount) {
-			val := float64(v.SegmentsRetransmittedPersec-winNetTCPSegmentsLastRetransmitCount) / float64(v.SegmentsPersec-winNetTCPSegmentsLastCount) * 100
-			Add(&md, "win.net.tcp.retransmit_pct", val, nil, metadata.Gauge, metadata.Pct, descWinNetTCPv4SegmentsRetransmit)
-		}
-		winNetTCPSegmentsLastRetransmitCount = v.SegmentsRetransmittedPersec
-		winNetTCPSegmentsLastCount = v.SegmentsPersec
-	}
-	return md, nil
-}
-
-const (
-	descWinNetTCPv4ConnectionFailures          = "Connection Failures is the number of times TCP connections have made a direct transition to the CLOSED state from the SYN-SENT state or the SYN-RCVD state, plus the number of times TCP connections have made a direct transition to the LISTEN state from the SYN-RCVD state."
-	descWinNetTCPv4ConnectionsActive           = "Connections Active is the number of times TCP connections have made a direct transition to the SYN-SENT state from the CLOSED state. In other words, it shows a number of connections which are initiated by the local computer. The value is a cumulative total."
-	descWinNetTCPv4ConnectionsEstablished      = "Connections Established is the number of TCP connections for which the current state is either ESTABLISHED or CLOSE-WAIT."
-	descWinNetTCPv4ConnectionsPassive          = "Connections Passive is the number of times TCP connections have made a direct transition to the SYN-RCVD state from the LISTEN state. In other words, it shows a number of connections to the local computer, which are initiated by remote computers. The value is a cumulative total."
-	descWinNetTCPv4ConnectionsReset            = "Connections Reset is the number of times TCP connections have made a direct transition to the CLOSED state from either the ESTABLISHED state or the CLOSE-WAIT state."
-	descWinNetTCPv4SegmentsReceivedPersec      = "Segments Received/sec is the rate at which segments are received, including those received in error.  This count includes segments received on currently established connections."
-	descWinNetTCPv4SegmentsRetransmittedPersec = "Segments Retransmitted/sec is the rate at which segments are retransmitted, that is, segments transmitted containing one or more previously transmitted bytes."
-	descWinNetTCPv4SegmentsSentPersec          = "Segments Sent/sec is the rate at which segments are sent, including those on current connections, but excluding those containing only retransmitted bytes."
-	descWinNetTCPv4SegmentsRetransmit          = "Segments Retransmitted / (Segments Sent + Segments Received). Usually expected to be less than 0.1 - 0.01 percent, and anything above 1 percent is an indicator of a poor connection."
-)
-
-type Win32_PerfRawData_Tcpip_TCPv4 struct {
-	ConnectionFailures          uint32
-	ConnectionsActive           uint32
-	ConnectionsEstablished      uint32
-	ConnectionsPassive          uint32
-	ConnectionsReset            uint32
-	SegmentsPersec              uint32
-	SegmentsReceivedPersec      uint32
-	SegmentsRetransmittedPersec uint32
-	SegmentsSentPersec          uint32
-}
diff --git a/cmd/scollector/collectors/ntp_unix.go b/cmd/scollector/collectors/ntp_unix.go
deleted file mode 100644
index a40d0e5..0000000
--- a/cmd/scollector/collectors/ntp_unix.go
+++ /dev/null
@@ -1,96 +0,0 @@
-// +build !windows
-
-package collectors
-
-import (
-	"fmt"
-	"strconv"
-	"strings"
-
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-	"bosun.org/util"
-)
-
-func init() {
-	collectors = append(collectors, &IntervalCollector{F: c_ntp_peers_unix})
-}
-
-var ntpNtpqPeerFields = []string{
-	"remote",
-	"refid",
-	"st",
-	"t",
-	"when",
-	"poll",
-	"reach",
-	"delay",
-	"offset",
-	"jitter",
-}
-
-// ntUnPretty reverses human formating for poll and when, see prettyinterval in ntpq/ntpq-subs.c
-func ntpUnPretty(s string) (int64, error) {
-	if len(s) < 1 {
-		return 0, fmt.Errorf("Zero length string passed to ntpUnPretty")
-	}
-	var multiplier int64 = 1
-	shift := 1
-	switch s[len(s)-1] {
-	case 'm':
-		multiplier = 60
-	case 'h':
-		multiplier = 60 * 60
-	case 'd':
-		multiplier = 60 * 60 * 24
-	default:
-		shift = 0
-	}
-	i, err := strconv.ParseInt(s[0:len(s)-shift], 10, 64)
-	return i * multiplier, err
-}
-
-func c_ntp_peers_unix() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	const metric = "ntp."
-	_ = util.ReadCommand(func(line string) error {
-		fields := strings.Fields(line)
-		if len(fields) != len(ntpNtpqPeerFields) || fields[0] == "remote" {
-			return nil
-		}
-		r := []rune(line)
-		if len(r) < 2 {
-			return fmt.Errorf("unexpected length of line")
-		}
-		fl := string(r[0])
-		rest := string(r[1:])
-		fields = strings.Fields(rest)
-		if len(fields) != len(ntpNtpqPeerFields) {
-			return fmt.Errorf("unexpected length of fields")
-		}
-		remote := fields[0]
-		tags := opentsdb.TagSet{"remote": remote, "refid": fields[1]}
-		var current_source int
-		if fl == "*" {
-			current_source = 1
-		}
-		Add(&md, metric+"current_source", current_source, tags, metadata.Gauge, metadata.Bool, "")
-		Add(&md, metric+"stratum", fields[2], tags, metadata.Gauge, "Stratum", "")
-		when, err := ntpUnPretty(fields[4])
-		if err != nil {
-			return err
-		}
-		Add(&md, metric+"when", when, tags, metadata.Gauge, metadata.Second, "")
-		poll, err := ntpUnPretty(fields[5])
-		if err != nil {
-			return err
-		}
-		Add(&md, metric+"poll", poll, tags, metadata.Gauge, metadata.Second, "")
-		Add(&md, metric+"reach", fields[6], tags, metadata.Gauge, "Code", "")
-		Add(&md, metric+"delay", fields[7], tags, metadata.Gauge, metadata.MilliSecond, "")
-		Add(&md, metric+"offset", fields[8], tags, metadata.Gauge, metadata.MilliSecond, "")
-		Add(&md, metric+"jitter", fields[9], tags, metadata.Gauge, metadata.MilliSecond, "")
-		return nil
-	}, "ntpq", "-pn")
-	return md, nil
-}
diff --git a/cmd/scollector/collectors/opentsdb.go b/cmd/scollector/collectors/opentsdb.go
deleted file mode 100644
index 640ac79..0000000
--- a/cmd/scollector/collectors/opentsdb.go
+++ /dev/null
@@ -1,32 +0,0 @@
-package collectors
-
-import (
-	"encoding/json"
-	"net/http"
-
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-)
-
-func init() {
-	collectors = append(collectors, &IntervalCollector{F: c_opentsdb, Enable: enableURL(tsdbURL)})
-}
-
-const tsdbURL = "http://localhost:4242/api/stats"
-
-func c_opentsdb() (opentsdb.MultiDataPoint, error) {
-	resp, err := http.Get(tsdbURL)
-	if err != nil {
-		return nil, err
-	}
-	defer resp.Body.Close()
-	var md, tmp opentsdb.MultiDataPoint
-	if err := json.NewDecoder(resp.Body).Decode(&tmp); err != nil {
-		return nil, err
-	}
-	for _, v := range tmp {
-		delete(v.Tags, "host")
-		AddTS(&md, v.Metric, v.Timestamp, v.Value, v.Tags, metadata.Unknown, metadata.None, "")
-	}
-	return md, nil
-}
diff --git a/cmd/scollector/collectors/processes_darwin.go b/cmd/scollector/collectors/processes_darwin.go
deleted file mode 100644
index 51bbc06..0000000
--- a/cmd/scollector/collectors/processes_darwin.go
+++ /dev/null
@@ -1,12 +0,0 @@
-package collectors
-
-import "fmt"
-
-func AddProcessConfig(params ProcessParams) error {
-	return fmt.Errorf("process watching not implemented on Darwin")
-}
-
-type ProcessParams struct{}
-
-func WatchProcesses() {
-}
diff --git a/cmd/scollector/collectors/processes_linux.go b/cmd/scollector/collectors/processes_linux.go
index 6cd092f..4015419 100644
--- a/cmd/scollector/collectors/processes_linux.go
+++ b/cmd/scollector/collectors/processes_linux.go
@@ -39,6 +39,11 @@ func WatchProcesses() {
 func linuxProcMonitor(w *WatchedProc, md *opentsdb.MultiDataPoint) error {
 	var err error
 	for pid, id := range w.Processes {
+		file_status, e := os.Stat("/proc/" + pid)
+		if e != nil {
+			w.Remove(pid)
+			continue
+		}
 		stats_file, e := ioutil.ReadFile("/proc/" + pid + "/stat")
 		if e != nil {
 			w.Remove(pid)
@@ -91,6 +96,7 @@ func linuxProcMonitor(w *WatchedProc, md *opentsdb.MultiDataPoint) error {
 				}
 			}
 		}
+		start_ts := file_status.ModTime().Unix()
 		Add(md, "linux.proc.cpu", stats[13], opentsdb.TagSet{"type": "user"}.Merge(tags), metadata.Counter, metadata.Pct, descLinuxProcCPUUser)
 		Add(md, "linux.proc.cpu", stats[14], opentsdb.TagSet{"type": "system"}.Merge(tags), metadata.Counter, metadata.Pct, descLinuxProcCPUSystem)
 		Add(md, "linux.proc.mem.fault", stats[9], opentsdb.TagSet{"type": "minflt"}.Merge(tags), metadata.Counter, metadata.Fault, descLinuxProcMemFaultMin)
@@ -104,6 +110,8 @@ func linuxProcMonitor(w *WatchedProc, md *opentsdb.MultiDataPoint) error {
 		Add(md, "linux.proc.io_bytes", io[4], opentsdb.TagSet{"type": "read"}.Merge(tags), metadata.Counter, metadata.Bytes, descLinuxProcIoBytesRead)
 		Add(md, "linux.proc.io_bytes", io[5], opentsdb.TagSet{"type": "write"}.Merge(tags), metadata.Counter, metadata.Bytes, descLinuxProcIoBytesWrite)
 		Add(md, "linux.proc.num_fds", len(fds), tags, metadata.Gauge, metadata.Files, descLinuxProcFd)
+		Add(md, "linux.proc.start_time", start_ts, tags, metadata.Gauge, metadata.Timestamp, descLinuxProcStartTS)
+		Add(md, "linux.proc.uptime", now()-start_ts, tags, metadata.Gauge, metadata.Second, descLinuxProcUptime)
 	}
 	return err
 }
@@ -124,6 +132,8 @@ const (
 	descLinuxProcFd           = "The number of open file descriptors."
 	descLinuxSoftFileLimit    = "The soft limit on the number of open file descriptors."
 	descLinuxHardFileLimit    = "The hard limit on the number of open file descriptors."
+	descLinuxProcUptime       = "The length of time, in seconds, since the process was started."
+	descLinuxProcStartTS      = "The timestamp of process start."
 )
 
 func getLinuxProccesses() ([]*Process, error) {
diff --git a/cmd/scollector/collectors/processes_solaris.go b/cmd/scollector/collectors/processes_solaris.go
deleted file mode 100644
index 1b4fa0b..0000000
--- a/cmd/scollector/collectors/processes_solaris.go
+++ /dev/null
@@ -1,14 +0,0 @@
-package collectors
-
-import (
-	"fmt"
-	"runtime"
-)
-
-func AddProcessConfig(params ProcessParams) error {
-	return fmt.Errorf("process monitoring not supported on %s-%s", runtime.GOOS, runtime.GOARCH)
-}
-
-type ProcessParams struct{}
-
-func WatchProcesses() {}
diff --git a/cmd/scollector/collectors/processes_windows.go b/cmd/scollector/collectors/processes_windows.go
deleted file mode 100644
index 70aa0ef..0000000
--- a/cmd/scollector/collectors/processes_windows.go
+++ /dev/null
@@ -1,275 +0,0 @@
-package collectors
-
-import (
-	"fmt"
-	"regexp"
-	"strings"
-
-	"bosun.org/_third_party/github.com/StackExchange/wmi"
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-)
-
-var regexesProcesses = []*regexp.Regexp{}
-
-func AddProcessConfig(params ProcessParams) error {
-	if params.Name == "" {
-		return fmt.Errorf("empty process Name")
-	}
-	reg, err := regexp.Compile(params.Name)
-	if err != nil {
-		return err
-	}
-	regexesProcesses = append(regexesProcesses, reg)
-	return nil
-}
-
-type ProcessParams struct {
-	Name string
-}
-
-func WatchProcesses() {
-	if len(regexesProcesses) == 0 {
-		// if no process settings configured in config file, use this set instead.
-		regexesProcesses = append(regexesProcesses, regexp.MustCompile("chrome|powershell|scollector|WinRM|MSSQLSERVER"))
-	}
-	collectors = append(collectors, &IntervalCollector{
-		F: c_windows_processes,
-	})
-}
-
-func c_windows_processes() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_PerfRawData_PerfProc_Process
-	var q = wmi.CreateQuery(&dst, `WHERE Name <> '_Total'`)
-	err := queryWmi(q, &dst)
-	if err != nil {
-		return nil, err
-	}
-
-	var svc_dst []Win32_Service
-	var svc_q = wmi.CreateQuery(&svc_dst, "")
-	err = queryWmi(svc_q, &svc_dst)
-	if err != nil {
-		return nil, err
-	}
-
-	var iis_dst []WorkerProcess
-	iis_q := wmi.CreateQuery(&iis_dst, "")
-	err = queryWmiNamespace(iis_q, &iis_dst, "root\\WebAdministration")
-	if err != nil {
-		// Don't return from this error since the name space might exist.
-		iis_dst = nil
-	}
-
-	var numberOfLogicalProcessors uint64
-	var core_dst []Win32_ComputerSystem
-	var core_q = wmi.CreateQuery(&core_dst, "")
-	err = queryWmi(core_q, &core_dst)
-	if err != nil {
-		return nil, err
-	}
-	for _, y := range core_dst {
-		numberOfLogicalProcessors = uint64(y.NumberOfLogicalProcessors)
-	}
-	if numberOfLogicalProcessors == 0 {
-		return nil, fmt.Errorf("invalid result: numberOfLogicalProcessors=%v", numberOfLogicalProcessors)
-	}
-
-	var md opentsdb.MultiDataPoint
-	var svc_dst_started []Win32_Service
-	for _, svc := range svc_dst {
-		if nameMatches(svc.Name, regexesProcesses) {
-			if svc.Started {
-				svc_dst_started = append(svc_dst_started, svc)
-			}
-			tags := opentsdb.TagSet{"name": svc.Name}
-			Add(&md, "win.service.started", btoi(svc.Started), tags, metadata.Gauge, metadata.Bool, descWinServiceStatus)
-			Add(&md, "win.service.status", btoi(svc.Status != "OK"), tags, metadata.Gauge, metadata.Ok, descWinServiceStatus)
-			Add(&md, "win.service.checkpoint", svc.CheckPoint, tags, metadata.Gauge, metadata.None, descWinServiceCheckPoint)
-			Add(&md, "win.service.wait_hint", svc.WaitHint, tags, metadata.Gauge, metadata.MilliSecond, descWinServiceWaitHint)
-		}
-	}
-
-	for _, v := range dst {
-		var name string
-		service_match := false
-		iis_match := false
-
-		process_match := nameMatches(v.Name, regexesProcesses)
-
-		id := "0"
-
-		if process_match {
-			raw_name := strings.Split(v.Name, "#")
-			name = raw_name[0]
-			if len(raw_name) == 2 {
-				id = raw_name[1]
-			}
-			// If you have a hash sign in your process name you don't deserve monitoring ;-)
-			if len(raw_name) > 2 {
-				continue
-			}
-		}
-
-		// A Service match could "overwrite" a process match, but that is probably what we would want
-		for _, svc := range svc_dst_started {
-			// It is possible the pid has gone and been reused, but I think this unlikely
-			// And I'm not aware of an atomic join we could do anyways
-			if svc.ProcessId != 0 && svc.ProcessId == v.IDProcess {
-				id = "0"
-				service_match = true
-				name = svc.Name
-				break
-			}
-		}
-
-		for _, a_pool := range iis_dst {
-			if a_pool.ProcessId == v.IDProcess {
-				id = "0"
-				iis_match = true
-				name = strings.Join([]string{"iis", a_pool.AppPoolName}, "_")
-				break
-			}
-		}
-
-		if !(service_match || process_match || iis_match) {
-			continue
-		}
-
-		//Use timestamp from WMI to fix issues with CPU metrics
-		ts := TSys100NStoEpoch(v.Timestamp_Sys100NS)
-		tags := opentsdb.TagSet{"name": name, "id": id}
-		AddTS(&md, "win.proc.cpu", ts, v.PercentPrivilegedTime/NS100_Seconds/numberOfLogicalProcessors, opentsdb.TagSet{"type": "privileged"}.Merge(tags), metadata.Counter, metadata.Pct, descWinProcCPU_priv)
-		AddTS(&md, "win.proc.cpu", ts, v.PercentUserTime/NS100_Seconds/numberOfLogicalProcessors, opentsdb.TagSet{"type": "user"}.Merge(tags), metadata.Counter, metadata.Pct, descWinProcCPU_user)
-		AddTS(&md, "win.proc.cpu_total", ts, v.PercentProcessorTime/NS100_Seconds/numberOfLogicalProcessors, tags, metadata.Counter, metadata.Pct, descWinProcCPU_total)
-		Add(&md, "win.proc.elapsed_time", (v.Timestamp_Object-v.ElapsedTime)/v.Frequency_Object, tags, metadata.Gauge, metadata.Second, descWinProcElapsed_time)
-		Add(&md, "win.proc.handle_count", v.HandleCount, tags, metadata.Gauge, metadata.Count, descWinProcHandle_count)
-		Add(&md, "win.proc.io_bytes", v.IOOtherBytesPersec, opentsdb.TagSet{"type": "other"}.Merge(tags), metadata.Counter, metadata.BytesPerSecond, descWinProcIo_bytes_other)
-		Add(&md, "win.proc.io_bytes", v.IOReadBytesPersec, opentsdb.TagSet{"type": "read"}.Merge(tags), metadata.Counter, metadata.BytesPerSecond, descWinProcIo_bytes_read)
-		Add(&md, "win.proc.io_bytes", v.IOWriteBytesPersec, opentsdb.TagSet{"type": "write"}.Merge(tags), metadata.Counter, metadata.BytesPerSecond, descWinProcIo_bytes_write)
-		Add(&md, "win.proc.io_operations", v.IOOtherOperationsPersec, opentsdb.TagSet{"type": "other"}.Merge(tags), metadata.Counter, metadata.Operation, descWinProcIo_operations)
-		Add(&md, "win.proc.io_operations", v.IOReadOperationsPersec, opentsdb.TagSet{"type": "read"}.Merge(tags), metadata.Counter, metadata.Operation, descWinProcIo_operations_read)
-		Add(&md, "win.proc.io_operations", v.IOWriteOperationsPersec, opentsdb.TagSet{"type": "write"}.Merge(tags), metadata.Counter, metadata.Operation, descWinProcIo_operations_write)
-		Add(&md, "win.proc.mem.page_faults", v.PageFaultsPersec, tags, metadata.Counter, metadata.PerSecond, descWinProcMemPage_faults)
-		Add(&md, "win.proc.mem.pagefile_bytes", v.PageFileBytes, tags, metadata.Gauge, metadata.Bytes, descWinProcMemPagefile_bytes)
-		Add(&md, "win.proc.mem.pagefile_bytes_peak", v.PageFileBytesPeak, tags, metadata.Gauge, metadata.Bytes, descWinProcMemPagefile_bytes_peak)
-		Add(&md, "win.proc.mem.pool_nonpaged_bytes", v.PoolNonpagedBytes, tags, metadata.Gauge, metadata.Bytes, descWinProcMemPool_nonpaged_bytes)
-		Add(&md, "win.proc.mem.pool_paged_bytes", v.PoolPagedBytes, tags, metadata.Gauge, metadata.Bytes, descWinProcMemPool_paged_bytes)
-		Add(&md, "win.proc.mem.vm.bytes", v.VirtualBytes, tags, metadata.Gauge, metadata.Bytes, descWinProcMemVmBytes)
-		Add(&md, "win.proc.mem.vm.bytes_peak", v.VirtualBytesPeak, tags, metadata.Gauge, metadata.Bytes, descWinProcMemVmBytes_peak)
-		Add(&md, "win.proc.mem.working_set", v.WorkingSet, tags, metadata.Gauge, metadata.Bytes, descWinProcMemWorking_set)
-		Add(&md, "win.proc.mem.working_set_peak", v.WorkingSetPeak, tags, metadata.Gauge, metadata.Bytes, descWinProcMemWorking_set_peak)
-		Add(&md, "win.proc.mem.working_set_private", v.WorkingSetPrivate, tags, metadata.Gauge, metadata.Bytes, descWinProcMemWorking_set_private)
-		Add(&md, "win.proc.priority_base", v.PriorityBase, tags, metadata.Gauge, metadata.None, descWinProcPriority_base)
-		Add(&md, "win.proc.private_bytes", v.PrivateBytes, tags, metadata.Gauge, metadata.Bytes, descWinProcPrivate_bytes)
-		Add(&md, "win.proc.thread_count", v.ThreadCount, tags, metadata.Gauge, metadata.Count, descWinProcthread_count)
-	}
-	return md, nil
-}
-
-func nameMatches(name string, regexes []*regexp.Regexp) bool {
-	for _, r := range regexes {
-		if r.MatchString(name) {
-			return true
-		}
-	}
-	return false
-}
-
-func btoi(b bool) int {
-	if b {
-		return 1
-	}
-	return 0
-}
-
-// Divide CPU by 1e5 because: 1 seconds / 100 Nanoseconds = 1e7. This is the
-// percent time as a decimal, so divide by two less zeros to make it the same as
-// the result * 100.
-const NS100_Seconds = 1e5
-
-const (
-	descWinProcCPU_priv               = "Percentage of elapsed time that this thread has spent executing code in privileged mode."
-	descWinProcCPU_total              = "Percentage of elapsed time that this process's threads have spent executing code in user or privileged mode."
-	descWinProcCPU_user               = "Percentage of elapsed time that this process's threads have spent executing code in user mode."
-	descWinProcElapsed_time           = "Elapsed time in seconds this process has been running."
-	descWinProcHandle_count           = "Total number of handles the process has open across all threads."
-	descWinProcIo_bytes_other         = "Rate at which the process is issuing bytes to I/O operations that do not involve data such as control operations."
-	descWinProcIo_bytes_read          = "Rate at which the process is reading bytes from I/O operations."
-	descWinProcIo_bytes_write         = "Rate at which the process is writing bytes to I/O operations."
-	descWinProcIo_operations          = "Rate at which the process is issuing I/O operations that are neither a read or a write request."
-	descWinProcIo_operations_read     = "Rate at which the process is issuing read I/O operations."
-	descWinProcIo_operations_write    = "Rate at which the process is issuing write I/O operations."
-	descWinProcMemPage_faults         = "Rate of page faults by the threads executing in this process."
-	descWinProcMemPagefile_bytes      = "Current number of bytes this process has used in the paging file(s)."
-	descWinProcMemPagefile_bytes_peak = "Maximum number of bytes this process has used in the paging file(s)."
-	descWinProcMemPool_nonpaged_bytes = "Total number of bytes for objects that cannot be written to disk when they are not being used."
-	descWinProcMemPool_paged_bytes    = "Total number of bytes for objects that can be written to disk when they are not being used."
-	descWinProcMemVmBytes             = "Current size, in bytes, of the virtual address space that the process is using."
-	descWinProcMemVmBytes_peak        = "Maximum number of bytes of virtual address space that the process has used at any one time."
-	descWinProcMemWorking_set         = "Current number of bytes in the working set of this process at any point in time."
-	descWinProcMemWorking_set_peak    = "Maximum number of bytes in the working set of this process at any point in time."
-	descWinProcMemWorking_set_private = "Current number of bytes in the working set that are not shared with other processes."
-	descWinProcPriority_base          = "Current base priority of this process. Threads within a process can raise and lower their own base priority relative to the process base priority of the process."
-	descWinProcPrivate_bytes          = "Current number of bytes this process has allocated that cannot be shared with other processes."
-	descWinProcthread_count           = "Number of threads currently active in this process."
-)
-
-// Actually a CIM_StatisticalInformation.
-type Win32_PerfRawData_PerfProc_Process struct {
-	ElapsedTime             uint64
-	Frequency_Object        uint64
-	HandleCount             uint32
-	IDProcess               uint32
-	IOOtherBytesPersec      uint64
-	IOOtherOperationsPersec uint64
-	IOReadBytesPersec       uint64
-	IOReadOperationsPersec  uint64
-	IOWriteBytesPersec      uint64
-	IOWriteOperationsPersec uint64
-	Name                    string
-	PageFaultsPersec        uint32
-	PageFileBytes           uint64
-	PageFileBytesPeak       uint64
-	PercentPrivilegedTime   uint64
-	PercentProcessorTime    uint64
-	PercentUserTime         uint64
-	PoolNonpagedBytes       uint32
-	PoolPagedBytes          uint32
-	PriorityBase            uint32
-	PrivateBytes            uint64
-	ThreadCount             uint32
-	Timestamp_Object        uint64
-	Timestamp_Sys100NS      uint64
-	VirtualBytes            uint64
-	VirtualBytesPeak        uint64
-	WorkingSet              uint64
-	WorkingSetPeak          uint64
-	WorkingSetPrivate       uint64
-}
-
-const (
-	descWinServiceCheckPoint = "The CheckPoint property specifies a value that the service increments periodically to report its progress during a lengthy start, stop, pause, or continue operation. For example, the service should increment this value as it completes each step of its initialization when it is starting up. The user interface program that invoked the operation on the service uses this value to track the progress of the service during a lengthy operation. This value is not valid and should be zero when the service does not have a start, stop, pause, or continue operation pending."
-	descWinServiceStarted    = "Started is a boolean indicating whether the service has been started (TRUE), or stopped (FALSE)."
-	descWinServiceStatus     = "The Status property indicates the current status of the object. Right now 0=OK and 1=Not OK, but various operational and non-operational statuses can be defined such as OK, Degraded,  Pred Fail, Error, Starting, Stopping, and Service."
-	descWinServiceWaitHint   = "The WaitHint property specifies the estimated time required (in milliseconds) for a pending start, stop, pause, or continue operation. After the specified amount of time has elapsed, the service makes its next call to the SetServiceStatus function with either an incremented CheckPoint value or a change in Current State. If the amount of time specified by WaitHint passes, and CheckPoint has not been incremented, or the Current State has not changed, the service control manager or service control program assumes that an error has occurred."
-)
-
-// Actually a Win32_BaseServce.
-type Win32_Service struct {
-	CheckPoint uint32
-	Name       string
-	ProcessId  uint32
-	Started    bool
-	Status     string
-	WaitHint   uint32
-}
-
-type WorkerProcess struct {
-	AppPoolName string
-	ProcessId   uint32
-}
-
-type Win32_ComputerSystem struct {
-	NumberOfLogicalProcessors uint32
-}
diff --git a/cmd/scollector/collectors/procstats_linux.go b/cmd/scollector/collectors/procstats_linux.go
index 14e1fe0..54a1125 100644
--- a/cmd/scollector/collectors/procstats_linux.go
+++ b/cmd/scollector/collectors/procstats_linux.go
@@ -250,103 +250,103 @@ func c_procstats_linux() (opentsdb.MultiDataPoint, error) {
 	}); err != nil {
 		Error = err
 	}
-	if err := readLine("/proc/net/sockstat", func(s string) error {
-		cols := strings.Fields(s)
-		switch cols[0] {
-		case "sockets:":
-			if len(cols) < 3 {
-				return fmt.Errorf("sockstat: error parsing sockets line")
-			}
-			Add(&md, "linux.net.sockets.used", cols[2], nil, metadata.Gauge, metadata.Socket, "")
-		case "TCP:":
-			if len(cols) < 11 {
-				return fmt.Errorf("sockstat: error parsing tcp line")
-			}
-			Add(&md, "linux.net.sockets.tcp_in_use", cols[2], nil, metadata.Gauge, metadata.Socket, "")
-			Add(&md, "linux.net.sockets.tcp_orphaned", cols[4], nil, metadata.Gauge, metadata.Socket, "")
-			Add(&md, "linux.net.sockets.tcp_time_wait", cols[6], nil, metadata.Gauge, metadata.Socket, "")
-			Add(&md, "linux.net.sockets.tcp_allocated", cols[8], nil, metadata.Gauge, metadata.None, "")
-			Add(&md, "linux.net.sockets.tcp_mem", cols[10], nil, metadata.Gauge, metadata.None, "")
-		case "UDP:":
-			if len(cols) < 5 {
-				return fmt.Errorf("sockstat: error parsing udp line")
-			}
-			Add(&md, "linux.net.sockets.udp_in_use", cols[2], nil, metadata.Gauge, metadata.Socket, "")
-			Add(&md, "linux.net.sockets.udp_mem", cols[4], nil, metadata.Gauge, metadata.Page, "")
-		case "UDPLITE:":
-			if len(cols) < 3 {
-				return fmt.Errorf("sockstat: error parsing udplite line")
-			}
-			Add(&md, "linux.net.sockets.udplite_in_use", cols[2], nil, metadata.Gauge, metadata.Socket, "")
-		case "RAW:":
-			if len(cols) < 3 {
-				return fmt.Errorf("sockstat: error parsing raw line")
-			}
-			Add(&md, "linux.net.sockets.raw_in_use", cols[2], nil, metadata.Gauge, metadata.Socket, "")
-		case "FRAG:":
-			if len(cols) < 5 {
-				return fmt.Errorf("sockstat: error parsing frag line")
-			}
-			Add(&md, "linux.net.sockets.frag_in_use", cols[2], nil, metadata.Gauge, metadata.Socket, "")
-			Add(&md, "linux.net.sockets.frag_mem", cols[4], nil, metadata.Gauge, metadata.Bytes, "")
-		}
-		return nil
-	}); err != nil {
-		Error = err
-	}
-	ln := 0
-	var headers []string
-	if err := readLine("/proc/net/netstat", func(s string) error {
-		cols := strings.Fields(s)
-		if ln%2 == 0 {
-			headers = cols
-		} else {
-			if len(cols) < 1 || len(cols) != len(headers) {
-				return fmt.Errorf("netstat: parsing failed")
-			}
-			root := strings.ToLower(strings.TrimSuffix(headers[0], "Ext:"))
-			for i, v := range cols[1:] {
-				i++
-				m := "linux.net.stat." + root + "." + strings.TrimPrefix(strings.ToLower(headers[i]), "tcp")
-				Add(&md, m, v, nil, metadata.Counter, metadata.None, "")
-			}
-		}
-		ln += 1
-		return nil
-	}); err != nil {
-		Error = err
-	}
-	ln = 0
-	if err := readLine("/proc/net/snmp", func(s string) error {
-		ln++
-		if ln%2 != 0 {
-			f := strings.Fields(s)
-			if len(f) < 2 {
-				return fmt.Errorf("Failed to parse header line")
-			}
-			headers = f
-		} else {
-			values := strings.Fields(s)
-			if len(values) != len(headers) {
-				return fmt.Errorf("Mismatched header and value length")
-			}
-			proto := strings.ToLower(strings.TrimSuffix(values[0], ":"))
-			for i, v := range values {
-				if i == 0 {
-					continue
-				}
-				var stype metadata.RateType = metadata.Counter
-				stat := strings.ToLower(headers[i])
-				if strings.HasPrefix(stat, "rto") {
-					stype = metadata.Gauge
-				}
-				Add(&md, "linux.net.stat."+proto+"."+stat, v, nil, stype, metadata.None, "")
-			}
-		}
-		return nil
-	}); err != nil {
-		Error = err
-	}
+//	if err := readLine("/proc/net/sockstat", func(s string) error {
+//		cols := strings.Fields(s)
+//		switch cols[0] {
+//		case "sockets:":
+//			if len(cols) < 3 {
+//				return fmt.Errorf("sockstat: error parsing sockets line")
+//			}
+//			Add(&md, "linux.net.sockets.used", cols[2], nil, metadata.Gauge, metadata.Socket, "")
+//		case "TCP:":
+//			if len(cols) < 11 {
+//				return fmt.Errorf("sockstat: error parsing tcp line")
+//			}
+//			Add(&md, "linux.net.sockets.tcp_in_use", cols[2], nil, metadata.Gauge, metadata.Socket, "")
+//			Add(&md, "linux.net.sockets.tcp_orphaned", cols[4], nil, metadata.Gauge, metadata.Socket, "")
+//			Add(&md, "linux.net.sockets.tcp_time_wait", cols[6], nil, metadata.Gauge, metadata.Socket, "")
+//			Add(&md, "linux.net.sockets.tcp_allocated", cols[8], nil, metadata.Gauge, metadata.None, "")
+//			Add(&md, "linux.net.sockets.tcp_mem", cols[10], nil, metadata.Gauge, metadata.None, "")
+//		case "UDP:":
+//			if len(cols) < 5 {
+//				return fmt.Errorf("sockstat: error parsing udp line")
+//			}
+//			Add(&md, "linux.net.sockets.udp_in_use", cols[2], nil, metadata.Gauge, metadata.Socket, "")
+//			Add(&md, "linux.net.sockets.udp_mem", cols[4], nil, metadata.Gauge, metadata.Page, "")
+//		case "UDPLITE:":
+//			if len(cols) < 3 {
+//				return fmt.Errorf("sockstat: error parsing udplite line")
+//			}
+//			Add(&md, "linux.net.sockets.udplite_in_use", cols[2], nil, metadata.Gauge, metadata.Socket, "")
+//		case "RAW:":
+//			if len(cols) < 3 {
+//				return fmt.Errorf("sockstat: error parsing raw line")
+//			}
+//			Add(&md, "linux.net.sockets.raw_in_use", cols[2], nil, metadata.Gauge, metadata.Socket, "")
+//		case "FRAG:":
+//			if len(cols) < 5 {
+//				return fmt.Errorf("sockstat: error parsing frag line")
+//			}
+//			Add(&md, "linux.net.sockets.frag_in_use", cols[2], nil, metadata.Gauge, metadata.Socket, "")
+//			Add(&md, "linux.net.sockets.frag_mem", cols[4], nil, metadata.Gauge, metadata.Bytes, "")
+//		}
+//		return nil
+//	}); err != nil {
+//		Error = err
+//	}
+//	ln := 0
+//	var headers []string
+//	if err := readLine("/proc/net/netstat", func(s string) error {
+//		cols := strings.Fields(s)
+//		if ln%2 == 0 {
+//			headers = cols
+//		} else {
+//			if len(cols) < 1 || len(cols) != len(headers) {
+//				return fmt.Errorf("netstat: parsing failed")
+//			}
+//			root := strings.ToLower(strings.TrimSuffix(headers[0], "Ext:"))
+//			for i, v := range cols[1:] {
+//				i++
+//				m := "linux.net.stat." + root + "." + strings.TrimPrefix(strings.ToLower(headers[i]), "tcp")
+//				Add(&md, m, v, nil, metadata.Counter, metadata.None, "")
+//			}
+//		}
+//		ln += 1
+//		return nil
+//	}); err != nil {
+//		Error = err
+//	}
+//	ln = 0
+//	if err := readLine("/proc/net/snmp", func(s string) error {
+//		ln++
+//		if ln%2 != 0 {
+//			f := strings.Fields(s)
+//			if len(f) < 2 {
+//				return fmt.Errorf("Failed to parse header line")
+//			}
+//			headers = f
+//		} else {
+//			values := strings.Fields(s)
+//			if len(values) != len(headers) {
+//				return fmt.Errorf("Mismatched header and value length")
+//			}
+//			proto := strings.ToLower(strings.TrimSuffix(values[0], ":"))
+//			for i, v := range values {
+//				if i == 0 {
+//					continue
+//				}
+//				var stype metadata.RateType = metadata.Counter
+//				stat := strings.ToLower(headers[i])
+//				if strings.HasPrefix(stat, "rto") {
+//					stype = metadata.Gauge
+//				}
+//				Add(&md, "linux.net.stat."+proto+"."+stat, v, nil, stype, metadata.None, "")
+//			}
+//		}
+//		return nil
+//	}); err != nil {
+//		Error = err
+//	}
 	const bondingPath = "/proc/net/bonding"
 	bondDevices, _ := ioutil.ReadDir(bondingPath)
 	for _, fi := range bondDevices {
diff --git a/cmd/scollector/collectors/redis_unix.go b/cmd/scollector/collectors/redis_unix.go
deleted file mode 100644
index 20028a4..0000000
--- a/cmd/scollector/collectors/redis_unix.go
+++ /dev/null
@@ -1,287 +0,0 @@
-// +build darwin linux
-
-package collectors
-
-import (
-	"fmt"
-	"regexp"
-	"strconv"
-	"strings"
-	"time"
-
-	"bosun.org/_third_party/github.com/garyburd/redigo/redis"
-
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-	"bosun.org/util"
-)
-
-func init() {
-	collectors = append(collectors, &IntervalCollector{F: c_redis, init: redisInit})
-}
-
-var redisFields = map[string]bool{
-	"aof_enabled":                  true,
-	"aof_rewrite_in_progress":      true,
-	"aof_rewrite_scheduled":        true,
-	"aof_last_rewrite_time_sec":    true,
-	"aof_current_rewrite_time_sec": true,
-	"aof_last_bgrewrite_status":    true,
-	"bgrewriteaof_in_progress":     true,
-	"bgsave_in_progress":           true,
-	"blocked_clients":              true,
-	"changes_since_last_save":      true,
-	"client_biggest_input_buf":     true,
-	"client_longest_output_list":   true,
-	"connected_clients":            true,
-	"connected_slaves":             true,
-	"evicted_keys":                 true,
-	"expired_keys":                 true,
-	"hash_max_zipmap_entries":      true,
-	"hash_max_zipmap_value":        true,
-	"keyspace_hits":                true,
-	"keyspace_misses":              true,
-	"master_link_status":           true,
-	"master_sync_in_progress":      true,
-	"master_last_io_seconds_ago":   true,
-	"master_sync_left_bytes":       true,
-	"mem_fragmentation_ratio":      true,
-	"pubsub_channels":              true,
-	"pubsub_patterns":              true,
-	"rdb_changes_since_last_save":  true,
-	"rdb_bgsave_in_progress":       true,
-	"rdb_last_save_time":           true,
-	"rdb_last_bgsave_status":       true,
-	"rdb_last_bgsave_time_sec":     true,
-	"rdb_current_bgsave_time_sec":  true,
-	"role": true,
-	"total_commands_processed":   true,
-	"total_connections_received": true,
-	"uptime_in_seconds":          true,
-	"used_cpu_sys":               true,
-	"used_cpu_user":              true,
-	"used_memory":                true,
-	"used_memory_rss":            true,
-}
-
-// For master_link_status.
-var redisMlsMap = map[string]string{
-	"up":   "1",
-	"down": "0",
-}
-
-// For aof_last_bgrewrite_status, rdb_last_bgsave_status.
-func status(s string) string {
-	if s == "ok" {
-		return "1"
-	}
-	return "0"
-}
-
-// For role which translates to is_slave
-func slave(s string) string {
-	if s == "slave" {
-		return "1"
-	}
-	return "0"
-}
-
-var (
-	tcRE           = regexp.MustCompile(`^\s*#\s*scollector.(\w+)\s*=\s*(.+)$`)
-	redisInstances []opentsdb.TagSet
-)
-
-func redisScollectorTags(cfg string) map[string]string {
-	m := make(opentsdb.TagSet)
-	readLine(cfg, func(cfgline string) error {
-		result := tcRE.FindStringSubmatch(cfgline)
-		if len(result) == 3 {
-			m[result[1]] = result[2]
-		}
-		return nil
-	})
-	return m
-}
-
-func redisInit() {
-	update := func() {
-		var instances []opentsdb.TagSet
-		oldRedis := false
-		add := func(port string) {
-			ri := make(opentsdb.TagSet)
-			ri["port"] = port
-			instances = append(instances, ri)
-		}
-		util.ReadCommand(func(line string) error {
-			sp := strings.Fields(line)
-			if len(sp) != 3 || !strings.HasSuffix(sp[1], "redis-server") {
-				return nil
-			}
-			if !strings.Contains(sp[2], ":") {
-				oldRedis = true
-				return nil
-			}
-			port := strings.Split(sp[2], ":")[1]
-			if port != "0" {
-				add(port)
-			}
-			return nil
-		}, "ps", "-e", "-o", "pid,args")
-		if oldRedis {
-			util.ReadCommand(func(line string) error {
-				if !strings.Contains(line, "redis-server") {
-					return nil
-				}
-				sp := strings.Fields(line)
-				if len(sp) < 7 || !strings.Contains(sp[3], ":") {
-					return nil
-				}
-				port := strings.Split(sp[3], ":")[1]
-				add(port)
-				return nil
-			}, "netstat", "-tnlp")
-		}
-		redisInstances = instances
-	}
-	update()
-	go func() {
-		for range time.Tick(time.Minute * 5) {
-			update()
-		}
-	}()
-}
-
-func redisKeyCount(line string) (int64, error) {
-	err := fmt.Errorf("Error parsing keyspace line from redis info: %v", line)
-	colSplit := strings.Split(line, ":")
-	if len(colSplit) < 2 {
-		return 0, err
-	}
-	comSplit := strings.Split(colSplit[1], ",")
-	if len(comSplit) != 3 {
-		return 0, err
-	}
-	eqSplit := strings.Split(comSplit[0], "=")
-	if len(eqSplit) != 2 || eqSplit[0] != "keys" {
-		return 0, err
-	}
-	v, err := strconv.ParseInt(eqSplit[1], 10, 64)
-	if err != nil {
-		return 0, err
-	}
-	return v, nil
-}
-
-func c_redis() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	var Error error
-	for _, instance := range redisInstances {
-		c, err := redis.Dial("tcp", fmt.Sprintf(":%s", instance["port"]))
-		if err != nil {
-			Error = err
-			continue
-		}
-		defer c.Close()
-		info, err := c.Do("info", "all")
-		if err != nil {
-			Error = err
-			continue
-		}
-		tags := instance.Copy()
-		infoSplit := strings.Split(string(info.([]uint8)), "\n")
-		for _, line := range infoSplit {
-			line = strings.TrimSpace(line)
-			sp := strings.Split(line, ":")
-			if len(sp) < 2 || sp[0] != "config_file" {
-				continue
-			}
-			if sp[1] != "" {
-				m := redisScollectorTags(sp[1])
-				tags.Merge(m)
-				break
-			}
-		}
-		var keyspace bool
-		var keys int64
-		for _, line := range infoSplit {
-			line = strings.TrimSpace(line)
-			if line == "" {
-				continue
-			}
-			if line == "# Keyspace" {
-				keyspace = true
-				continue
-			}
-			if keyspace {
-				k, err := redisKeyCount(line)
-				if err != nil {
-					return nil, err
-				}
-				keys += k
-				continue
-			}
-			sp := strings.Split(line, ":")
-			if len(sp) < 2 || !(redisFields[sp[0]] || strings.HasPrefix(sp[0], "cmdstat_")) {
-				continue
-			}
-			if sp[0] == "master_link_status" {
-				Add(&md, "redis."+sp[0], redisMlsMap[sp[1]], tags, metadata.Unknown, metadata.None, "")
-				continue
-			}
-			if sp[0] == "role" {
-				Add(&md, "redis.is_slave", slave(sp[1]), tags, metadata.Gauge, metadata.Bool, "")
-				continue
-			}
-			if sp[0] == "aof_last_bgrewrite_status" || sp[0] == "rdb_last_bgsave_status" {
-				Add(&md, "redis."+sp[0], status(sp[1]), tags, metadata.Unknown, metadata.None, "")
-				continue
-			}
-			if strings.HasPrefix(sp[0], "cmdstat_") {
-				cmdStats := strings.Split(sp[1], ",")
-				if len(cmdStats) < 3 {
-					continue
-				}
-				cmdStatsCalls := strings.Split(cmdStats[0], "=")
-				if len(cmdStatsCalls) < 2 {
-					continue
-				}
-				cmdStatsUsec := strings.Split(cmdStats[1], "=")
-				if len(cmdStatsUsec) < 2 {
-					continue
-				}
-				var cmdStatsMsec, cmdStatsMsecPc float64
-				microsec, err := strconv.ParseFloat(cmdStatsUsec[1], 64)
-				if err != nil {
-					continue
-				}
-				cmdStatsMsec = microsec / 1000
-				cmdStatsUsecPc := strings.Split(cmdStats[2], "=")
-				if len(cmdStatsUsecPc) < 2 {
-					continue
-				}
-				microsec, err = strconv.ParseFloat(cmdStatsUsecPc[1], 64)
-				if err != nil {
-					continue
-				}
-				cmdStatsMsecPc = microsec / 1000
-				if shortTag := strings.Split(sp[0], "_"); len(shortTag) == 2 {
-					tags["cmd"] = shortTag[1]
-				}
-				Add(&md, "redis.cmdstats_msec_pc", cmdStatsMsecPc, tags, metadata.Gauge, metadata.MilliSecond, descRedisCmdMsecPc)
-				Add(&md, "redis.cmdstats_msec", cmdStatsMsec, tags, metadata.Counter, metadata.MilliSecond, descRedisCmdMsec)
-				Add(&md, "redis.cmdstats_calls", cmdStatsCalls[1], tags, metadata.Counter, metadata.Operation, descRedisCmdCalls)
-				continue
-			}
-			Add(&md, "redis."+sp[0], sp[1], tags, metadata.Unknown, metadata.None, "")
-		}
-		Add(&md, "redis.key_count", keys, tags, metadata.Gauge, metadata.Key, descRedisKeyCount)
-	}
-	return md, Error
-}
-
-const (
-	descRedisKeyCount  = "The total number of keys in the instance."
-	descRedisCmdMsecPc = "Average CPU consumed per command execution."
-	descRedisCmdMsec   = "Total CPU time consumed by commands."
-	descRedisCmdCalls  = "Number of calls."
-)
diff --git a/cmd/scollector/collectors/riak.go b/cmd/scollector/collectors/riak.go
deleted file mode 100644
index 2702c34..0000000
--- a/cmd/scollector/collectors/riak.go
+++ /dev/null
@@ -1,516 +0,0 @@
-package collectors
-
-import (
-	"encoding/json"
-	"fmt"
-	"net/http"
-	"strings"
-
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-)
-
-var riakMeta = map[string]MetricMeta{
-	"pbc_connects_total": {
-		Metric:   "pbc_connections",
-		RateType: metadata.Counter,
-		Unit:     metadata.Connection,
-		Desc:     "Total number of Protocol Buffers connections made.",
-	},
-	"read_repairs_total": {
-		Metric:   "read_repairs",
-		RateType: metadata.Counter,
-		Unit:     metadata.Operation,
-		Desc:     "Total number of Read Repairs this node has coordinated.",
-	},
-	"read_repairs_primary_outofdate_count": {
-		Metric:   "read_repairs_primary_outofdate",
-		RateType: metadata.Counter,
-		Unit:     metadata.Operation,
-		Desc:     "Total number of read repair operations performed on primary vnodes due to stale replicas.",
-	},
-	"read_repairs_primary_notfound_count": {
-		Metric:   "read_repairs_primary_notfound",
-		RateType: metadata.Counter,
-		Unit:     metadata.Operation,
-		Desc:     "Total number of read repair operations performed on primary vnodes due to missing replicas.",
-	},
-	"read_repairs_fallback_outofdate_count": {
-		Metric:   "read_repairs_fallback_outofdate",
-		RateType: metadata.Counter,
-		Unit:     metadata.Operation,
-		Desc:     "Total number of read repair operations performed on fallback vnodes due to stale replicas.",
-	},
-	"read_repairs_fallback_notfound_count": {
-		Metric:   "read_repairs_fallback_notfound",
-		RateType: metadata.Counter,
-		Unit:     metadata.Operation,
-		Desc:     "Total number of read repair operations performed on fallback vnodes due to missing replicas.",
-	},
-	"coord_redirs_total": {
-		Metric:   "coord_redirs",
-		RateType: metadata.Counter,
-		Unit:     metadata.Operation,
-		Desc:     "Total number of requests this node has redirected to other nodes for coordination.",
-	},
-	"precommit_fail": {
-		Metric:   "precommit_fail",
-		RateType: metadata.Counter,
-		Unit:     metadata.Event,
-		Desc:     "Total number of pre-commit hook failures.",
-	},
-	"postcommit_fail": {
-		Metric:   "postcommit_fail",
-		RateType: metadata.Counter,
-		Unit:     metadata.Event,
-		Desc:     "Total number of post-commit hook failures.",
-	},
-	"executing_mappers": {
-		Metric:   "executing_mappers",
-		RateType: metadata.Gauge,
-		Unit:     metadata.Process,
-	},
-	"pipeline_create_count": {
-		Metric:   "pipeline.create.count",
-		RateType: metadata.Counter,
-		Unit:     metadata.Process,
-		Desc:     "The total number of pipelines created since the node was started.",
-	},
-	"pipeline_create_error_count": {
-		Metric:   "pipeline.create.errors",
-		RateType: metadata.Counter,
-		Unit:     metadata.Event,
-		Desc:     "The total number of pipeline creation errors since the node was started.",
-	},
-	"pipeline_active": {
-		Metric:   "active",
-		TagSet:   opentsdb.TagSet{"type": "pbc"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Process,
-		Desc:     "The number of pipelines active in the last 60 seconds.",
-	},
-	"index_fsm_active": {
-		Metric:   "active",
-		TagSet:   opentsdb.TagSet{"type": "index"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Process,
-		Desc:     "Number of active Secondary Index FSMs.",
-	},
-	"list_fsm_active": {
-		Metric:   "active",
-		TagSet:   opentsdb.TagSet{"type": "list"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Process,
-		Desc:     "Number of active Keylisting FSMs.",
-	},
-
-	"memory_total": {
-		Metric:   "memory",
-		TagSet:   opentsdb.TagSet{"type": "total"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Bytes,
-		Desc:     "Total allocated memory (sum of processes and system).",
-	},
-	"memory_processes": {
-		Metric:   "memory",
-		TagSet:   opentsdb.TagSet{"type": "processes"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Bytes,
-		Desc:     "Total amount of memory allocated for Erlang processes.",
-	},
-	"memory_processes_used": {
-		Metric:   "memory",
-		TagSet:   opentsdb.TagSet{"type": "processes_used"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Bytes,
-		Desc:     "Total amount of memory used by Erlang processes.",
-	},
-	"memory_system": {
-		Metric:   "memory",
-		TagSet:   opentsdb.TagSet{"type": "system"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Bytes,
-		Desc:     "Total allocated memory that is not directly related to an Erlang process.",
-	},
-	"memory_system_used": {
-		Metric:   "memory",
-		TagSet:   opentsdb.TagSet{"type": "system_used"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Bytes,
-	},
-	"memory_atom": {
-		Metric:   "memory",
-		TagSet:   opentsdb.TagSet{"type": "atom"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Bytes,
-		Desc:     "Total amount of memory currently allocated for atom storage.",
-	},
-	"memory_atom_used": {
-		Metric:   "memory",
-		TagSet:   opentsdb.TagSet{"type": "atom_used"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Bytes,
-		Desc:     "Total amount of memory currently used for atom storage.",
-	},
-	"memory_binary": {
-		Metric:   "memory",
-		TagSet:   opentsdb.TagSet{"type": "binary"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Bytes,
-		Desc:     "Total amount of memory used for binaries.",
-	},
-	"memory_code": {
-		Metric:   "memory",
-		TagSet:   opentsdb.TagSet{"type": "code"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Bytes,
-		Desc:     "Total amount of memory allocated for Erlang code.",
-	},
-	"memory_ets": {
-		Metric:   "memory",
-		TagSet:   opentsdb.TagSet{"type": "ets"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Bytes,
-		Desc:     "Total memory allocated for Erlang Term Storage.",
-	},
-	"mem_total": {
-		Metric:   "memory",
-		TagSet:   opentsdb.TagSet{"type": "available"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Bytes,
-		Desc:     "Total available system memory.",
-	},
-	"mem_allocated": {
-		Metric:   "memory",
-		TagSet:   opentsdb.TagSet{"type": "allocated"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Bytes,
-		Desc:     "Total memory allocated for this node.",
-	},
-
-	"vnode_index_reads_total": {
-		Metric:   "vnode.index.requests",
-		RateType: metadata.Counter,
-		Unit:     metadata.Operation,
-		Desc:     "Total number of local replicas participating in secondary index reads.",
-	},
-	"vnode_index_writes_total": {
-		Metric:   "vnode.index.requests",
-		TagSet:   opentsdb.TagSet{"type": "write"},
-		RateType: metadata.Counter,
-		Unit:     metadata.Operation,
-		Desc:     "Total number of local replicas participating in secondary index writes.",
-	},
-	"vnode_index_deletes_total": {
-		Metric:   "vnode.index.requests",
-		TagSet:   opentsdb.TagSet{"type": "delete"},
-		RateType: metadata.Counter,
-		Unit:     metadata.Operation,
-		Desc:     "Total number of local replicas participating in secondary index deletes.",
-	},
-	"vnode_index_writes_postings_total": {
-		Metric:   "vnode.index.requests",
-		TagSet:   opentsdb.TagSet{"type": "write_post"},
-		RateType: metadata.Counter,
-		Unit:     metadata.Operation,
-		Desc:     "Total number of individual secondary index values written.",
-	},
-	"vnode_index_deletes_postings_total": {
-		Metric:   "vnode.index.requests",
-		TagSet:   opentsdb.TagSet{"type": "delete_post"},
-		RateType: metadata.Counter,
-		Unit:     metadata.Operation,
-		Desc:     "Total number of individual secondary index values deleted.",
-	},
-
-	"vnode_gets_total": {
-		Metric:   "vnode.requests",
-		TagSet:   opentsdb.TagSet{"type": "get"},
-		RateType: metadata.Counter,
-		Unit:     metadata.Operation,
-		Desc:     "Total number of GETs coordinated by local vnodes.",
-	},
-	"vnode_puts_total": {
-		Metric:   "vnode.requests",
-		TagSet:   opentsdb.TagSet{"type": "put"},
-		RateType: metadata.Counter,
-		Unit:     metadata.Operation,
-		Desc:     "Total number of PUTS coordinated by local vnodes.",
-	},
-	"node_gets_total": {
-		Metric:   "node.requests",
-		TagSet:   opentsdb.TagSet{"type": "get"},
-		RateType: metadata.Counter,
-		Unit:     metadata.Operation,
-		Desc:     "Total number of GETs coordinated by this node, including GETs to non-local vnodes.",
-	},
-	"node_puts_total": {
-		Metric:   "node.requests",
-		TagSet:   opentsdb.TagSet{"type": "put"},
-		RateType: metadata.Counter,
-		Unit:     metadata.Operation,
-		Desc:     "Total number of PUTs coordinated by this node, including PUTs to non-local vnodes.",
-	},
-	"node_get_fsm_time_mean": {
-		Metric:   "node.latency.mean",
-		TagSet:   opentsdb.TagSet{"type": "get"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Second,
-		Desc:     "Mean time between reception of client GET request and subsequent response to client.",
-	},
-	"node_put_fsm_time_mean": {
-		Metric:   "node.latency.mean",
-		TagSet:   opentsdb.TagSet{"type": "put"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Second,
-		Desc:     "Mean time between reception of client PUT request and subsequent response to client.",
-	},
-	"node_get_fsm_time_median": {
-		Metric:   "node.latency.median",
-		TagSet:   opentsdb.TagSet{"type": "get"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Second,
-		Desc:     "Median time between reception of client GET request and subsequent response to client.",
-	},
-	"node_put_fsm_time_median": {
-		Metric:   "node.latency.median",
-		TagSet:   opentsdb.TagSet{"type": "put"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Second,
-		Desc:     "Median time between reception of client PUT request and subsequent response to client.",
-	},
-	"node_get_fsm_time_95": {
-		Metric:   "node.latency.95th",
-		TagSet:   opentsdb.TagSet{"type": "get"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Second,
-		Desc:     "95th percentile time between reception of client GET request and subsequent response to client.",
-	},
-	"node_put_fsm_time_95": {
-		Metric:   "node.latency.95th",
-		TagSet:   opentsdb.TagSet{"type": "put"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Second,
-		Desc:     "95th percentile time between reception of client PUT request and subsequent response to client.",
-	},
-	"node_get_fsm_time_99": {
-		Metric:   "node.latency.99th",
-		TagSet:   opentsdb.TagSet{"type": "get"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Second,
-		Desc:     "99th percentile time between reception of client GET request and subsequent response to client.",
-	},
-	"node_put_fsm_time_99": {
-		Metric:   "node.latency.99th",
-		TagSet:   opentsdb.TagSet{"type": "put"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Second,
-		Desc:     "99th percentile time between reception of client PUT request and subsequent response to client.",
-	},
-	"node_get_fsm_time_100": {
-		Metric:   "node.latency.100th",
-		TagSet:   opentsdb.TagSet{"type": "get"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Second,
-		Desc:     "100th percentile time between reception of client GET request and subsequent response to client.",
-	},
-	"node_put_fsm_time_100": {
-		Metric:   "node.latency.100th",
-		TagSet:   opentsdb.TagSet{"type": "put"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Second,
-		Desc:     "100th percentile time between reception of client PUT request and subsequent response to client.",
-	},
-	"node_get_fsm_objsize_mean": {
-		Metric:   "node.objsize.mean",
-		TagSet:   opentsdb.TagSet{"type": "get"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Bytes,
-		Desc:     "Mean object size encountered by this node within the last minute.",
-	},
-	"node_get_fsm_objsize_median": {
-		Metric:   "node.objsize.median",
-		TagSet:   opentsdb.TagSet{"type": "get"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Bytes,
-		Desc:     "Median object size encountered by this node within the last minute.",
-	},
-	"node_get_fsm_objsize_95": {
-		Metric:   "node.objsize.95th",
-		TagSet:   opentsdb.TagSet{"type": "get"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Bytes,
-		Desc:     "95th percentile object size encountered by this node within the last minute.",
-	},
-	"node_get_fsm_objsize_99": {
-		Metric:   "node.objsize.99th",
-		TagSet:   opentsdb.TagSet{"type": "get"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Bytes,
-		Desc:     "99th percentile object size encountered by this node within the last minute.",
-	},
-	"node_get_fsm_objsize_100": {
-		Metric:   "node.objsize.100th",
-		TagSet:   opentsdb.TagSet{"type": "get"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Bytes,
-		Desc:     "100th percentile object size encountered by this node within the last minute.",
-	},
-	"node_get_fsm_siblings_mean": {
-		Metric:   "node.siblings.mean",
-		TagSet:   opentsdb.TagSet{"type": "get"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Count,
-		Desc:     "Mean number of siblings encountered during all GET operations by this node within the last minute.",
-	},
-	"node_get_fsm_siblings_median": {
-		Metric:   "node.siblings.median",
-		TagSet:   opentsdb.TagSet{"type": "get"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Count,
-		Desc:     "Median number of siblings encountered during all GET operations by this node within the last minute.",
-	},
-	"node_get_fsm_siblings_95": {
-		Metric:   "node.siblings.95th",
-		TagSet:   opentsdb.TagSet{"type": "get"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Count,
-		Desc:     "95th percentile of siblings encountered during all GET operations by this node within the last minute.",
-	},
-	"node_get_fsm_siblings_99": {
-		Metric:   "node.siblings.99th",
-		TagSet:   opentsdb.TagSet{"type": "get"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Count,
-		Desc:     "99th percentile of siblings encountered during all GET operations by this node within the last minute.",
-	},
-	"node_get_fsm_siblings_100": {
-		Metric:   "node.siblings.100th",
-		TagSet:   opentsdb.TagSet{"type": "get"},
-		RateType: metadata.Gauge,
-		Unit:     metadata.Count,
-		Desc:     "100th percentile of siblings encountered during all GET operations by this node within the last minute.",
-	},
-	"node_get_fsm_rejected_total": {
-		Metric:   "node.requests.rejected",
-		TagSet:   opentsdb.TagSet{"type": "get"},
-		RateType: metadata.Counter,
-		Unit:     metadata.Event,
-		Desc:     "Total number of GET FSMs rejected by Sidejob's overload protection.",
-	},
-	"node_put_fsm_rejected_total": {
-		Metric:   "node.requests.rejected",
-		TagSet:   opentsdb.TagSet{"type": "put"},
-		RateType: metadata.Counter,
-		Unit:     metadata.Event,
-		Desc:     "Total number of PUT FSMs rejected by Sidejob's overload protection.",
-	},
-	"ring_num_partitions": {
-		Metric:   "ring_num_partitions",
-		RateType: metadata.Gauge,
-		Unit:     metadata.Count,
-		Desc:     "The number of partitions in the ring.",
-	},
-	"ring_creation_size": {
-		Metric:   "ring.creation_size",
-		RateType: metadata.Gauge,
-		Unit:     metadata.Count,
-		Desc:     "Ring size this cluster was created with.",
-	},
-	"cpu_nprocs": {
-		Metric:   "cpu.nprocs",
-		RateType: metadata.Gauge,
-		Unit:     metadata.Count,
-		Desc:     "Number of operating system processes.",
-	},
-	"cpu_avg1": {
-		Metric:   "cpu.avg1",
-		RateType: metadata.Gauge,
-		Unit:     metadata.Load,
-		Desc:     "The average number of active processes for the last 1 minute (equivalent to top(1) command’s load average when divided by 256()).",
-	},
-	"cpu_avg5": {
-		Metric:   "cpu.avg5",
-		RateType: metadata.Gauge,
-		Unit:     metadata.Load,
-		Desc:     "The average number of active processes for the last 5 minutes (equivalent to top(1) command’s load average when divided by 256()).",
-	},
-	"cpu_avg15": {
-		Metric:   "cpu.avg15",
-		RateType: metadata.Gauge,
-		Unit:     metadata.Load,
-		Desc:     "The average number of active processes for the last 15 minutes (equivalent to top(1) command’s load average when divided by 256()).",
-	},
-	"riak_search_vnodeq_total": {
-		Metric:   "search.vnodeq",
-		RateType: metadata.Counter,
-		Unit:     metadata.Event,
-		Desc:     "Total number of unprocessed messages all vnode message queues in the Riak Search subsystem have received on this node since it was started.",
-	},
-	"riak_search_vnodes_running": {
-		Metric:   "search.vnodes_running",
-		RateType: metadata.Gauge,
-		Unit:     metadata.Process,
-		Desc:     "Total number of vnodes currently running in the Riak Search subsystem.",
-	},
-}
-
-func init() {
-	collectors = append(collectors, &IntervalCollector{F: c_riak, Enable: enableRiak})
-}
-
-const (
-	riakURL string = "http://localhost:8098/stats"
-)
-
-func enableRiak() bool {
-	return enableURL(riakURL)()
-}
-
-func c_riak() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	res, err := http.Get(riakURL)
-	if err != nil {
-		return nil, err
-	}
-	defer res.Body.Close()
-	var r map[string]interface{}
-	if err := json.NewDecoder(res.Body).Decode(&r); err != nil {
-		return nil, err
-	}
-	for k, v := range r {
-		if m, ok := riakMeta[k]; ok {
-			if strings.HasPrefix(m.Metric, "node.latency") {
-				if nl, ok := v.(float64); ok {
-					v = nl / 1000000
-				} else {
-					err := fmt.Errorf("riak: bad integer %s in metric '%s'", v, m.Metric)
-					return nil, err
-				}
-			}
-			Add(&md, "riak."+m.Metric, v, m.TagSet, m.RateType, m.Unit, m.Desc)
-		} else if k == "connected_nodes" {
-			nodes, ok := v.([]interface{})
-			// 'connected_nodes' array can be empty
-			if !ok {
-				err := fmt.Errorf("riak: unexpected content or type for 'connected_nodes' metric array")
-				return nil, err
-			}
-			Add(&md, "riak.connected_nodes", len(nodes), nil, metadata.Gauge, metadata.Count, descConNodes)
-		} else if k == "ring_members" {
-			ringMembers, ok := v.([]interface{})
-			// at least one ring member must always exist
-			if !ok || len(ringMembers) < 1 {
-				err := fmt.Errorf("riak: unexpected content or type for 'ring_members' metric array")
-				return nil, err
-			}
-			Add(&md, "riak.ring_members", len(ringMembers), nil, metadata.Gauge, metadata.Count, descRingMembers)
-		}
-	}
-	return md, nil
-}
-
-const (
-	descConNodes    = "Count of nodes that this node is aware of at this time."
-	descRingMembers = "Count of nodes that are members of the ring."
-)
diff --git a/cmd/scollector/collectors/snmp.go b/cmd/scollector/collectors/snmp.go
deleted file mode 100644
index c0f5e09..0000000
--- a/cmd/scollector/collectors/snmp.go
+++ /dev/null
@@ -1,69 +0,0 @@
-package collectors
-
-import (
-	"fmt"
-	"io"
-	"math/big"
-
-	"bosun.org/_third_party/github.com/mjibson/snmp"
-)
-
-func SNMP(community, host string) error {
-	if host == "" {
-		return fmt.Errorf("empty SNMP hostname")
-	}
-	if community == "" {
-		return fmt.Errorf("empty SNMP community")
-	}
-	SNMPIfaces(community, host)
-	SNMPCisco(community, host)
-	return nil
-}
-
-// snmp_subtree takes an oid and returns all data exactly one level below it. It
-// produces an error if there is more than one level below.
-func snmp_subtree(host, community, oid string) (map[int]interface{}, error) {
-	rows, err := snmp.Walk(host, community, oid)
-	if err != nil {
-		return nil, err
-	}
-	m := make(map[int]interface{})
-	for rows.Next() {
-		switch oid {
-		case ifHCInBroadcastPkts:
-			a := new(big.Int)
-			id, err := rows.Scan(&a)
-			if err != nil {
-				return nil, err
-			}
-			switch t := id.(type) {
-			case int:
-				m[t] = a
-			default:
-				return nil, fmt.Errorf("snmp subtree: only one level allowed")
-			}
-		default:
-			var a interface{}
-			id, err := rows.Scan(&a)
-			if err != nil {
-				return nil, err
-			}
-			switch t := id.(type) {
-			case int:
-				m[t] = a
-			default:
-				return nil, fmt.Errorf("snmp subtree: only one level allowed")
-			}
-		}
-	}
-	if err := rows.Err(); err != nil && err != io.EOF {
-		return nil, err
-	}
-	return m, nil
-}
-
-func snmp_oid(host, community, oid string) (*big.Int, error) {
-	v := new(big.Int)
-	err := snmp.Get(host, community, oid, &v)
-	return v, err
-}
diff --git a/cmd/scollector/collectors/snmp_cisco.go b/cmd/scollector/collectors/snmp_cisco.go
deleted file mode 100644
index f54fd92..0000000
--- a/cmd/scollector/collectors/snmp_cisco.go
+++ /dev/null
@@ -1,67 +0,0 @@
-package collectors
-
-import (
-	"fmt"
-	"math/big"
-	"time"
-
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-)
-
-const (
-	ciscoCPU     = ".1.3.6.1.4.1.9.9.109.1.1.1.1.6"
-	ciscoMemFree = ".1.3.6.1.4.1.9.9.48.1.1.1.6"
-	ciscoMemName = ".1.3.6.1.4.1.9.9.48.1.1.1.2"
-	ciscoMemUsed = ".1.3.6.1.4.1.9.9.48.1.1.1.5"
-)
-
-// SNMPCisco registers a SNMP CISCO collector for the given community and host.
-func SNMPCisco(community, host string) {
-	collectors = append(collectors, &IntervalCollector{
-		F: func() (opentsdb.MultiDataPoint, error) {
-			return c_snmp_cisco(community, host)
-		},
-		Interval: time.Second * 30,
-		name:     fmt.Sprintf("snmp-cisco-%s", host),
-	})
-}
-
-func c_snmp_cisco(community, host string) (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	var v *big.Int
-	var err error
-	if v, err = snmp_oid(host, community, ciscoCPU); err == nil {
-	} else if v, err = snmp_oid(host, community, ciscoCPU+".1"); err == nil {
-	} else {
-		return nil, err
-	}
-	Add(&md, "cisco.cpu", v.String(), opentsdb.TagSet{"host": host}, metadata.Gauge, metadata.Pct, "The overall CPU busy percentage in the last five-second period.")
-
-	names, err := snmp_subtree(host, community, ciscoMemName)
-	if err != nil {
-		return nil, err
-	}
-	used, err := snmp_subtree(host, community, ciscoMemUsed)
-	if err != nil {
-		return nil, err
-	}
-	free, err := snmp_subtree(host, community, ciscoMemFree)
-	if err != nil {
-		return nil, err
-	}
-	for id, name := range names {
-		n := fmt.Sprintf("%s", name)
-		u, present := used[id]
-		if !present {
-			continue
-		}
-		f, present := free[id]
-		if !present {
-			continue
-		}
-		Add(&md, "cisco.mem.used", u, opentsdb.TagSet{"host": host, "name": n}, metadata.Unknown, metadata.None, "")
-		Add(&md, "cisco.mem.free", f, opentsdb.TagSet{"host": host, "name": n}, metadata.Unknown, metadata.None, "")
-	}
-	return md, nil
-}
diff --git a/cmd/scollector/collectors/snmp_ifaces.go b/cmd/scollector/collectors/snmp_ifaces.go
deleted file mode 100644
index 153b39e..0000000
--- a/cmd/scollector/collectors/snmp_ifaces.go
+++ /dev/null
@@ -1,117 +0,0 @@
-package collectors
-
-import (
-	"fmt"
-	"strings"
-	"time"
-
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-)
-
-const (
-	ifAlias              = ".1.3.6.1.2.1.31.1.1.1.18"
-	ifDescr              = ".1.3.6.1.2.1.2.2.1.2"
-	ifHCInBroadcastPkts  = ".1.3.6.1.2.1.31.1.1.1.9"
-	ifHCInMulticastPkts  = ".1.3.6.1.2.1.31.1.1.1.8"
-	ifHCInUcastPkts      = ".1.3.6.1.2.1.31.1.1.1.7"
-	ifHCOutBroadcastPkts = ".1.3.6.1.2.1.31.1.1.1.13"
-	ifHCOutMulticastPkts = ".1.3.6.1.2.1.31.1.1.1.12"
-	ifHCOutOctets        = ".1.3.6.1.2.1.31.1.1.1.10"
-	ifHCOutUcastPkts     = ".1.3.6.1.2.1.31.1.1.1.11"
-	ifHCinOctets         = ".1.3.6.1.2.1.31.1.1.1.6"
-	ifInDiscards         = ".1.3.6.1.2.1.2.2.1.13"
-	ifInErrors           = ".1.3.6.1.2.1.2.2.1.14"
-	ifName               = ".1.3.6.1.2.1.31.1.1.1.1"
-	ifOutDiscards        = ".1.3.6.1.2.1.2.2.1.19"
-	ifOutErrors          = ".1.3.6.1.2.1.2.2.1.20"
-)
-
-// SNMPIfaces registers a SNMP Interfaces collector for the given community and host.
-func SNMPIfaces(community, host string) {
-	collectors = append(collectors, &IntervalCollector{
-		F: func() (opentsdb.MultiDataPoint, error) {
-			return c_snmp_ifaces(community, host)
-		},
-		Interval: time.Second * 30,
-		name:     fmt.Sprintf("snmp-ifaces-%s", host),
-	})
-}
-
-func switch_bond(metric, iname string) string {
-	if strings.Contains(iname, "port-channel") {
-		return "os.net.bond" + strings.TrimPrefix(metric, "os.net")
-	}
-	return metric
-}
-
-func c_snmp_ifaces(community, host string) (opentsdb.MultiDataPoint, error) {
-	n, err := snmp_subtree(host, community, ifName)
-	if err != nil || len(n) == 0 {
-		n, err = snmp_subtree(host, community, ifDescr)
-		if err != nil {
-			return nil, err
-		}
-	}
-	a, err := snmp_subtree(host, community, ifAlias)
-	if err != nil {
-		return nil, err
-	}
-	names := make(map[interface{}]string, len(n))
-	aliases := make(map[interface{}]string, len(a))
-	for k, v := range n {
-		names[k] = fmt.Sprintf("%s", v)
-	}
-	for k, v := range a {
-		// In case clean would come up empty, prevent the point from being removed
-		// by setting our own empty case.
-		aliases[k], _ = opentsdb.Clean(fmt.Sprintf("%s", v))
-		if aliases[k] == "" {
-			aliases[k] = "NA"
-		}
-	}
-	var md opentsdb.MultiDataPoint
-	add := func(oid, metric, dir string) error {
-		m, err := snmp_subtree(host, community, oid)
-		if err != nil {
-			return err
-		}
-		for k, v := range m {
-			tags := opentsdb.TagSet{
-				"host":      host,
-				"direction": dir,
-				"iface":     fmt.Sprintf("%d", k),
-				"iname":     names[k],
-			}
-			Add(&md, switch_bond(metric, names[k]), v, tags, metadata.Unknown, metadata.None, "")
-			metadata.AddMeta("", tags, "alias", aliases[k], false)
-		}
-		return nil
-	}
-	oids := []snmpAdd{
-		{ifHCInBroadcastPkts, osNetBroadcast, "in"},
-		{ifHCInMulticastPkts, osNetMulticast, "in"},
-		{ifHCInUcastPkts, osNetUnicast, "in"},
-		{ifHCOutBroadcastPkts, osNetBroadcast, "out"},
-		{ifHCOutMulticastPkts, osNetMulticast, "out"},
-		{ifHCOutOctets, osNetBytes, "out"},
-		{ifHCOutUcastPkts, osNetUnicast, "out"},
-		{ifHCinOctets, osNetBytes, "in"},
-		{ifInDiscards, osNetDropped, "in"},
-		{ifInErrors, osNetErrors, "in"},
-		{ifOutDiscards, osNetDropped, "out"},
-		{ifOutErrors, osNetErrors, "out"},
-	}
-	for _, o := range oids {
-		if err := add(o.oid, o.metric, o.dir); err != nil {
-			return nil, err
-		}
-	}
-	return md, nil
-}
-
-type snmpAdd struct {
-	oid    string
-	metric string
-	dir    string
-}
diff --git a/cmd/scollector/collectors/sntp_windows.go b/cmd/scollector/collectors/sntp_windows.go
deleted file mode 100644
index 08200fe..0000000
--- a/cmd/scollector/collectors/sntp_windows.go
+++ /dev/null
@@ -1,91 +0,0 @@
-package collectors
-
-import (
-	"fmt"
-	"strings"
-	"time"
-
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-	"bosun.org/util"
-)
-
-func init() {
-	collectors = append(collectors, &IntervalCollector{F: c_sntp_windows})
-}
-
-func c_sntp_windows() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	const metric = "sntp."
-	var (
-		stratum string
-		delay   float64
-		when    float64
-		source  string
-		poll    float64
-	)
-	if err := util.ReadCommand(func(line string) error {
-		f := strings.SplitN(line, ":", 2)
-		if len(f) != 2 {
-			return nil
-		}
-		f[1] = strings.TrimSpace(f[1])
-		switch f[0] {
-		case "Stratum":
-			sf := strings.Fields(f[1])
-			if len(sf) < 1 {
-				return fmt.Errorf("Unexpected value for stratum")
-			}
-			stratum = sf[0]
-		case "Root Delay":
-			d, err := time.ParseDuration(f[1])
-			if err != nil {
-				return err
-			}
-			delay = d.Seconds()
-		case "Last Successful Sync Time":
-			if f[1] == "unspecified" {
-				break
-			}
-			t, err := time.Parse("1/2/2006 3:04:05 PM", f[1])
-			if err != nil {
-				return err
-			}
-			when = time.Since(t).Seconds()
-		case "Source":
-			source = strings.TrimSpace(f[1])
-		case "Poll Interval":
-			sf := strings.Fields(f[1])
-			if len(sf) != 2 {
-				return fmt.Errorf("Unexpected value for Poll Interval")
-			}
-			s := strings.Trim(sf[1], "()")
-			d, err := time.ParseDuration(strings.TrimSpace(s))
-			if err != nil {
-				return err
-			}
-			poll = d.Seconds()
-		}
-		return nil
-	}, "w32tm", "/query", "/status"); err != nil {
-		return nil, nil
-	}
-	tags := opentsdb.TagSet{"remote": source}
-	Add(&md, metric+"stratum", stratum, tags, metadata.Gauge, "Stratum", "")
-	Add(&md, metric+"delay", delay, tags, metadata.Gauge, metadata.Second, "")
-	Add(&md, metric+"when", when, tags, metadata.Gauge, metadata.Second, "")
-	Add(&md, metric+"poll", poll, tags, metadata.Gauge, metadata.Second, "")
-	_ = util.ReadCommand(func(line string) error {
-		f := strings.SplitN(line, ",", 2)
-		if len(f) != 2 {
-			return nil
-		}
-		d, err := time.ParseDuration(strings.TrimSpace(f[1]))
-		if err != nil {
-			return nil
-		}
-		Add(&md, metric+"offset", d.Seconds(), tags, metadata.Gauge, metadata.Second, "")
-		return nil
-	}, "w32tm", "/stripchart", fmt.Sprintf("/computer:%v", source), "/samples:1", "/dataonly")
-	return md, nil
-}
diff --git a/cmd/scollector/collectors/sql_windows.go b/cmd/scollector/collectors/sql_windows.go
deleted file mode 100644
index f376d9c..0000000
--- a/cmd/scollector/collectors/sql_windows.go
+++ /dev/null
@@ -1,501 +0,0 @@
-package collectors
-
-import (
-	"fmt"
-	"strings"
-	"time"
-
-	"bosun.org/_third_party/github.com/StackExchange/wmi"
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-	"bosun.org/util"
-)
-
-func init() {
-	c := &IntervalCollector{
-		F: c_mssql,
-	}
-	c.init = wmiInit(c, func() interface{} { return &[]Win32_PerfRawData_MSSQLSERVER_SQLServerGeneralStatistics{} }, `WHERE Name <> '_Total'`, &sqlQuery)
-	collectors = append(collectors, c)
-
-	var dstCluster []MSCluster_Cluster
-	var q = wmi.CreateQuery(&dstCluster, ``)
-	if err := queryWmiNamespace(q, &dstCluster, rootMSCluster); err != nil {
-		sqlClusterName = "None"
-	} else if len(dstCluster) != 1 {
-		sqlClusterName = "Unknown"
-	} else {
-		sqlClusterName = dstCluster[0].Name
-	}
-
-	c_replica_db := &IntervalCollector{
-		F: c_mssql_replica_db,
-	}
-	c_replica_db.init = wmiInit(c_replica_db, func() interface{} { return &[]Win32_PerfRawData_MSSQLSERVER_SQLServerDatabaseReplica{} }, `WHERE Name <> '_Total'`, &sqlAGDBQuery)
-	collectors = append(collectors, c_replica_db)
-
-	c_replica_server := &IntervalCollector{
-		F: c_mssql_replica_server,
-	}
-	c_replica_server.init = wmiInit(c_replica_server, func() interface{} { return &[]Win32_PerfRawData_MSSQLSERVER_SQLServerAvailabilityReplica{} }, `WHERE Name <> '_Total'`, &sqlAGQuery)
-	collectors = append(collectors, c_replica_server)
-
-	c_replica_votes := &IntervalCollector{
-		F:        c_mssql_replica_votes,
-		Interval: time.Minute * 5,
-	}
-	c_replica_votes.init = wmiInitNamespace(c_replica_votes, func() interface{} { return &[]MSCluster_Node{} }, fmt.Sprintf("WHERE Name = '%s'", util.Hostname), &sqlAGVotes, rootMSCluster)
-	collectors = append(collectors, c_replica_votes)
-
-	c_replica_resources := &IntervalCollector{
-		F:        c_mssql_replica_resources,
-		Interval: time.Minute,
-	}
-	c_replica_resources.init = wmiInitNamespace(c_replica_resources, func() interface{} { return &[]MSCluster_Resource{} }, ``, &sqlAGResources, rootMSCluster)
-	collectors = append(collectors, c_replica_resources)
-}
-
-const (
-	rootMSCluster string = "root\\MSCluster"
-)
-
-var (
-	sqlClusterName string
-	sqlQuery       string
-	sqlAGDBQuery   string
-	sqlAGQuery     string
-	sqlAGVotes     string
-	sqlAGResources string
-)
-
-func c_mssql() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	var err error
-	add := func(f func() (opentsdb.MultiDataPoint, error)) {
-		dps, e := f()
-		if e != nil {
-			err = e
-		}
-		md = append(md, dps...)
-	}
-	add(c_mssql_general)
-	add(c_mssql_statistics)
-	add(c_mssql_locks)
-	add(c_mssql_databases)
-	return md, err
-}
-
-func c_mssql_general() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_PerfRawData_MSSQLSERVER_SQLServerGeneralStatistics
-	var q = wmi.CreateQuery(&dst, `WHERE Name <> '_Total'`)
-	if err := queryWmi(q, &dst); err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		Add(&md, "mssql.user_connections", v.UserConnections, nil, metadata.Gauge, metadata.Count, descMSSQLUserConnections)
-		Add(&md, "mssql.connection_resets", v.ConnectionResetPersec, nil, metadata.Counter, metadata.PerSecond, descMSSQLConnectionResetPersec)
-		Add(&md, "mssql.logins", v.LoginsPersec, nil, metadata.Counter, metadata.PerSecond, descMSSQLLoginsPersec)
-		Add(&md, "mssql.logouts", v.LogoutsPersec, nil, metadata.Counter, metadata.PerSecond, descMSSQLLogoutsPersec)
-		Add(&md, "mssql.mars_deadlocks", v.MarsDeadlocks, nil, metadata.Counter, metadata.Count, descMSSQLMarsDeadlocks)
-		Add(&md, "mssql.proc_blocked", v.Processesblocked, nil, metadata.Gauge, metadata.Count, descMSSQLProcessesblocked)
-		Add(&md, "mssql.temptables_created", v.TempTablesCreationRate, nil, metadata.Counter, metadata.PerSecond, descMSSQLTempTablesCreationRate)
-		Add(&md, "mssql.temptables_to_destroy", v.TempTablesForDestruction, nil, metadata.Gauge, metadata.Count, descMSSQLTempTablesForDestruction)
-		Add(&md, "mssql.transactions_total", v.Transactions, nil, metadata.Gauge, metadata.Count, descMSSQLTransactions)
-
-	}
-	return md, nil
-}
-
-const (
-	descMSSQLUserConnections          = "Number of users connected to the system."
-	descMSSQLConnectionResetPersec    = "Total number of connection resets per second."
-	descMSSQLLoginsPersec             = "Total number of logins started per second."
-	descMSSQLLogoutsPersec            = "Total number of logouts started per second."
-	descMSSQLMarsDeadlocks            = "Number of Mars Deadlocks detected."
-	descMSSQLProcessesblocked         = "Number of currently blocked processes."
-	descMSSQLTempTablesCreationRate   = "Number of temporary tables/table variables created/sec."
-	descMSSQLTempTablesForDestruction = "Number of temporary tables/table variables waiting to be destroyed by the cleanup system thread."
-	descMSSQLTransactions             = "Number of transaction enlistments (local, dtc, and bound)."
-)
-
-type Win32_PerfRawData_MSSQLSERVER_SQLServerGeneralStatistics struct {
-	ConnectionResetPersec    uint64
-	LoginsPersec             uint64
-	LogoutsPersec            uint64
-	MarsDeadlocks            uint64
-	Processesblocked         uint64
-	TempTablesCreationRate   uint64
-	TempTablesForDestruction uint64
-	Transactions             uint64
-	UserConnections          uint64
-}
-
-func c_mssql_statistics() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_PerfRawData_MSSQLSERVER_SQLServerSQLStatistics
-	var q = wmi.CreateQuery(&dst, `WHERE Name <> '_Total'`)
-	err := queryWmi(q, &dst)
-	if err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		Add(&md, "mssql.autoparam_attempts", v.AutoParamAttemptsPersec, nil, metadata.Counter, metadata.PerSecond, descMSSQLAutoParamAttemptsPersec)
-		Add(&md, "mssql.autoparam_failed", v.FailedAutoParamsPersec, nil, metadata.Counter, metadata.PerSecond, descMSSQLFailedAutoParamsPersec)
-		Add(&md, "mssql.autoparam_forced", v.ForcedParameterizationsPersec, nil, metadata.Counter, metadata.PerSecond, descMSSQLForcedParameterizationsPersec)
-		Add(&md, "mssql.autoparam_safe", v.SafeAutoParamsPersec, nil, metadata.Counter, metadata.PerSecond, descMSSQLSafeAutoParamsPersec)
-		Add(&md, "mssql.autoparam_unsafe", v.UnsafeAutoParamsPersec, nil, metadata.Counter, metadata.PerSecond, descMSSQLUnsafeAutoParamsPersec)
-		Add(&md, "mssql.batches", v.BatchRequestsPersec, nil, metadata.Counter, metadata.PerSecond, descMSSQLBatchRequestsPersec)
-		Add(&md, "mssql.guided_plans", v.GuidedplanexecutionsPersec, nil, metadata.Counter, metadata.PerSecond, descMSSQLGuidedplanexecutionsPersec)
-		Add(&md, "mssql.misguided_plans", v.MisguidedplanexecutionsPersec, nil, metadata.Counter, metadata.PerSecond, descMSSQLMisguidedplanexecutionsPersec)
-		Add(&md, "mssql.compilations", v.SQLCompilationsPersec, nil, metadata.Counter, metadata.PerSecond, descMSSQLSQLCompilationsPersec)
-		Add(&md, "mssql.recompilations", v.SQLReCompilationsPersec, nil, metadata.Counter, metadata.PerSecond, descMSSQLSQLReCompilationsPersec)
-	}
-	return md, nil
-}
-
-const (
-	descMSSQLAutoParamAttemptsPersec       = "Number of auto-parameterization attempts."
-	descMSSQLFailedAutoParamsPersec        = "Number of failed auto-parameterizations."
-	descMSSQLForcedParameterizationsPersec = "Number of statements parameterized by forced parameterization per second."
-	descMSSQLSafeAutoParamsPersec          = "Number of safe auto-parameterizations."
-	descMSSQLUnsafeAutoParamsPersec        = "Number of unsafe auto-parameterizations."
-	descMSSQLBatchRequestsPersec           = "Number of SQL batch requests received by server."
-	descMSSQLGuidedplanexecutionsPersec    = "Number of plan executions per second in which the query plan has been generated by using a plan guide."
-	descMSSQLMisguidedplanexecutionsPersec = "Number of plan executions per second in which a plan guide could not be honored during plan generation. The plan guide was disregarded and normal compilation was used to generate the executed plan."
-	descMSSQLSQLCompilationsPersec         = "Number of SQL compilations."
-	descMSSQLSQLReCompilationsPersec       = "Number of SQL re-compiles."
-)
-
-type Win32_PerfRawData_MSSQLSERVER_SQLServerSQLStatistics struct {
-	AutoParamAttemptsPersec       uint64
-	BatchRequestsPersec           uint64
-	FailedAutoParamsPersec        uint64
-	ForcedParameterizationsPersec uint64
-	GuidedplanexecutionsPersec    uint64
-	MisguidedplanexecutionsPersec uint64
-	SafeAutoParamsPersec          uint64
-	SQLCompilationsPersec         uint64
-	SQLReCompilationsPersec       uint64
-	UnsafeAutoParamsPersec        uint64
-}
-
-func c_mssql_locks() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_PerfRawData_MSSQLSERVER_SQLServerLocks
-	var q = wmi.CreateQuery(&dst, `WHERE Name = 'Page' OR Name = 'Extent' OR Name = 'Object' or Name = 'Database'`)
-	err := queryWmi(q, &dst)
-	if err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		tags := opentsdb.TagSet{"type": v.Name}
-		Add(&md, "mssql.lock_wait_time", v.AverageWaitTimems, tags, metadata.Counter, metadata.MilliSecond, descMSSQLAverageWaitTimems)
-		Add(&md, "mssql.lock_requests", v.LockRequestsPersec, tags, metadata.Counter, metadata.PerSecond, descMSSQLLockRequestsPersec)
-		Add(&md, "mssql.lock_timeouts", v.LockTimeoutsPersec, tags, metadata.Counter, metadata.PerSecond, descMSSQLLockTimeoutsPersec)
-		Add(&md, "mssql.lock_timeouts0", v.LockTimeoutstimeout0Persec, tags, metadata.Counter, metadata.PerSecond, descMSSQLLockTimeoutstimeout0Persec)
-		Add(&md, "mssql.lock_waits", v.LockWaitsPersec, tags, metadata.Counter, metadata.PerSecond, descMSSQLLockWaitsPersec)
-		Add(&md, "mssql.deadlocks", v.NumberofDeadlocksPersec, tags, metadata.Counter, metadata.PerSecond, descMSSQLNumberofDeadlocksPersec)
-
-	}
-	return md, nil
-}
-
-const (
-	descMSSQLAverageWaitTimems          = "The average amount of wait time (milliseconds) for each lock request that resulted in a wait."
-	descMSSQLLockRequestsPersec         = "Number of new locks and lock conversions requested from the lock manager."
-	descMSSQLLockTimeoutsPersec         = "Number of lock requests that timed out. This includes requests for NOWAIT locks."
-	descMSSQLLockTimeoutstimeout0Persec = "Number of lock requests that timed out. This does not include requests for NOWAIT locks."
-	descMSSQLLockWaitsPersec            = "Number of lock requests that could not be satisfied immediately and required the caller to wait before being granted the lock."
-	descMSSQLNumberofDeadlocksPersec    = "Number of lock requests that resulted in a deadlock."
-)
-
-type Win32_PerfRawData_MSSQLSERVER_SQLServerLocks struct {
-	AverageWaitTimems          uint64
-	LockRequestsPersec         uint64
-	LockTimeoutsPersec         uint64
-	LockTimeoutstimeout0Persec uint64
-	LockWaitsPersec            uint64
-	Name                       string
-	NumberofDeadlocksPersec    uint64
-}
-
-func c_mssql_databases() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_PerfRawData_MSSQLSERVER_SQLServerDatabases
-	var q = wmi.CreateQuery(&dst, `WHERE Name <> '_Total'`)
-	err := queryWmi(q, &dst)
-	if err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		tags := opentsdb.TagSet{"db": v.Name}
-		Add(&md, "mssql.active_transactions", v.ActiveTransactions, tags, metadata.Gauge, metadata.Count, descMSSQLActiveTransactions)
-		Add(&md, "mssql.backup_restore_throughput", v.BackupPerRestoreThroughputPersec, tags, metadata.Counter, metadata.PerSecond, descMSSQLBackupPerRestoreThroughputPersec)
-		Add(&md, "mssql.bulkcopy_rows", v.BulkCopyRowsPersec, tags, metadata.Counter, metadata.PerSecond, descMSSQLBulkCopyRowsPersec)
-		Add(&md, "mssql.bulkcopy_throughput", v.BulkCopyThroughputPersec, tags, metadata.Counter, metadata.KBytes, descMSSQLBulkCopyThroughputPersec)
-		Add(&md, "mssql.commit_table_entries", v.Committableentries, tags, metadata.Gauge, metadata.Count, descMSSQLCommittableentries)
-		Add(&md, "mssql.data_files_size", v.DataFilesSizeKB*1024, tags, metadata.Gauge, metadata.Bytes, descMSSQLDataFilesSizeKB)
-		Add(&md, "mssql.dbcc_logical_scan_bytes", v.DBCCLogicalScanBytesPersec, tags, metadata.Counter, metadata.BytesPerSecond, descMSSQLDBCCLogicalScanBytesPersec)
-		//Add(&md, "mssql.group_commit_time", v.GroupCommitTimePersec, tags, metadata.Counter, metadata.PerSecond, descMSSQLGroupCommitTimePersec)
-		Add(&md, "mssql.log_bytes_flushed", v.LogBytesFlushedPersec, tags, metadata.Counter, metadata.BytesPerSecond, descMSSQLLogBytesFlushedPersec)
-		Add(&md, "mssql.log_cache_hit_ratio", v.LogCacheHitRatio, tags, metadata.Counter, metadata.Pct, descMSSQLLogCacheHitRatio)
-		Add(&md, "mssql.log_cache_hit_ratio_base", v.LogCacheHitRatio_Base, tags, metadata.Counter, metadata.None, descMSSQLLogCacheHitRatio_Base)
-		Add(&md, "mssql.log_cache_reads", v.LogCacheReadsPersec, tags, metadata.Counter, metadata.PerSecond, descMSSQLLogCacheReadsPersec)
-		Add(&md, "mssql.log_files_size", v.LogFilesSizeKB*1024, tags, metadata.Gauge, metadata.Bytes, descMSSQLLogFilesSizeKB)
-		Add(&md, "mssql.log_files_used_size", v.LogFilesUsedSizeKB*1024, tags, metadata.Gauge, metadata.Bytes, descMSSQLLogFilesUsedSizeKB)
-		Add(&md, "mssql.log_flushes", v.LogFlushesPersec, tags, metadata.Counter, metadata.PerSecond, descMSSQLLogFlushesPersec)
-		Add(&md, "mssql.log_flush_waits", v.LogFlushWaitsPersec, tags, metadata.Counter, metadata.PerSecond, descMSSQLLogFlushWaitsPersec)
-		Add(&md, "mssql.log_flush_wait_time", v.LogFlushWaitTime, tags, metadata.Counter, metadata.MilliSecond, descMSSQLLogFlushWaitTime)
-		//Add(&md, "mssql.log_flush_write_time_ms", v.LogFlushWriteTimems, tags, metadata.Counter, metadata.MilliSecond, descMSSQLLogFlushWriteTimems)
-		Add(&md, "mssql.log_growths", v.LogGrowths, tags, metadata.Gauge, metadata.Count, descMSSQLLogGrowths)
-		//Add(&md, "mssql.log_pool_cache_misses", v.LogPoolCacheMissesPersec, tags, metadata.Counter, metadata.PerSecond, descMSSQLLogPoolCacheMissesPersec)
-		//Add(&md, "mssql.log_pool_disk_reads", v.LogPoolDiskReadsPersec, tags, metadata.Counter, metadata.PerSecond, descMSSQLLogPoolDiskReadsPersec)
-		//Add(&md, "mssql.log_pool_requests", v.LogPoolRequestsPersec, tags, metadata.Counter, metadata.PerSecond, descMSSQLLogPoolRequestsPersec)
-		Add(&md, "mssql.log_shrinks", v.LogShrinks, tags, metadata.Gauge, metadata.Count, descMSSQLLogShrinks)
-		Add(&md, "mssql.log_truncations", v.LogTruncations, tags, metadata.Gauge, metadata.Count, descMSSQLLogTruncations)
-		Add(&md, "mssql.percent_log_used", v.PercentLogUsed, tags, metadata.Gauge, metadata.Pct, descMSSQLPercentLogUsed)
-		Add(&md, "mssql.repl_pending_xacts", v.ReplPendingXacts, tags, metadata.Gauge, metadata.Count, descMSSQLReplPendingXacts)
-		Add(&md, "mssql.repl_trans_rate", v.ReplTransRate, tags, metadata.Counter, metadata.PerSecond, descMSSQLReplTransRate)
-		Add(&md, "mssql.shrink_data_movement_bytes", v.ShrinkDataMovementBytesPersec, tags, metadata.Counter, metadata.BytesPerSecond, descMSSQLShrinkDataMovementBytesPersec)
-		Add(&md, "mssql.tracked_transactions", v.TrackedtransactionsPersec, tags, metadata.Counter, metadata.PerSecond, descMSSQLTrackedtransactionsPersec)
-		Add(&md, "mssql.transactions", v.TransactionsPersec, tags, metadata.Counter, metadata.PerSecond, descMSSQLTransactionsPersec)
-		Add(&md, "mssql.write_transactions", v.WriteTransactionsPersec, tags, metadata.Counter, metadata.PerSecond, descMSSQLWriteTransactionsPersec)
-
-	}
-	return md, nil
-}
-
-const (
-	descMSSQLActiveTransactions               = "Number of active update transactions for the database."
-	descMSSQLBackupPerRestoreThroughputPersec = "Read/write throughput for backup/restore of a database."
-	descMSSQLBulkCopyRowsPersec               = "Number of rows bulk copied."
-	descMSSQLBulkCopyThroughputPersec         = "KiloBytes bulk copied."
-	descMSSQLCommittableentries               = "The size of the in-memory part of the commit table for the database."
-	descMSSQLDataFilesSizeKB                  = "The cumulative size of all the data files in the database."
-	descMSSQLDBCCLogicalScanBytesPersec       = "Logical read scan rate for DBCC commands."
-	descMSSQLGroupCommitTimePersec            = "Group stall time (microseconds) per second."
-	descMSSQLLogBytesFlushedPersec            = "Total number of log bytes flushed."
-	descMSSQLLogCacheHitRatio                 = "Percentage of log cache reads that were satisfied from the log cache."
-	descMSSQLLogCacheHitRatio_Base            = "Percentage of log cache reads that were satisfied from the log cache."
-	descMSSQLLogCacheReadsPersec              = "Reads performed through the log manager cache."
-	descMSSQLLogFilesSizeKB                   = "The cumulative size of all the log files in the database."
-	descMSSQLLogFilesUsedSizeKB               = "The cumulative used size of all the log files in the database."
-	descMSSQLLogFlushesPersec                 = "Number of log flushes."
-	descMSSQLLogFlushWaitsPersec              = "Number of commits waiting on log flush."
-	descMSSQLLogFlushWaitTime                 = "Total wait time (milliseconds)."
-	descMSSQLLogFlushWriteTimems              = "Milliseconds it took to perform the writes of log flushes completed in the last second."
-	descMSSQLLogGrowths                       = "Total number of log growths for this database."
-	descMSSQLLogPoolCacheMissesPersec         = "Log block cache misses from log pool."
-	descMSSQLLogPoolDiskReadsPersec           = "Log disk reads via log pool."
-	descMSSQLLogPoolRequestsPersec            = "Log block requests performed through log pool."
-	descMSSQLLogShrinks                       = "Total number of log shrinks for this database."
-	descMSSQLLogTruncations                   = "Total number of log truncations for this database."
-	descMSSQLPercentLogUsed                   = "The percent of space in the log that is in use."
-	descMSSQLReplPendingXacts                 = "Number of pending replication transactions in the database."
-	descMSSQLReplTransRate                    = "Replication transaction rate (replicated transactions/sec.)."
-	descMSSQLShrinkDataMovementBytesPersec    = "The rate data is being moved by Autoshrink, DBCC SHRINKDATABASE or SHRINKFILE."
-	descMSSQLTrackedtransactionsPersec        = "Number of committed transactions recorded in the commit table for the database."
-	descMSSQLTransactionsPersec               = "Number of transactions started for the database."
-	descMSSQLWriteTransactionsPersec          = "Number of transactions which wrote to the database in the last second."
-)
-
-type Win32_PerfRawData_MSSQLSERVER_SQLServerDatabases struct {
-	ActiveTransactions               uint64
-	BackupPerRestoreThroughputPersec uint64
-	BulkCopyRowsPersec               uint64
-	BulkCopyThroughputPersec         uint64
-	Committableentries               uint64
-	DataFilesSizeKB                  uint64
-	DBCCLogicalScanBytesPersec       uint64
-	//GroupCommitTimePersec            uint64
-	LogBytesFlushedPersec uint64
-	LogCacheHitRatio      uint64
-	LogCacheHitRatio_Base uint64
-	LogCacheReadsPersec   uint64
-	LogFilesSizeKB        uint64
-	LogFilesUsedSizeKB    uint64
-	LogFlushesPersec      uint64
-	LogFlushWaitsPersec   uint64
-	LogFlushWaitTime      uint64
-	//LogFlushWriteTimems              uint64
-	LogGrowths uint64
-	//LogPoolCacheMissesPersec         uint64
-	//LogPoolDiskReadsPersec uint64
-	//LogPoolRequestsPersec            uint64
-	LogShrinks                    uint64
-	LogTruncations                uint64
-	Name                          string
-	PercentLogUsed                uint64
-	ReplPendingXacts              uint64
-	ReplTransRate                 uint64
-	ShrinkDataMovementBytesPersec uint64
-	TrackedtransactionsPersec     uint64
-	TransactionsPersec            uint64
-	WriteTransactionsPersec       uint64
-}
-
-func c_mssql_replica_db() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_PerfRawData_MSSQLSERVER_SQLServerDatabaseReplica
-	if err := queryWmi(sqlAGDBQuery, &dst); err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		tags := opentsdb.TagSet{"db": v.Name}
-		//see http://technet.microsoft.com/en-us/library/dn135338%28v=sql.110%29.aspx
-		Add(&md, "mssql.replica.bytes_db", v.FileBytesReceivedPersec, opentsdb.TagSet{"db": v.Name, "type": "filestream_received"}, metadata.Counter, metadata.BytesPerSecond, descMSSQLReplicaFileBytesReceivedPersec)
-		Add(&md, "mssql.replica.bytes_db", v.LogBytesReceivedPersec, opentsdb.TagSet{"db": v.Name, "type": "log_received"}, metadata.Counter, metadata.BytesPerSecond, descMSSQLReplicaLogBytesReceivedPersec)
-		Add(&md, "mssql.replica.bytes_db", v.RedoneBytesPersec, opentsdb.TagSet{"db": v.Name, "type": "log_redone"}, metadata.Counter, metadata.BytesPerSecond, descMSSQLReplicaRedoneBytesPersec)
-		Add(&md, "mssql.replica.mirrored_transactions", v.MirroredWriteTransactionsPersec, tags, metadata.Counter, metadata.PerSecond, descMSSQLReplicaMirroredWriteTransactionsPersec)
-		Add(&md, "mssql.replica.redo_blocked", v.RedoblockedPersec, tags, metadata.Counter, metadata.PerSecond, descMSSQLReplicaRedoblockedPersec)
-		Add(&md, "mssql.replica.delay_ack", v.TransactionDelay, opentsdb.TagSet{"db": v.Name}, metadata.Counter, metadata.MilliSecond, descMSSQLReplicaTransactionDelay)
-		Add(&md, "mssql.replica.recovery", v.LogSendQueue*1024, opentsdb.TagSet{"db": v.Name, "type": "sending"}, metadata.Gauge, metadata.Bytes, descMSSQLReplicaLogSendQueue)
-		Add(&md, "mssql.replica.recovery", v.RecoveryQueue*1024, opentsdb.TagSet{"db": v.Name, "type": "received"}, metadata.Gauge, metadata.Bytes, descMSSQLReplicaRecoveryQueue)
-		Add(&md, "mssql.replica.recovery", v.RedoBytesRemaining*1024, opentsdb.TagSet{"db": v.Name, "type": "redo"}, metadata.Gauge, metadata.Bytes, descMSSQLReplicaRedoBytesRemaining)
-		Add(&md, "mssql.replica.recovery", v.TotalLogrequiringundo*1024, opentsdb.TagSet{"db": v.Name, "type": "undo_total"}, metadata.Gauge, metadata.Bytes, descMSSQLReplicaTotalLogrequiringundo)
-		Add(&md, "mssql.replica.recovery", v.Logremainingforundo*1024, opentsdb.TagSet{"db": v.Name, "type": "undo_remaining"}, metadata.Gauge, metadata.Bytes, descMSSQLReplicaLogremainingforundo)
-	}
-	return md, nil
-}
-
-const (
-	descMSSQLReplicaFileBytesReceivedPersec         = "Amount of filestream data received by the availability replica for the database."
-	descMSSQLReplicaLogBytesReceivedPersec          = "Amount of logs received by the availability replica for the database."
-	descMSSQLReplicaLogremainingforundo             = "The amount of log in bytes remaining to finish the undo phase."
-	descMSSQLReplicaLogSendQueue                    = "Amount of logs in bytes that is waiting to be sent to the database replica."
-	descMSSQLReplicaMirroredWriteTransactionsPersec = "Number of transactions which wrote to the mirrored database in the last second, that waited for log to be sent to the mirror."
-	descMSSQLReplicaRecoveryQueue                   = "Total number of hardened log in bytes that is waiting to be redone on the secondary."
-	descMSSQLReplicaRedoblockedPersec               = "Number of times redo gets blocked in the last second."
-	descMSSQLReplicaRedoBytesRemaining              = "The amount of log in bytes remaining to be redone to finish the reverting phase."
-	descMSSQLReplicaRedoneBytesPersec               = "Amount of log records redone in the last second to catch up the database replica."
-	descMSSQLReplicaTotalLogrequiringundo           = "The amount of log in bytes that need to be undone."
-	descMSSQLReplicaTransactionDelay                = "Number of milliseconds transaction termination waited for acknowledgement per second."
-)
-
-type Win32_PerfRawData_MSSQLSERVER_SQLServerDatabaseReplica struct {
-	FileBytesReceivedPersec         uint64
-	LogBytesReceivedPersec          uint64
-	Logremainingforundo             uint64
-	LogSendQueue                    uint64
-	MirroredWriteTransactionsPersec uint64
-	Name                            string
-	RecoveryQueue                   uint64
-	RedoblockedPersec               uint64
-	RedoBytesRemaining              uint64
-	RedoneBytesPersec               uint64
-	TotalLogrequiringundo           uint64
-	TransactionDelay                uint64
-}
-
-func c_mssql_replica_server() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_PerfRawData_MSSQLSERVER_SQLServerAvailabilityReplica
-	if err := queryWmi(sqlAGQuery, &dst); err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		//split name into AvailibilityGroup and Destination. Name is in 'Group:Destination' format
-		s := strings.Split(v.Name, ":")
-		if len(s) != 2 {
-			return nil, fmt.Errorf("Invalid Availibility Group Name: '%s'", v.Name)
-		}
-		destination := strings.ToLower(s[1])
-		//see http://technet.microsoft.com/en-us/library/ff878472(v=sql.110).aspx
-		//also https://livedemo.customers.na.apm.ibmserviceengage.com/help/index.jsp?topic=%2Fcom.ibm.koq.doc%2Fattr_koqadbst.htm
-		Add(&md, "mssql.replica.bytes_ag", v.BytesReceivedfromReplicaPersec, opentsdb.TagSet{"group": s[0], "destination": destination, "type": "received"}, metadata.Counter, metadata.BytesPerSecond, descMSSQLReplicaBytesReceivedfromReplicaPersec)
-		Add(&md, "mssql.replica.bytes_ag", v.BytesSenttoReplicaPersec, opentsdb.TagSet{"group": s[0], "destination": destination, "type": "sent_replica"}, metadata.Counter, metadata.BytesPerSecond, descMSSQLReplicaBytesSenttoReplicaPersec)
-		Add(&md, "mssql.replica.bytes_ag", v.BytesSenttoTransportPersec, opentsdb.TagSet{"group": s[0], "destination": destination, "type": "sent_transport"}, metadata.Counter, metadata.BytesPerSecond, descMSSQLReplicaBytesSenttoTransportPersec)
-		Add(&md, "mssql.replica.delay_flow", v.FlowControlTimemsPersec, opentsdb.TagSet{"group": s[0], "destination": destination}, metadata.Counter, metadata.MilliSecond, descMSSQLReplicaFlowControlTimemsPersec)
-		Add(&md, "mssql.replica.messages", v.FlowControlPersec, opentsdb.TagSet{"group": s[0], "destination": destination, "type": "flow_control"}, metadata.Counter, metadata.PerSecond, descMSSQLReplicaFlowControlPersec)
-		Add(&md, "mssql.replica.messages", v.ReceivesfromReplicaPersec, opentsdb.TagSet{"group": s[0], "destination": destination, "type": "received"}, metadata.Counter, metadata.PerSecond, descMSSQLReplicaReceivesfromReplicaPersec)
-		Add(&md, "mssql.replica.messages", v.ResentMessagesPersec, opentsdb.TagSet{"group": s[0], "destination": destination, "type": "resent"}, metadata.Counter, metadata.PerSecond, descMSSQLReplicaResentMessagesPersec)
-		Add(&md, "mssql.replica.messages", v.SendstoReplicaPersec, opentsdb.TagSet{"group": s[0], "destination": destination, "type": "sent_replica"}, metadata.Counter, metadata.PerSecond, descMSSQLReplicaSendstoReplicaPersec)
-		Add(&md, "mssql.replica.messages", v.SendstoTransportPersec, opentsdb.TagSet{"group": s[0], "destination": destination, "type": "sent_transport"}, metadata.Counter, metadata.PerSecond, descMSSQLReplicaSendstoTransportPersec)
-
-	}
-	return md, nil
-}
-
-const (
-	descMSSQLReplicaBytesReceivedfromReplicaPersec = "Total bytes receieved from the availability replica."
-	descMSSQLReplicaBytesSenttoReplicaPersec       = "Total bytes sent to the availabilty replica."
-	descMSSQLReplicaBytesSenttoTransportPersec     = "Total bytes sent to transport for the availabilty replica."
-	descMSSQLReplicaFlowControlPersec              = "Number of flow control initiated in the last second."
-	descMSSQLReplicaFlowControlTimemsPersec        = "Time in milliseconds messages waited on flow control in the last second."
-	descMSSQLReplicaReceivesfromReplicaPersec      = "Total receives from the availability replica."
-	descMSSQLReplicaResentMessagesPersec           = "Number of messages being resent in the last second."
-	descMSSQLReplicaSendstoReplicaPersec           = "Total sends to the availability replica."
-	descMSSQLReplicaSendstoTransportPersec         = "Total sends to transport for the availability replica."
-)
-
-type Win32_PerfRawData_MSSQLSERVER_SQLServerAvailabilityReplica struct {
-	BytesReceivedfromReplicaPersec uint64
-	BytesSenttoReplicaPersec       uint64
-	BytesSenttoTransportPersec     uint64
-	FlowControlPersec              uint64
-	FlowControlTimemsPersec        uint64
-	Name                           string
-	ReceivesfromReplicaPersec      uint64
-	ResentMessagesPersec           uint64
-	SendstoReplicaPersec           uint64
-	SendstoTransportPersec         uint64
-}
-
-func c_mssql_replica_votes() (opentsdb.MultiDataPoint, error) {
-	var dst []MSCluster_Node
-	if err := queryWmiNamespace(sqlAGVotes, &dst, rootMSCluster); err != nil {
-		return nil, err
-	}
-
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		Add(&md, "mssql.replica.votes", v.NodeWeight, opentsdb.TagSet{"cluster": sqlClusterName, "type": "standard"}, metadata.Gauge, metadata.Count, descMSSQLReplicaNodeWeight)
-		Add(&md, "mssql.replica.votes", v.DynamicWeight, opentsdb.TagSet{"cluster": sqlClusterName, "type": "dynamic"}, metadata.Gauge, metadata.Count, descMSSQLReplicaDynamicWeight)
-		Add(&md, "mssql.replica.cluster_state", v.State, opentsdb.TagSet{"cluster": sqlClusterName}, metadata.Gauge, metadata.StatusCode, descMSSQLReplicaClusterState)
-	}
-	return md, nil
-}
-
-const (
-	descMSSQLReplicaNodeWeight    = "The current vote weight of the node."
-	descMSSQLReplicaDynamicWeight = "The vote weight of the node when adjusted by the dynamic quorum feature."
-	descMSSQLReplicaClusterState  = "StateUnknown (-1), Up (0), Down (1), Paused (2), Joining (3)."
-)
-
-type MSCluster_Node struct {
-	Name          string
-	NodeWeight    uint32
-	DynamicWeight uint32
-	State         uint32
-}
-
-type MSCluster_Cluster struct {
-	Name string
-}
-
-func c_mssql_replica_resources() (opentsdb.MultiDataPoint, error) {
-	var dst []MSCluster_Resource
-	//Only report metrics for resources owned by this node
-	var q = wmi.CreateQuery(&dst, fmt.Sprintf("WHERE OwnerNode = '%s'", util.Hostname))
-	if err := queryWmiNamespace(q, &dst, rootMSCluster); err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		Add(&md, "mssql.replica.resource_state", v.State, opentsdb.TagSet{"group": v.OwnerGroup, "type": v.Type, "name": v.Name}, metadata.Gauge, metadata.StatusCode, descMSSQLReplicaResourceState)
-	}
-	return md, nil
-}
-
-const (
-	descMSSQLReplicaResourceState = "StateUnknown (-1), TBD (0), Initializing (1), Online (2), Offline (3), Failed(4), Pending(128), Online Pending (129), Offline Pending (130)."
-)
-
-type MSCluster_Resource struct {
-	Name       string
-	OwnerGroup string
-	OwnerNode  string
-	Type       string
-	State      uint32
-}
diff --git a/cmd/scollector/collectors/system_windows.go b/cmd/scollector/collectors/system_windows.go
deleted file mode 100644
index 5fd70c8..0000000
--- a/cmd/scollector/collectors/system_windows.go
+++ /dev/null
@@ -1,74 +0,0 @@
-package collectors
-
-import (
-	"bosun.org/_third_party/github.com/StackExchange/wmi"
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-)
-
-func init() {
-	collectors = append(collectors, &IntervalCollector{F: c_system_windows})
-	collectors = append(collectors, &IntervalCollector{F: c_windows_process_total})
-}
-
-func c_system_windows() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_PerfRawData_PerfOS_System
-	var q = wmi.CreateQuery(&dst, "")
-	err := queryWmi(q, &dst)
-	if err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		//see http://microsoft.public.win32.programmer.wmi.narkive.com/09kqthVC/lastbootuptime
-		var uptime = (v.Timestamp_Object - v.SystemUpTime) / v.Frequency_Object
-		Add(&md, "win.system.context_switches", v.ContextSwitchesPersec, nil, metadata.Counter, metadata.ContextSwitch, descWinSystemContextSwitchesPersec)
-		Add(&md, "win.system.exceptions", v.ExceptionDispatchesPersec, nil, metadata.Counter, metadata.PerSecond, descWinSystemExceptionDispatchesPersec)
-		Add(&md, "win.system.cpu_queue", v.ProcessorQueueLength, nil, metadata.Gauge, metadata.Count, descWinSystemProcessorQueueLength)
-		Add(&md, "win.system.syscall", v.SystemCallsPersec, nil, metadata.Counter, metadata.Syscall, descWinSystemSystemCallsPersec)
-		Add(&md, "win.system.threads", v.Threads, nil, metadata.Gauge, metadata.Count, descWinSystemThreads)
-		Add(&md, "win.system.uptime", uptime, nil, metadata.Gauge, metadata.Second, osSystemUptimeDesc)
-		Add(&md, "win.system.processes", v.Processes, nil, metadata.Gauge, metadata.Count, descWinSystemProcesses)
-		Add(&md, osSystemUptime, uptime, nil, metadata.Gauge, metadata.Second, osSystemUptimeDesc)
-	}
-	return md, nil
-}
-
-const (
-	descWinSystemContextSwitchesPersec     = "Context Switches/sec is the combined rate at which all processors on the computer are switched from one thread to another.  Context switches occur when a running thread voluntarily relinquishes the processor, is preempted by a higher priority ready thread, or switches between user-mode and privileged (kernel) mode to use an Executive or subsystem service.  It is the sum of Thread\\Context Switches/sec for all threads running on all processors in the computer and is measured in numbers of switches."
-	descWinSystemExceptionDispatchesPersec = "Exception Dispatches/sec is the rate, in incidents per second, at which exceptions were dispatched by the system."
-	descWinSystemProcesses                 = "The number of processes running on the system."
-	descWinSystemProcessorQueueLength      = "Processor Queue Length is the number of threads in the processor queue.  Unlike the disk counters, this counter shows ready threads only, not threads that are running.  There is a single queue for processor time even on computers with multiple processors. Therefore, if a computer has multiple processors, you need to divide this value by the number of processors servicing the workload. A sustained processor queue of less than 10 threads per processor is normally acceptable, dependent on the workload."
-	descWinSystemSystemCallsPersec         = "System Calls/sec is the combined rate of calls to operating system service routines by all processes running on the computer. These routines perform all of the basic scheduling and synchronization of activities on the computer, and provide access to non-graphic devices, memory management, and name space management."
-	descWinSystemThreads                   = "The number of threads running on the system."
-)
-
-type Win32_PerfRawData_PerfOS_System struct {
-	ContextSwitchesPersec     uint32
-	ExceptionDispatchesPersec uint32
-	Frequency_Object          uint64
-	Processes                 uint32
-	ProcessorQueueLength      uint32
-	SystemCallsPersec         uint32
-	SystemUpTime              uint64
-	Threads                   uint32
-	Timestamp_Object          uint64
-}
-
-func c_windows_process_total() (opentsdb.MultiDataPoint, error) {
-	var dst []Win32_PerfRawData_PerfProc_Process
-	var q = wmi.CreateQuery(&dst, `WHERE Name = '_Total'`)
-	err := queryWmi(q, &dst)
-	if err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	for _, v := range dst {
-		Add(&md, "win.system.handle_count", v.HandleCount, nil, metadata.Gauge, metadata.Count, descWinSystemHandle_count)
-	}
-	return md, nil
-}
-
-const (
-	descWinSystemHandle_count = "Total number of handles open across all threads."
-)
diff --git a/cmd/scollector/collectors/vmstat_darwin.go b/cmd/scollector/collectors/vmstat_darwin.go
deleted file mode 100644
index c16c130..0000000
--- a/cmd/scollector/collectors/vmstat_darwin.go
+++ /dev/null
@@ -1,61 +0,0 @@
-package collectors
-
-import (
-	"strconv"
-	"strings"
-
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-	"bosun.org/util"
-)
-
-func init() {
-	collectors = append(collectors, &IntervalCollector{F: c_vmstat_darwin})
-}
-
-func c_vmstat_darwin() (opentsdb.MultiDataPoint, error) {
-	var md opentsdb.MultiDataPoint
-	var free float64
-	util.ReadCommand(func(line string) error {
-		if line == "" || strings.HasPrefix(line, "Object cache") || strings.HasPrefix(line, "Mach Virtual") {
-			return nil
-		}
-		fields := strings.Split(line, ":")
-		if len(fields) < 2 {
-			return nil
-		}
-		value, err := strconv.ParseFloat(strings.TrimSpace(fields[1]), 64)
-		if err != nil {
-			return nil
-		}
-		if strings.HasPrefix(fields[0], "Pages") {
-			name := strings.TrimSpace(fields[0])
-			name = strings.Replace(name, "Pages ", "", -1)
-			name = strings.Replace(name, " ", "", -1)
-			Add(&md, "darwin.mem.vm.4kpages."+name, value, nil, metadata.Unknown, metadata.None, "")
-			if name == "free" {
-				free = value * 4096
-				Add(&md, osMemFree, free, nil, metadata.Gauge, metadata.Bytes, osMemFreeDesc)
-			}
-		} else if fields[0] == "Pageins" {
-			Add(&md, "darwin.mem.vm.pageins", value, nil, metadata.Counter, metadata.None, "")
-		} else if fields[0] == "Pageouts" {
-			Add(&md, "darwin.mem.vm.pageouts", value, nil, metadata.Counter, metadata.None, "")
-		}
-		return nil
-	}, "vm_stat")
-	util.ReadCommand(func(line string) error {
-		total, _ := strconv.ParseFloat(line, 64)
-		if total == 0 {
-			return nil
-		}
-		Add(&md, osMemTotal, total, nil, metadata.Gauge, metadata.Bytes, osMemTotalDesc)
-		if free == 0 {
-			return nil
-		}
-		Add(&md, osMemUsed, total-free, nil, metadata.Gauge, metadata.Bytes, osMemUsedDesc)
-		Add(&md, osMemPctFree, free/total, nil, metadata.Gauge, metadata.Pct, osMemPctFreeDesc)
-		return nil
-	}, "sysctl", "-n", "hw.memsize")
-	return md, nil
-}
diff --git a/cmd/scollector/collectors/vsphere.go b/cmd/scollector/collectors/vsphere.go
deleted file mode 100644
index 6368f69..0000000
--- a/cmd/scollector/collectors/vsphere.go
+++ /dev/null
@@ -1,307 +0,0 @@
-package collectors
-
-import (
-	"bytes"
-	"encoding/xml"
-	"fmt"
-	"io"
-	"strconv"
-
-	"bosun.org/metadata"
-	"bosun.org/opentsdb"
-	"bosun.org/util"
-	"bosun.org/vsphere"
-)
-
-// Vsphere registers a vSphere collector.
-func Vsphere(user, pwd, host string) error {
-	if host == "" || user == "" || pwd == "" {
-		return fmt.Errorf("empty Host, User, or Password in Vsphere")
-	}
-	collectors = append(collectors, &IntervalCollector{
-		F: func() (opentsdb.MultiDataPoint, error) {
-			return c_vsphere(user, pwd, host)
-		},
-		name: fmt.Sprintf("vsphere-%s", host),
-	})
-	return nil
-}
-
-func c_vsphere(user, pwd, host string) (opentsdb.MultiDataPoint, error) {
-	v, err := vsphere.Connect(host, user, pwd)
-	if err != nil {
-		return nil, err
-	}
-	var md opentsdb.MultiDataPoint
-	if err := vsphereHost(v, &md); err != nil {
-		return nil, err
-	}
-	if err := vsphereDatastore(v, &md); err != nil {
-		return nil, err
-	}
-	if err := vsphereGuest(util.Clean(host), v, &md); err != nil {
-		return nil, err
-	}
-	return md, nil
-}
-
-func vsphereDatastore(v *vsphere.Vsphere, md *opentsdb.MultiDataPoint) error {
-	res, err := v.Info("Datastore", []string{
-		"name",
-		"summary.capacity",
-		"summary.freeSpace",
-	})
-	if err != nil {
-		return err
-	}
-	var Error error
-	for _, r := range res {
-		var name string
-		for _, p := range r.Props {
-			if p.Name == "name" {
-				name = p.Val.Inner
-				break
-			}
-		}
-		if name == "" {
-			Error = fmt.Errorf("vsphere: empty name")
-			continue
-		}
-		tags := opentsdb.TagSet{
-			"disk": name,
-			"host": "",
-		}
-		var diskTotal, diskFree int64
-		for _, p := range r.Props {
-			switch p.Val.Type {
-			case "xsd:long", "xsd:int", "xsd:short":
-				i, err := strconv.ParseInt(p.Val.Inner, 10, 64)
-				if err != nil {
-					Error = fmt.Errorf("vsphere bad integer: %s", p.Val.Inner)
-					continue
-				}
-				switch p.Name {
-				case "summary.capacity":
-					Add(md, osDiskTotal, i, tags, metadata.Gauge, metadata.Bytes, "")
-					Add(md, "vsphere.disk.space_total", i, tags, metadata.Gauge, metadata.Bytes, "")
-					diskTotal = i
-				case "summary.freeSpace":
-					Add(md, "vsphere.disk.space_free", i, tags, metadata.Gauge, metadata.Bytes, "")
-					diskFree = i
-				}
-			}
-		}
-		if diskTotal > 0 && diskFree > 0 {
-			diskUsed := diskTotal - diskFree
-			Add(md, "vsphere.disk.space_used", diskUsed, tags, metadata.Gauge, metadata.Bytes, "")
-			Add(md, osDiskUsed, diskUsed, tags, metadata.Gauge, metadata.Bytes, "")
-			Add(md, osDiskPctFree, float64(diskFree)/float64(diskTotal)*100, tags, metadata.Gauge, metadata.Pct, "")
-		}
-	}
-	return Error
-}
-
-type HostSystemIdentificationInfo struct {
-	IdentiferValue string `xml:"identifierValue"`
-	IdentiferType  struct {
-		Label   string `xml:"label"`
-		Summary string `xml:"summary"`
-		Key     string `xml:"key"`
-	} `xml:"identifierType"`
-}
-
-func vsphereHost(v *vsphere.Vsphere, md *opentsdb.MultiDataPoint) error {
-	res, err := v.Info("HostSystem", []string{
-		"name",
-		"summary.hardware.cpuMhz",
-		"summary.hardware.memorySize", // bytes
-		"summary.hardware.numCpuCores",
-		"summary.hardware.numCpuCores",
-		"summary.quickStats.overallCpuUsage",    // MHz
-		"summary.quickStats.overallMemoryUsage", // MB
-		"summary.hardware.otherIdentifyingInfo",
-		"summary.hardware.model",
-	})
-	if err != nil {
-		return err
-	}
-	var Error error
-	for _, r := range res {
-		var name string
-		for _, p := range r.Props {
-			if p.Name == "name" {
-				name = util.Clean(p.Val.Inner)
-				break
-			}
-		}
-		if name == "" {
-			Error = fmt.Errorf("vsphere: empty name")
-			continue
-		}
-		tags := opentsdb.TagSet{
-			"host": name,
-		}
-		var memTotal, memUsed int64
-		var cpuMhz, cpuCores, cpuUse int64
-		for _, p := range r.Props {
-			switch p.Val.Type {
-			case "xsd:long", "xsd:int", "xsd:short":
-				i, err := strconv.ParseInt(p.Val.Inner, 10, 64)
-				if err != nil {
-					Error = fmt.Errorf("vsphere bad integer: %s", p.Val.Inner)
-					continue
-				}
-				switch p.Name {
-				case "summary.hardware.memorySize":
-					Add(md, osMemTotal, i, tags, metadata.Gauge, metadata.Bytes, osMemTotalDesc)
-					memTotal = i
-				case "summary.quickStats.overallMemoryUsage":
-					memUsed = i * 1024 * 1024
-					Add(md, osMemUsed, memUsed, tags, metadata.Gauge, metadata.Bytes, osMemUsedDesc)
-				case "summary.hardware.cpuMhz":
-					cpuMhz = i
-				case "summary.quickStats.overallCpuUsage":
-					cpuUse = i
-					Add(md, "vsphere.cpu", cpuUse, opentsdb.TagSet{"host": name, "type": "usage"}, metadata.Gauge, metadata.MHz, "")
-				case "summary.hardware.numCpuCores":
-					cpuCores = i
-				}
-			case "xsd:string":
-				switch p.Name {
-				case "summary.hardware.model":
-					metadata.AddMeta("", tags, "model", p.Val.Inner, false)
-				}
-			case "ArrayOfHostSystemIdentificationInfo":
-				switch p.Name {
-				case "summary.hardware.otherIdentifyingInfo":
-					d := xml.NewDecoder(bytes.NewBufferString(p.Val.Inner))
-					// Blade servers may have multiple service tags. We want to use the last one.
-					var lastServiceTag string
-					for {
-						var t HostSystemIdentificationInfo
-						err := d.Decode(&t)
-						if err == io.EOF {
-							break
-						}
-						if err != nil {
-							return err
-						}
-						if t.IdentiferType.Key == "ServiceTag" {
-							lastServiceTag = t.IdentiferValue
-						}
-					}
-					if lastServiceTag != "" {
-						metadata.AddMeta("", tags, "serialNumber", lastServiceTag, false)
-					}
-				}
-			}
-		}
-		if memTotal > 0 && memUsed > 0 {
-			memFree := memTotal - memUsed
-			Add(md, osMemFree, memFree, tags, metadata.Gauge, metadata.Bytes, osMemFreeDesc)
-			Add(md, osMemPctFree, float64(memFree)/float64(memTotal)*100, tags, metadata.Gauge, metadata.Pct, osMemPctFreeDesc)
-		}
-		if cpuMhz > 0 && cpuUse > 0 && cpuCores > 0 {
-			cpuTotal := cpuMhz * cpuCores
-			Add(md, "vsphere.cpu", cpuTotal-cpuUse, opentsdb.TagSet{"host": name, "type": "idle"}, metadata.Gauge, metadata.MHz, "")
-			Add(md, "vsphere.cpu.pct", float64(cpuUse)/float64(cpuTotal)*100, tags, metadata.Gauge, metadata.Pct, "")
-		}
-	}
-	return Error
-}
-
-func vsphereGuest(vsphereHost string, v *vsphere.Vsphere, md *opentsdb.MultiDataPoint) error {
-	hres, err := v.Info("HostSystem", []string{
-		"name",
-	})
-	if err != nil {
-		return err
-	}
-	//Fetch host ids so we can set the hypervisor as metadata
-	hosts := make(map[string]string)
-	for _, r := range hres {
-		for _, p := range r.Props {
-			if p.Name == "name" {
-				hosts[r.ID] = util.Clean(p.Val.Inner)
-				break
-			}
-		}
-	}
-	res, err := v.Info("VirtualMachine", []string{
-		"name",
-		"runtime.host",
-		"config.hardware.memoryMB",
-		"config.hardware.numCPU",
-		"summary.quickStats.balloonedMemory",
-		"summary.quickStats.guestMemoryUsage",
-		"summary.quickStats.hostMemoryUsage",
-		"summary.quickStats.overallCpuUsage",
-	})
-	if err != nil {
-		return err
-	}
-	var Error error
-	for _, r := range res {
-		var name string
-		for _, p := range r.Props {
-			if p.Name == "name" {
-				name = util.Clean(p.Val.Inner)
-				break
-			}
-		}
-		if name == "" {
-			Error = fmt.Errorf("vsphere: empty name")
-			continue
-		}
-		tags := opentsdb.TagSet{
-			"host": vsphereHost, "guest": name,
-		}
-		var memTotal, memUsed int64
-		for _, p := range r.Props {
-			switch p.Val.Type {
-			case "xsd:long", "xsd:int", "xsd:short":
-				i, err := strconv.ParseInt(p.Val.Inner, 10, 64)
-				if err != nil {
-					Error = fmt.Errorf("vsphere bad integer: %s", p.Val.Inner)
-					continue
-				}
-				switch p.Name {
-				case "config.hardware.memoryMB":
-					memTotal = i * 1024 * 1024
-					Add(md, "vsphere.guest.mem.total", memTotal, tags, metadata.Gauge, metadata.Bytes, "")
-				case "summary.quickStats.hostMemoryUsage":
-					Add(md, "vsphere.guest.mem.host", i*1024*1024, tags, metadata.Gauge, metadata.Bytes, descVsphereGuestMemHost)
-				case "summary.quickStats.guestMemoryUsage":
-					memUsed = i * 1024 * 1024
-					Add(md, "vsphere.guest.mem.used", memUsed, tags, metadata.Gauge, metadata.Bytes, descVsphereGuestMemUsed)
-				case "summary.quickStats.overallCpuUsage":
-					Add(md, "vsphere.guest.cpu", i, tags, metadata.Gauge, metadata.MHz, "")
-				case "summary.quickStats.balloonedMemory":
-					Add(md, "vsphere.guest.mem.ballooned", i*1024*1024, tags, metadata.Gauge, metadata.Bytes, descVsphereGuestMemBallooned)
-				case "config.hardware.numCPU":
-					Add(md, "vsphere.guest.num_cpu", i, tags, metadata.Gauge, metadata.Gauge, "")
-				}
-			case "HostSystem":
-				s := p.Val.Inner
-				switch p.Name {
-				case "runtime.host":
-					if v, ok := hosts[s]; ok {
-						metadata.AddMeta("", opentsdb.TagSet{"host": name}, "hypervisor", v, false)
-					}
-				}
-			}
-		}
-		if memTotal > 0 && memUsed > 0 {
-			memFree := memTotal - memUsed
-			Add(md, "vsphere.guest.mem.free", memFree, tags, metadata.Gauge, metadata.Bytes, "")
-			Add(md, "vsphere.guest.mem.percent_free", float64(memFree)/float64(memTotal)*100, tags, metadata.Gauge, metadata.Pct, "")
-		}
-	}
-	return Error
-}
-
-const (
-	descVsphereGuestMemHost      = "Host memory utilization, also known as consumed host memory. Includes the overhead memory of the VM."
-	descVsphereGuestMemUsed      = "Guest memory utilization statistics, also known as active guest memory."
-	descVsphereGuestMemBallooned = "The size of the balloon driver in the VM. The host will inflate the balloon driver to reclaim physical memory from the VM. This is a sign that there is memory pressure on the host."
-)
diff --git a/cmd/scollector/collectors/wmi_windows.go b/cmd/scollector/collectors/wmi_windows.go
deleted file mode 100644
index 4a3359a..0000000
--- a/cmd/scollector/collectors/wmi_windows.go
+++ /dev/null
@@ -1,29 +0,0 @@
-package collectors
-
-import "bosun.org/_third_party/github.com/StackExchange/wmi"
-
-func queryWmi(query string, dst interface{}) error {
-	return queryWmiNamespace(query, dst, "")
-}
-
-func queryWmiNamespace(query string, dst interface{}, namespace string) error {
-	return wmi.QueryNamespace(query, dst, namespace)
-}
-
-func wmiInit(c *IntervalCollector, dst func() interface{}, where string, query *string) func() {
-	return func() {
-		*query = wmi.CreateQuery(dst(), where)
-		c.Enable = func() bool {
-			return queryWmi(*query, dst()) == nil
-		}
-	}
-}
-
-func wmiInitNamespace(c *IntervalCollector, dst func() interface{}, where string, query *string, namespace string) func() {
-	return func() {
-		*query = wmi.CreateQuery(dst(), where)
-		c.Enable = func() bool {
-			return queryWmiNamespace(*query, dst(), namespace) == nil
-		}
-	}
-}
diff --git a/cmd/scollector/doc.go b/cmd/scollector/doc.go
index fdee950..c3ce991 100644
--- a/cmd/scollector/doc.go
+++ b/cmd/scollector/doc.go
@@ -83,7 +83,7 @@ scollector's log.
 
 Configuration File
 
-If scollector.conf exists in the same directory as the scollector
+If scollector.toml exists in the same directory as the scollector
 executable or is specified via the -conf="" flag, it's content
 will be used to set configuration flags. The format is toml
 (https://github.com/toml-lang/toml/blob/master/versions/en/toml-v0.2.0.md).
diff --git a/cmd/scollector/main.go b/cmd/scollector/main.go
index d74b55a..326ea75 100644
--- a/cmd/scollector/main.go
+++ b/cmd/scollector/main.go
@@ -64,9 +64,9 @@ type Conf struct {
 	// the specified community.
 	KeepalivedCommunity string
 	HAProxy             []HAProxy
-	SNMP                []SNMP
+//	SNMP                []SNMP
 	ICMP                []ICMP
-	Vsphere             []Vsphere
+//	Vsphere             []Vsphere
 	AWS                 []AWS
 	Process             []collectors.ProcessParams
 	ProcessDotNet       []ProcessDotNet
@@ -88,11 +88,11 @@ type ICMP struct {
 	Host string
 }
 
-type Vsphere struct {
-	Host     string
-	User     string
-	Password string
-}
+//type Vsphere struct {
+//	Host     string
+//	User     string
+//	Password string
+//}
 
 type AWS struct {
 	AccessKey string
@@ -100,10 +100,10 @@ type AWS struct {
 	Region    string
 }
 
-type SNMP struct {
-	Community string
-	Host      string
-}
+//type SNMP struct {
+//	Community string
+//	Host      string
+//}
 
 type ProcessDotNet struct {
 	Name string
@@ -138,10 +138,13 @@ func readConf() *Conf {
 		}
 	} else {
 		defer f.Close()
-		_, err := toml.DecodeReader(f, conf)
+		md, err := toml.DecodeReader(f, conf)
 		if err != nil {
 			slog.Fatal(err)
 		}
+		if u := md.Undecoded(); len(u) > 0 {
+			slog.Fatalf("extra keys in %s: %v", loc, u)
+		}
 	}
 	return conf
 }
@@ -198,18 +201,18 @@ func main() {
 			collectors.HAProxy(h.User, h.Password, i.Tier, i.URL)
 		}
 	}
-	for _, s := range conf.SNMP {
-		check(collectors.SNMP(s.Community, s.Host))
-	}
+//	for _, s := range conf.SNMP {
+//		check(collectors.SNMP(s.Community, s.Host))
+//	}
 	for _, i := range conf.ICMP {
 		check(collectors.ICMP(i.Host))
 	}
 	for _, a := range conf.AWS {
 		check(collectors.AWS(a.AccessKey, a.SecretKey, a.Region))
 	}
-	for _, v := range conf.Vsphere {
-		check(collectors.Vsphere(v.User, v.Password, v.Host))
-	}
+//	for _, v := range conf.Vsphere {
+//		check(collectors.Vsphere(v.User, v.Password, v.Host))
+//	}
 	for _, p := range conf.Process {
 		check(collectors.AddProcessConfig(p))
 	}
@@ -383,18 +386,18 @@ func toToml(fname string) {
 			c.Filter = strings.Split(v, ",")
 		case "coldir":
 			c.ColDir = v
-		case "snmp":
-			for _, s := range strings.Split(v, ",") {
-				sp := strings.Split(s, "@")
-				if len(sp) != 2 {
-					slog.Fatal("invalid snmp string:", v)
-				}
-				c.SNMP = append(c.SNMP, SNMP{
-					Community: sp[0],
-					Host:      sp[1],
-				})
-			}
-		case "icmp":
+//		case "snmp":
+//			for _, s := range strings.Split(v, ",") {
+//				sp := strings.Split(s, "@")
+//				if len(sp) != 2 {
+//					slog.Fatal("invalid snmp string:", v)
+//				}
+//				c.SNMP = append(c.SNMP, SNMP{
+//					Community: sp[0],
+//					Host:      sp[1],
+//				})
+//			}
+//		case "icmp":
 			c.ICMP = append(c.ICMP, ICMP{v})
 
 		case "haproxy":
@@ -448,28 +451,28 @@ func toToml(fname string) {
 					Region:    region,
 				})
 			}
-		case "vsphere":
-			for _, s := range strings.Split(v, ",") {
-				sp := strings.SplitN(s, ":", 2)
-				if len(sp) != 2 {
-					slog.Fatal("invalid vsphere string:", v)
-				}
-				user := sp[0]
-				idx := strings.LastIndex(sp[1], "@")
-				if idx == -1 {
-					slog.Fatal("invalid vsphere string:", v)
-				}
-				pwd := sp[1][:idx]
-				host := sp[1][idx+1:]
-				if len(user) == 0 || len(pwd) == 0 || len(host) == 0 {
-					slog.Fatal("invalid vsphere string:", v)
-				}
-				c.Vsphere = append(c.Vsphere, Vsphere{
-					User:     user,
-					Password: pwd,
-					Host:     host,
-				})
-			}
+//		case "vsphere":
+//			for _, s := range strings.Split(v, ",") {
+//				sp := strings.SplitN(s, ":", 2)
+//				if len(sp) != 2 {
+//					slog.Fatal("invalid vsphere string:", v)
+//				}
+//				user := sp[0]
+//				idx := strings.LastIndex(sp[1], "@")
+//				if idx == -1 {
+//					slog.Fatal("invalid vsphere string:", v)
+//				}
+//				pwd := sp[1][:idx]
+//				host := sp[1][idx+1:]
+//				if len(user) == 0 || len(pwd) == 0 || len(host) == 0 {
+//					slog.Fatal("invalid vsphere string:", v)
+//				}
+//				c.Vsphere = append(c.Vsphere, Vsphere{
+//					User:     user,
+//					Password: pwd,
+//					Host:     host,
+//				})
+//			}
 		case "freq":
 			freq, err := strconv.Atoi(v)
 			if err != nil {
diff --git a/cmd/tsdbrelay/main.go b/cmd/tsdbrelay/main.go
index 3dfc217..773c7cf 100644
--- a/cmd/tsdbrelay/main.go
+++ b/cmd/tsdbrelay/main.go
@@ -2,19 +2,33 @@ package main
 
 import (
 	"bytes"
+	"compress/gzip"
+	"encoding/json"
 	"flag"
 	"io"
 	"log"
 	"net/http"
+	"net/http/httptest"
 	"net/http/httputil"
 	"net/url"
+
+	"bosun.org/cmd/tsdbrelay/denormalize"
+	"bosun.org/opentsdb"
 )
 
 var (
-	listenAddr  = flag.String("l", ":4242", "Listen address.")
-	bosunServer = flag.String("b", "bosun", "Target Bosun server. Can specify port with host:port.")
-	tsdbServer  = flag.String("t", "", "Target OpenTSDB server. Can specify port with host:port.")
-	logVerbose  = flag.Bool("v", false, "enable verbose logging")
+	listenAddr    = flag.String("l", ":4242", "Listen address.")
+	bosunServer   = flag.String("b", "bosun", "Target Bosun server. Can specify port with host:port.")
+	tsdbServer    = flag.String("t", "", "Target OpenTSDB server. Can specify port with host:port.")
+	logVerbose    = flag.Bool("v", false, "enable verbose logging")
+	toDenormalize = flag.String("denormalize", "", "List of metrics to denormalize. Comma seperated list of `metric__tagname__tagname` rules. Will be translated to `___metric__tagvalue__tagvalue`")
+)
+
+var (
+	tsdbPutURL    string
+	bosunIndexURL string
+
+	denormalizationRules map[string]*denormalize.DenormalizationRule
 )
 
 func main() {
@@ -25,14 +39,35 @@ func main() {
 	log.Println("listen on", *listenAddr)
 	log.Println("relay to bosun at", *bosunServer)
 	log.Println("relay to tsdb at", *tsdbServer)
+	if *toDenormalize != "" {
+		var err error
+		denormalizationRules, err = denormalize.ParseDenormalizationRules(*toDenormalize)
+		if err != nil {
+			log.Fatal(err)
+		}
+	}
+
 	tsdbURL := &url.URL{
 		Scheme: "http",
 		Host:   *tsdbServer,
 	}
+
+	u := url.URL{
+		Scheme: "http",
+		Host:   *tsdbServer,
+		Path:   "/api/put",
+	}
+	tsdbPutURL = u.String()
 	bosunURL := &url.URL{
 		Scheme: "http",
 		Host:   *bosunServer,
 	}
+	u = url.URL{
+		Scheme: "http",
+		Host:   *bosunServer,
+		Path:   "/api/index",
+	}
+	bosunIndexURL = u.String()
 	tsdbProxy := httputil.NewSingleHostReverseProxy(tsdbURL)
 	http.Handle("/api/put", &relayProxy{
 		ReverseProxy: tsdbProxy,
@@ -74,6 +109,10 @@ func (rw *relayWriter) WriteHeader(code int) {
 }
 
 func (rp *relayProxy) ServeHTTP(responseWriter http.ResponseWriter, r *http.Request) {
+	rp.relayRequest(responseWriter, r, true)
+}
+
+func (rp *relayProxy) relayRequest(responseWriter http.ResponseWriter, r *http.Request, parse bool) {
 	reader := &passthru{ReadCloser: r.Body}
 	r.Body = reader
 	w := &relayWriter{ResponseWriter: responseWriter}
@@ -86,12 +125,7 @@ func (rp *relayProxy) ServeHTTP(responseWriter http.ResponseWriter, r *http.Requ
 	// Run in a separate go routine so we can end the source's request.
 	go func() {
 		body := bytes.NewBuffer(reader.buf.Bytes())
-		u := &url.URL{
-			Scheme: "http",
-			Host:   *bosunServer,
-			Path:   "/api/index",
-		}
-		req, err := http.NewRequest(r.Method, u.String(), body)
+		req, err := http.NewRequest(r.Method, bosunIndexURL, body)
 		if err != nil {
 			verbose("%v", err)
 			return
@@ -104,4 +138,59 @@ func (rp *relayProxy) ServeHTTP(responseWriter http.ResponseWriter, r *http.Requ
 		resp.Body.Close()
 		verbose("bosun relay success")
 	}()
+	if parse && denormalizationRules != nil {
+		go rp.denormalize(bytes.NewReader(reader.buf.Bytes()))
+	}
+}
+
+func (rp *relayProxy) denormalize(body io.Reader) {
+	gReader, err := gzip.NewReader(body)
+	if err != nil {
+		verbose("error making gzip reader: %v", err)
+		return
+	}
+	decoder := json.NewDecoder(gReader)
+	dps := []*opentsdb.DataPoint{}
+	err = decoder.Decode(&dps)
+	if err != nil {
+		verbose("error decoding data points: %v", err)
+		return
+	}
+	relayDps := []*opentsdb.DataPoint{}
+	for _, dp := range dps {
+		if rule, ok := denormalizationRules[dp.Metric]; ok {
+			if err = rule.Translate(dp); err == nil {
+				relayDps = append(relayDps, dp)
+			} else {
+				verbose(err.Error())
+			}
+		}
+	}
+	if len(relayDps) == 0 {
+		return
+	}
+	buf := &bytes.Buffer{}
+	gWriter := gzip.NewWriter(buf)
+	encoder := json.NewEncoder(gWriter)
+	err = encoder.Encode(relayDps)
+	if err != nil {
+		verbose("error encoding denormalized data points: %v", err)
+		return
+	}
+	if err = gWriter.Close(); err != nil {
+		verbose("error zipping denormalized data points: %v", err)
+		return
+	}
+	req, err := http.NewRequest("POST", tsdbPutURL, buf)
+	if err != nil {
+		verbose("%v", err)
+		return
+	}
+	req.Header.Set("Content-Type", "application/json")
+	req.Header.Set("Content-Encoding", "gzip")
+
+	responseWriter := httptest.NewRecorder()
+	rp.relayRequest(responseWriter, req, false)
+
+	verbose("relayed %d denormalized data points. Tsdb response: %d", len(relayDps), responseWriter.Code)
 }
diff --git a/collect/collect.go b/collect/collect.go
index f29f5fa..2487fad 100644
--- a/collect/collect.go
+++ b/collect/collect.go
@@ -5,7 +5,6 @@
 package collect // import "bosun.org/collect"
 
 import (
-	"encoding/json"
 	"fmt"
 	"net/http"
 	"net/url"
@@ -53,7 +52,7 @@ var (
 	tsdbURL             string
 	osHostname          string
 	metricRoot          string
-	queue               []json.RawMessage
+	queue               []*opentsdb.DataPoint
 	qlock, mlock, slock sync.Mutex // Locks for queues, maps, stats.
 	counters            = make(map[string]*addMetric)
 	sets                = make(map[string]*setMetric)
diff --git a/collect/queue.go b/collect/queue.go
index 8c4c69b..aff2cd7 100644
--- a/collect/queue.go
+++ b/collect/queue.go
@@ -22,12 +22,7 @@ func queuer() {
 				slock.Unlock()
 				break
 			}
-			m, err := json.Marshal(dp)
-			if err != nil {
-				slog.Error(err)
-			} else {
-				queue = append(queue, m)
-			}
+			queue = append(queue, dp)
 			select {
 			case dp = <-tchan:
 				continue
@@ -60,37 +55,24 @@ func send() {
 	}
 }
 
-func sendBatch(batch []json.RawMessage) {
+func sendBatch(batch []*opentsdb.DataPoint) {
 	if Print {
 		for _, d := range batch {
-			slog.Info(string(d))
+			j, err := d.MarshalJSON()
+			if err != nil {
+				slog.Error(err)
+			}
+			slog.Info(string(j))
 		}
 		recordSent(len(batch))
 		return
 	}
-	var buf bytes.Buffer
-	g := gzip.NewWriter(&buf)
-	if err := json.NewEncoder(g).Encode(batch); err != nil {
-		slog.Error(err)
-		return
-	}
-	if err := g.Close(); err != nil {
-		slog.Error(err)
-		return
-	}
-	req, err := http.NewRequest("POST", tsdbURL, &buf)
-	if err != nil {
-		slog.Error(err)
-		return
-	}
-	req.Header.Set("Content-Type", "application/json")
-	req.Header.Set("Content-Encoding", "gzip")
 	now := time.Now()
-	resp, err := client.Do(req)
-	d := time.Since(now).Nanoseconds() / 1e6
+	resp, err := SendDataPoints(batch, tsdbURL)
 	if err == nil {
 		defer resp.Body.Close()
 	}
+	d := time.Since(now).Nanoseconds() / 1e6
 	Add("collect.post.total_duration", Tags, d)
 	Add("collect.post.count", Tags, 1)
 	// Some problem with connecting to the server; retry later.
@@ -111,13 +93,8 @@ func sendBatch(batch []json.RawMessage) {
 		}
 		restored := 0
 		for _, msg := range batch {
-			var dp opentsdb.DataPoint
-			if err := json.Unmarshal(msg, &dp); err != nil {
-				slog.Error(err)
-				continue
-			}
 			restored++
-			tchan <- &dp
+			tchan <- msg
 		}
 		d := time.Second * 5
 		Add("collect.post.restore", Tags, int64(restored))
@@ -136,3 +113,23 @@ func recordSent(num int) {
 	sent += int64(num)
 	slock.Unlock()
 }
+
+func SendDataPoints(dps []*opentsdb.DataPoint, tsdb string) (*http.Response, error) {
+	var buf bytes.Buffer
+	g := gzip.NewWriter(&buf)
+	if err := json.NewEncoder(g).Encode(dps); err != nil {
+		return nil, err
+	}
+	if err := g.Close(); err != nil {
+		return nil, err
+	}
+	req, err := http.NewRequest("POST", tsdb, &buf)
+	if err != nil {
+		return nil, err
+	}
+	req.Header.Set("Content-Type", "application/json")
+	req.Header.Set("Content-Encoding", "gzip")
+
+	resp, err := client.Do(req)
+	return resp, err
+}
diff --git a/docs/api.md b/docs/api.md
index 66815b8..ccf8bb5 100644
--- a/docs/api.md
+++ b/docs/api.md
@@ -187,14 +187,21 @@ Returns data about alerts, templates, and their relations.
 
 ## Configuration Endpoints
 
+### /api/backup
+
+Returns the state file for backup. The state file is guaranteed to be in a
+consistent state. This route is implemented by creating an in-memory copy
+of the state file, then streaming that to the response, so as to not block
+writes to the state file by other parts of bosun.
+
 ### /api/config
 
 Returns the current configuration that bosun is loaded with as text.
 
-### /api/config_test?config_text={text}
+### /api/config_test
 
-Validates an entire bosun configuration file for syntax errors. Returns an error
-if invalid.
+Reads a configuration file from the POST body then checks it for for syntax
+errors. Returns an error if invalid.
 
 </div>
 </div>
diff --git a/docs/configuration.md b/docs/configuration.md
index bd6420f..abd63b9 100644
--- a/docs/configuration.md
+++ b/docs/configuration.md
@@ -144,6 +144,7 @@ Global template functions:
 
 * V: performs variable expansion on the argument and returns it. Needed since normal variable expansion is not done due to the `$` character being used by the Go template syntax.
 * bytes: converts the string input into a human-readable number of bytes with extension KB, MB, GB, etc.
+* pct: formats the float argument as a percentage. For example: `{{5.1 | pct}}` -> `5.10%`.
 * replace: [strings.Replace](http://golang.org/pkg/strings/#Replace)
 * short: Trims the string to everything before the first period. Useful for turning a FQDN into a shortname. For example: `{{short "foo.baz.com"}}` -> `foo`.
 
diff --git a/docs/expressions.md b/docs/expressions.md
index 491a6d7..aacc9f3 100644
--- a/docs/expressions.md
+++ b/docs/expressions.md
@@ -25,12 +25,12 @@ This section documents Bosun's expression Language. Bosun's expression language
 There are three data types in Bosun's expression language:
 
  1. **Scalar**: This is the simplest type, it is a single numeric value with no group associated with it. Keep in mind that an empty group, `{}` is still a group.
- 2. **Number**: A number is a single numeric value with a group associated with it.
- 3. **Series**: A series is an array of timestamp-value pairs and an associated group.
+ 2. **NumberSet**: A number set is a group of tagged numeric values with one value per unique grouping.
+ 3. **SeriesSet**: A series is an array of timestamp-value pairs and an associated group.
 
-In the vast majority of your alerts you will getting ***series*** back from your time series database and ***reducing*** them into ***numbers***.
+In the vast majority of your alerts you will getting ***seriesSets*** back from your time series database and ***reducing*** them into ***numberSets***.
 
-## Groups
+## Group keys
 Groups are generally provided by your time series database. We also sometimes refer to groups as "Tags". When you query your time series database and get multiple time series back, each time series needs an identifier. So for example if I make a query with some thing like `host=*` then I will get one time series per host. Host is the tag key, and the various various values returned, i.e. host1, host2, host3.... are the tag values. Therefor the group for a single time series is something like `{host=host1}`. A group have multiple tag keys.
 
 Each group can become its own alert instance. This is what we mean by ***scope*** or dimensionality. Thus, you can do things like `avg(q("sum:sys.cpu{host=ny-*}", "5m", "")) > 0.8` to check many hosts at once. The dimensions can be manipulated with our expression language.  
@@ -58,7 +58,7 @@ From highest to lowest:
 1. `&&`
 1. `||`
 
-## Numbers
+## Numeric constants
 
 Numbers may be specified in decimal (123.45), octal (072), or hex (0x2A). Exponentials and signs are supported (-0.8e-2).
 
@@ -91,7 +91,7 @@ We don't need to understand everything in this alert, but it is worth highlighti
 
 ## Graphite Query Functions
 
-### GraphiteQuery(query, startDuration, endDuration, format)
+### GraphiteQuery(query string, startDuration string, endDuration string, format string) seriesSet
 
 Performs a graphite query.  the duration format is the internal bosun format (which happens to be the same as OpenTSDB's format).
 Functions pretty much the same as q() (see that for more info) but for graphite.
@@ -103,22 +103,22 @@ For example:
 
 `groupByNode(collectd.*.cpu.*.cpu.idle,1,'avg')`
 
-returns series named like `host1`, `host2` etc, in which case the format string can simply be `host`.
+returns seriesSet named like `host1`, `host2` etc, in which case the format string can simply be `host`.
 
 `collectd.web15.cpu.*.cpu.*`
 
-returns series named like `collectd.web15.cpu.3.idle`, requiring a format like  `.host..core..cpu_type`.
+returns seriesSet named like `collectd.web15.cpu.3.idle`, requiring a format like  `.host..core..cpu_type`.
 
 For advanced cases, you can use graphite's alias(), aliasSub(), etc to compose the exact parseable output format you need.
 This happens when the outer graphite function is something like "avg()" or "sum()" in which case graphite's output series will be identified as "avg(some.string.here)".
 
-### GraphiteBand(query, duration, period, format, num)
+### GraphiteBand(query string, duration string, period string, format string, num string) seriesSet
 
 Like band() but for graphite queries.
 
 ## Logstash Query Functions
 
-### lscount(indexRoot, keyString, filterString, bucketDuration, startDuration, endDuration)
+### lscount(indexRoot string, keyString string, filterString string, bucketDuration string, startDuration string, endDuration string) seriesSet
 
 lscount returns the per second rate of matching log documents.
 
@@ -134,7 +134,7 @@ For example:
 
 queries the "logstash" named indexes (we autogenerate the date porition of the indexes based on the time frame) and returns a series with groups like `{logsrouce:ny-bosun01, program:bosun}, {logsrouce:ny-bosun02, program:bosun}`. The values of the series will be the count of log entries in 5 second buckets over the last 10 minutes.
 
-### lsstat(indexRoot, keyString, filterString, field, rStat, bucketDuration, startDuration, endDuration)
+### lsstat(indexRoot string, keyString string, filterString string, field string, rStat(avg|min|max|sum|sum_of_squares|variance|std_deviation) string, bucketDuration string, startDuration string, endDuration string) series
 
 lstat returns various summary stats per bucket for the specified `field`. The field must be numeric in elastic. rStat can be one of `avg`, `min`, `max`, `sum`, `sum_of_squares`, `variance`, `std_deviation`. The rest of the fields behave the same as lscount except that there is no division based on `bucketDuration` since these are summary stats.
 
@@ -148,13 +148,17 @@ lstat returns various summary stats per bucket for the specified `field`. The fi
 
 ## OpenTSDB Query Functions
 
-Query functions take a query string (like `sum:os.cpu{host=*}`) and return a series.
+Query functions take a query string (like `sum:os.cpu{host=*}`) and return a seriesSet.
 
-### band(query, duration, period, num)
+### q(query string, startDuration string, endDuration string) seriesSet
+
+Generic query from endDuration to startDuration ago. If endDuration is the empty string (`""`), now is used. Support d( units are listed in [the docs](http://opentsdb.net/docs/build/html/user_guide/query/dates.html). Refer to [the docs](http://opentsdb.net/docs/build/html/user_guide/query/index.html) for query syntax. The query argument is the value part of the `m=...` expressions. `*` and `|` are fully supported. In addition, queries like `sys.cpu.user{host=ny-*}` are supported. These are performed by an additional step which determines valid matches, and replaces `ny-*` with `ny-web01|ny-web02|...|ny-web10` to achieve the same result. This lookup is kept in memory by the system and does not incur any additional OpenTSDB API requests, but does require tcollector instances pointed to the bosun server.
+
+### band(query string, duration string, period string, num scalar) seriesSet
 
 Band performs `num` queries of `duration` each, `period` apart and concatenates them together, starting `period` ago. So `band("avg:os.cpu", "1h", "1d", 7)` will return a series comprising of the given metric from 1d to 1d-1h-ago, 2d to 2d-1h-ago, etc, until 8d. This is a good way to get a time block from a certain hour of a day or certain day of a week over a long time period.
 
-### change(query, startDuration, endDuration)
+### change(query string, startDuration string, endDuration string) numberSet
 
 Change is a way to determine the change of a query from startDuration to endDuration. If endDuration is the empty string (`""`), now is used. The query must either be a rate or a counter converted to a rate with the `agg:rate:metric` flag.
 
@@ -166,15 +170,11 @@ Note that this is implemented using the bosun's `avg` function. The following is
 
 `avg(q("avg:rate:net.bytes", "60m", "")) * 60 * 60`
 
-### count(query, startDuration, endDuration)
+### count(query string, startDuration string, endDuration string) scalar
 
 Count returns the number of groups in the query as an ungrouped scalar.
 
-### q(query, startDuration, endDuration)
-
-Generic query from endDuration to startDuration ago. If endDuration is the empty string (`""`), now is used. Support d( units are listed in [the docs](http://opentsdb.net/docs/build/html/user_guide/query/dates.html). Refer to [the docs](http://opentsdb.net/docs/build/html/user_guide/query/index.html) for query syntax. The query argument is the value part of the `m=...` expressions. `*` and `|` are fully supported. In addition, queries like `sys.cpu.user{host=ny-*}` are supported. These are performed by an additional step which determines valid matches, and replaces `ny-*` with `ny-web01|ny-web02|...|ny-web10` to achieve the same result. This lookup is kept in memory by the system and does not incur any additional OpenTSDB API requests, but does require tcollector instances pointed to the bosun server.
-
-### window(query, duration, period, num, funcName)
+### window(query string, duration string, period string, num scalar, funcName string) seriesSet
 
 Window performs `num` queries of `duration` each, `period` apart, starting
 `period` ago. The results of the queries are run through `funcName` which
@@ -188,61 +188,61 @@ and those numbers created into a series.
 
 # Reduction Functions
 
-All reduction functions take a series and return a number.
+All reduction functions take a seriesSet and return a numberSet with one element per unique group.
 
-## avg(series)
+## avg(seriesSet) numberSet
 
 Average.
 
-## dev(series)
+## dev(seriesSet) numberSet
 
 Standard deviation.
 
-## diff(series)
+## diff(seriesSet) numberSet
 
-Diff returns the last point of the series minus the first point.
+Diff returns the last point of each series minus the first point.
 
-## first(series)
+## first(seriesSet) numberSet
 
-Returns the first (least recent) data point in the series.
+Returns the first (least recent) data point in each series.
 
-## forecastlr(series, y_val)
+## forecastlr(seriesSet, y_val scalar) numberSet
 
-Returns the number of seconds until a linear regression of the series will reach y_val.
+Returns the number of seconds until a linear regression of each series will reach y_val.
 
-## last(series)
+## last(seriesSet) numberSet
 
-Returns the last (most recent) data point in the series.
+Returns the last (most recent) data point in each series.
 
-## len(series)
+## len(seriesSet) numberSet
 
-Returns the length of the series.
+Returns the length of each series.
 
-## max(series)
+## max(seriesSet) numberSet
 
-Returns the maximum value of the series, same as calling percentile(series, 1).
+Returns the maximum value of each series, same as calling percentile(series, 1).
 
-## median(series)
+## median(seriesSet) numberSet
 
-Returns the median value of the series, same as calling percentile(series, .5).
+Returns the median value of each series, same as calling percentile(series, .5).
 
-## min(series)
+## min(seriesSet) numberSet
 
-Returns the minimum value of the series, same as calling percentile(series, 0).
+Returns the minimum value of each series, same as calling percentile(series, 0).
 
-## percentile(series, p)
+## percentile(seriesSet, p scalar) numberSet
 
-Returns the value from the series at the percentile p. Min and Max can be simulated using `p <= 0` and `p >= 1`, respectively.
+Returns the value from each series at the percentile p. Min and Max can be simulated using `p <= 0` and `p >= 1`, respectively.
 
-## since(series)
+## since(seriesSet) numberSet
 
-Returns the number of seconds since the most recent data point in the series.
+Returns the number of seconds since the most recent data point in each series.
 
-## streak(series)
+## streak(seriesSet) numberSet
 
 Returns the length of the longest streak of values that evaluate to true (i.e. max amount of contiguous non-zero values found).
 
-## sum(series)
+## sum(seriesSet) numberSet
 
 Sum.
 
@@ -250,7 +250,7 @@ Sum.
 
 Group functions modify the OpenTSDB groups.
 
-## t(number, group)
+## t(numberSet, group string) seriesSet
 
 Transposes N series of length 1 to 1 series of length N. If the group parameter is not the empty string, the number of series returned is equal to the number of tagks passed. This is useful for performing scalar aggregation across multiple results from a query. For example, to get the total memory used on the web tier: `sum(t(avg(q("avg:os.mem.used{host=*-web*}", "5m", "")), ""))`.
 
@@ -258,7 +258,7 @@ How transpose works conceptually
 
 Transpose Grouped results into a Single Result:  
 
-Before Transpose (Value Type is Number):  
+Before Transpose (Value Type is NumberSet):  
 
 Group       | Value  |
 ----------- | ----- |
@@ -266,7 +266,7 @@ Group       | Value  |
 {host=web02} | 7 |
 {host=web03} | 4 |
 
-After Transpose (Value Type is Series):  
+After Transpose (Value Type is SeriesSet):  
 
 Group        | Value  |
 ----------- | ----- |
@@ -274,7 +274,7 @@ Group        | Value  |
 
 Transpose Groups results into Multiple Results:  
 
-Before Transpose by host (Value Type is Number)  
+Before Transpose by host (Value Type is NumberSet)  
 
 Group        | Value  |
 ----------- | ----- |
@@ -282,7 +282,7 @@ Group        | Value  |
 {host=web01,disc=d} | 3 |
 {host=web02,disc=c} | 4 |
 
-After Transpose by "host" (Value type is Series)  
+After Transpose by "host" (Value type is SeriesSet)  
 
 Group        | Value  |
 ------------ | ------ |
@@ -316,13 +316,13 @@ Alert if more than 50% of servers in a group have ping timeouts
 
 Since our templates can reference any variable in this alert, we can show which servers are down in the notification, even though the alert just triggers on 25% of or-\* servers being down.
 
-## ungroup(number)
+## ungroup(numberSet) scalar
 
 Returns the input with its group removed. Used to combine queries from two differing groups.
 
 # Other Functions
 
-## alert(name, key)
+## alert(name string, key string) numberSet
 
 Executes and returns the `key` expression from alert `name` (which must be
 `warn` or `crit`). Any alert of the same name that is unknown or unevaluated
@@ -331,55 +331,55 @@ is also returned with a value of `1`. Primarily for use with `depends`.
 Example: `alert("host.down", "crit")` returns the crit
 expression from the host.down alert.
 
-## abs(number)
+## abs(numberSet) numberSet
 
-Returns the absolute value of the number.
+Returns the absolute value of each element in the numberSet.
 
-## d(string)
+## d(string) scalar
 
 Returns the number of seconds of the [OpenTSDB duration string](http://opentsdb.net/docs/build/html/user_guide/query/dates.html).
 
-## des(series, alpha, beta)
+## des(series, alpha scalar, beta scalar) series
 
 Returns series smoothed using Holt-Winters double exponential smoothing. Alpha
 (scalar) is the data smoothing factor. Beta (scalar) is the trend smoothing
 factor.
 
-## dropge(series, number)
+## dropge(seriesSet, scalar) seriesSet
 
 Remove any values greater than or equal to number from a series. Will error if this operation results in an empty series.
 
-## drople(series, number)
+## drople(seriesSet, scalar) seriesSet
 
 Remove any values lower than or equal to number from a series. Will error if this operation results in an empty series.
 
-## dropna(series)
+## dropna(seriesSet) seriesSet
 
 Remove any NaN or Inf values from a series. Will error if this operation results in an empty series.
 
-## epoch()
+## epoch() scalar
 
 Returns the Unix epoch in seconds of the expression start time (scalar).
 
-## filter(series, number)
+## filter(seriesSet, numberSet) seriesSet
 
 Returns all results in series that are a subset of anything in number, or
 that have number as a subset. Useful with the limit and sort functions to
 return the top X results of a query.
 
-## limit(number, count)
+## limit(numberSet, count scalar) numberSet
 
 Returns the first count (scalar) results of number.
 
-## lookup(table, key)
+## lookup(table string, key string) numberSet 
 
 Returns the first key from the given lookup table with matching tags.
 
-## nv(number, scalar)
+## nv(numberSet, scalar) numberSet
 
 Change the NaN value during binary operations (when joining two queries) of unknown groups to the scalar. This is useful to prevent unknown group and other errors from bubbling up.
 
-## sort(number, asc_desc)
+## sort(numberSet, (asc|desc) string) numberSet
 
 Returns the results sorted by value in ascending ("asc") or descending ("desc")
 order. Results are first sorted by groupname and then stably sorted so that
diff --git a/version/version.go b/version/version.go
index 652119f..c3cf0dd 100644
--- a/version/version.go
+++ b/version/version.go
@@ -23,13 +23,16 @@ var (
 
 // Get a string representing the version information for the current binary.
 func GetVersionInfo(app string) string {
+	var sha, build string
+	version := Version
 	if OfficialBuild == "" {
-		Version = Version + "-dev"
+		version += "-dev"
 	}
-	timeString := ""
-	buildTime, err := time.Parse("20060102150405", VersionDate)
-	if err == nil {
-		timeString = " Built " + buildTime.Format(time.RFC822)
+	if buildTime, err := time.Parse("20060102150405", VersionDate); err == nil {
+		build = " built " + buildTime.Format(time.RFC3339)
 	}
-	return fmt.Sprintf("%s version %v (%v)%s\n", app, Version, VersionSHA, timeString)
+	if VersionSHA != "" {
+		sha = fmt.Sprintf(" (%s)", VersionSHA)
+	}
+	return fmt.Sprintf("%s version %s%s%s", app, version, sha, build)
 }
